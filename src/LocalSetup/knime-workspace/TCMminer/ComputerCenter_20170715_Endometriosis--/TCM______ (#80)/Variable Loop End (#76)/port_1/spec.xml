<?xml version="1.0" encoding="UTF-8"?>
<config xmlns="http://www.knime.org/2008/09/XMLConfig" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.knime.org/2008/09/XMLConfig http://www.knime.org/XMLConfig_2008_09.xsd" key="spec.xml">
<entry key="spec_name" type="xstring" value="default"/>
<entry key="number_columns" type="xint" value="50"/>
<config key="column_spec_0">
<entry key="column_name" type="xstring" value="FailingNodeStackTrace"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="6"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:08:11 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:08:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:08:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:08:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:08:12 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:08:12 INFO Remoting: Starting remoting%%0001017/07/18 02:08:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46473]%%0001017/07/18 02:08:12 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46473]%%0001017/07/18 02:08:12 INFO Utils: Successfully started service 'sparkDriver' on port 46473.%%0001017/07/18 02:08:12 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:08:12 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:08:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-61cb6407-a356-4d08-8afd-66d83e794b50%%0001017/07/18 02:08:12 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:08:13 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b037b803-129d-4de1-b623-352fe8384519/httpd-4461f793-693a-4a3d-9ee6-d3c070936523%%0001017/07/18 02:08:13 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:08:13 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:08:13 INFO AbstractConnector: Started SocketConnector@0.0.0.0:37752%%0001017/07/18 02:08:13 INFO Utils: Successfully started service 'HTTP file server' on port 37752.%%0001017/07/18 02:08:13 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:08:13 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:08:13 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:08:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:08:13 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:08:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:08:14 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:08:14 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:08:14 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:08:14 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:08:14 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:08:14 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:08:14 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:08:14 INFO Client: Uploading resource file:/tmp/spark-b037b803-129d-4de1-b623-352fe8384519/__spark_conf__3959330619433399621.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22139/__spark_conf__3959330619433399621.zip%%0001017/07/18 02:08:14 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:08:14 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:08:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:08:14 INFO Client: Submitting application 22139 to ResourceManager%%0001017/07/18 02:08:15 INFO YarnClientImpl: Submitted application application_1491786134915_22139%%0001017/07/18 02:08:16 INFO Client: Application report for application_1491786134915_22139 (state: ACCEPTED)%%0001017/07/18 02:08:16 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314894880%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22139/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:08:17 INFO Client: Application report for application_1491786134915_22139 (state: ACCEPTED)%%0001017/07/18 02:08:17 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:36856/user/YarnAM#1533634657])%%0001017/07/18 02:08:17 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22139,http://hcnnc117:8088/proxy/application_1491786134915_22139), /proxy/application_1491786134915_22139%%0001017/07/18 02:08:17 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:08:18 INFO Client: Application report for application_1491786134915_22139 (state: RUNNING)%%0001017/07/18 02:08:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314894880%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22139/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:08:18 INFO YarnClientSchedulerBackend: Application application_1491786134915_22139 has started running.%%0001017/07/18 02:08:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36689.%%0001017/07/18 02:08:18 INFO NettyBlockTransferService: Server created on 36689%%0001017/07/18 02:08:18 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:08:18 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:08:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:36689 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 36689)%%0001017/07/18 02:08:18 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:08:19 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22139%%0001017/07/18 02:08:19 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:08:19 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:08:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:08:19 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:08:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:08:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:36689 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:08:19 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:08:19 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:08:20 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:08:20 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:08:20 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:08:20 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:08:20 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:08:20 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:08:20 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:08:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:08:20 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:08:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:08:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:36689 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:08:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:08:20 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:08:21 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:08:22 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:08:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46473] &lt;- [akka.tcp://driverPropsFetcher@hcdnc318:45434]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc318:45434] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc318:45434%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:24 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc318:51042/user/Executor#96535585]) with ID 1%%0001017/07/18 02:08:24 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:08:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc318, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:08:24 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc318:46705 with 530.0 MB RAM, BlockManagerId(1, hcdnc318, 46705)%%0001017/07/18 02:08:24 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46473] &lt;- [akka.tcp://driverPropsFetcher@hcdnc835:46825]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc835:46825] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc835:46825%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc318:46705 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:24 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc835:32795/user/Executor#-1278415339]) with ID 2%%0001017/07/18 02:08:24 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:08:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc835, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:08:24 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc835:39227 with 530.0 MB RAM, BlockManagerId(2, hcdnc835, 39227)%%0001017/07/18 02:08:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc318:46705 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:08:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc835:39227 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc835:39227 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:08:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1751 ms on hcdnc318 (1/2)%%0001017/07/18 02:08:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1806 ms on hcdnc835 (2/2)%%0001017/07/18 02:08:26 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.412 s%%0001017/07/18 02:08:26 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:26 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.535779 s%%0001017/07/18 02:08:26 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:08:26 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:08:26 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:08:26 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:08:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:08:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:08:26 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:08:26 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:08:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:08:26 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:08:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:36689 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:08:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:08:26 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:08:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc318, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:08:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc835, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc318:46705 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc835:39227 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:08:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 277 ms on hcdnc835 (1/2)%%0001017/07/18 02:08:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 322 ms on hcdnc318 (2/2)%%0001017/07/18 02:08:26 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.323 s%%0001017/07/18 02:08:26 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:26 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:26 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:26 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:08:26 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:26 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:08:26 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:08:26 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251391, maxMem=556038881%%0001017/07/18 02:08:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:08:26 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258327, maxMem=556038881%%0001017/07/18 02:08:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:36689 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:08:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:08:26 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:08:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc318, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc835, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc318:46705 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc835:39227 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc835:32795%%0001017/07/18 02:08:26 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 02:08:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc318:51042%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 89 ms on hcdnc835 (1/2)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 102 ms on hcdnc318 (2/2)%%0001017/07/18 02:08:27 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.103 s%%0001017/07/18 02:08:27 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:27 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.458226 s%%0001017/07/18 02:08:27 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:08:27 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:08:27 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:08:27 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:08:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:08:27 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262370, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268890, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:36689 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:08:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:08:27 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc835, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc318, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc835:39227 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc318:46705 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 101 ms on hcdnc318 (1/2)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 110 ms on hcdnc835 (2/2)%%0001017/07/18 02:08:27 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.110 s%%0001017/07/18 02:08:27 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:27 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.124875 s%%0001017/07/18 02:08:27 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:08:27 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:08:27 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:08:27 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:08:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:08:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272792, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279968, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:36689 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:08:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:08:27 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc318, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc835, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc318:46705 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc835:39227 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 184 ms on hcdnc318 (1/2)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 195 ms on hcdnc835 (2/2)%%0001017/07/18 02:08:27 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:27 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.196 s%%0001017/07/18 02:08:27 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:27 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:27 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:08:27 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:27 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284117, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286901, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:36689 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:08:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:08:27 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc835, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc318, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc318:46705 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc835:39227 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc318:51042%%0001017/07/18 02:08:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 174 bytes%%0001017/07/18 02:08:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc835:32795%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc318, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc835, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc318 (1/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc835 (2/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc318, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc835, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc318 (3/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc835 (4/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc835, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc318, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc835 (5/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 22 ms on hcdnc318 (6/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc318, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc835, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 17 ms on hcdnc318 (7/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 20 ms on hcdnc835 (8/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc835 (9/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc318 (10/10)%%0001017/07/18 02:08:27 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.111 s%%0001017/07/18 02:08:27 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:27 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.329830 s%%0001017/07/18 02:08:27 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:08:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 02:08:27 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:08:27 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:08:27 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:08:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:08:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(14512) called with curMem=288514, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.2 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(8051) called with curMem=303026, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.9 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:36689 (size: 7.9 KB, free: 530.2 MB)%%0001017/07/18 02:08:27 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:08:27 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc835, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc318, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc835:39227 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc318:46705 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc835:32795%%0001017/07/18 02:08:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc318:51042%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 424 ms on hcdnc318 (1/2)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 455 ms on hcdnc835 (2/2)%%0001017/07/18 02:08:28 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:28 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.456 s%%0001017/07/18 02:08:28 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:28 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:28 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:08:28 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:28 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:08:28 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:08:28 INFO MemoryStore: ensureFreeSpace(17944) called with curMem=311077, maxMem=556038881%%0001017/07/18 02:08:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 530.0 MB)%%0001017/07/18 02:08:28 INFO MemoryStore: ensureFreeSpace(9629) called with curMem=329021, maxMem=556038881%%0001017/07/18 02:08:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 530.0 MB)%%0001017/07/18 02:08:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:36689 (size: 9.4 KB, free: 530.2 MB)%%0001017/07/18 02:08:28 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:28 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:08:28 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc318, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc835, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc835:39227 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:08:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc318:46705 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:08:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc835:32795%%0001017/07/18 02:08:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 02:08:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc318:51042%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc835, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 108 ms on hcdnc835 (1/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc318, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 133 ms on hcdnc318 (2/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc835, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 56 ms on hcdnc835 (3/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc318, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 64 ms on hcdnc318 (4/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc835, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 55 ms on hcdnc835 (5/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc835, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 54 ms on hcdnc835 (6/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc318, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 83 ms on hcdnc318 (7/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc835, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 54 ms on hcdnc835 (8/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 53 ms on hcdnc318 (9/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 68 ms on hcdnc835 (10/10)%%0001017/07/18 02:08:28 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:28 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.392 s%%0001017/07/18 02:08:28 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.884791 s%%0001017/07/18 02:08:28 INFO SparkContext: Invoking stop() from shutdown hook%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:08:28 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:08:28 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:08:28 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:08:28 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:08:28 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:08:28 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:08:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46473] &lt;- [akka.tcp://sparkExecutor@hcdnc318:51042]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc318:51042] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc318:51042%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46473] &lt;- [akka.tcp://sparkExecutor@hcdnc835:32795]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc835:32795] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc835:32795%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:08:28 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:08:28 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:08:28 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:08:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:08:28 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:08:28 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:08:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-b037b803-129d-4de1-b623-352fe8384519/pyspark-7ab780e3-2bac-4af7-aaad-cfe5e81a32b9%%0001017/07/18 02:08:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-b037b803-129d-4de1-b623-352fe8384519%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:08:43 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:08:43 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:08:43 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:08:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:08:44 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:08:44 INFO Remoting: Starting remoting%%0001017/07/18 02:08:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:35862]%%0001017/07/18 02:08:44 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:35862]%%0001017/07/18 02:08:44 INFO Utils: Successfully started service 'sparkDriver' on port 35862.%%0001017/07/18 02:08:44 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:08:44 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:08:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8890d7ac-cc18-4962-825f-fd2081f00b90%%0001017/07/18 02:08:44 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:08:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-62698cb2-d96f-409f-9f5b-ddefa1843123/httpd-8521f33c-e24e-4cac-bfb3-2a0cab705c7e%%0001017/07/18 02:08:44 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:08:44 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:08:44 INFO AbstractConnector: Started SocketConnector@0.0.0.0:41856%%0001017/07/18 02:08:44 INFO Utils: Successfully started service 'HTTP file server' on port 41856.%%0001017/07/18 02:08:44 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:08:44 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:08:45 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:08:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:08:45 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:08:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:08:46 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:08:46 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:08:46 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:08:46 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:08:46 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:08:46 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:08:46 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:08:46 INFO Client: Uploading resource file:/tmp/spark-62698cb2-d96f-409f-9f5b-ddefa1843123/__spark_conf__3258497662408211574.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22140/__spark_conf__3258497662408211574.zip%%0001017/07/18 02:08:46 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:08:46 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:08:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:08:46 INFO Client: Submitting application 22140 to ResourceManager%%0001017/07/18 02:08:47 INFO YarnClientImpl: Submitted application application_1491786134915_22140%%0001017/07/18 02:08:48 INFO Client: Application report for application_1491786134915_22140 (state: ACCEPTED)%%0001017/07/18 02:08:48 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314926893%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22140/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:08:49 INFO Client: Application report for application_1491786134915_22140 (state: ACCEPTED)%%0001017/07/18 02:08:50 INFO Client: Application report for application_1491786134915_22140 (state: ACCEPTED)%%0001017/07/18 02:08:50 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:53899/user/YarnAM#-466894763])%%0001017/07/18 02:08:50 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22140,http://hcnnc117:8088/proxy/application_1491786134915_22140), /proxy/application_1491786134915_22140%%0001017/07/18 02:08:50 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:08:51 INFO Client: Application report for application_1491786134915_22140 (state: RUNNING)%%0001017/07/18 02:08:51 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314926893%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22140/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:08:51 INFO YarnClientSchedulerBackend: Application application_1491786134915_22140 has started running.%%0001017/07/18 02:08:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35338.%%0001017/07/18 02:08:51 INFO NettyBlockTransferService: Server created on 35338%%0001017/07/18 02:08:51 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:08:51 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:08:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:35338 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 35338)%%0001017/07/18 02:08:51 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:08:51 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22140%%0001017/07/18 02:08:51 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:08:51 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:08:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:08:51 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:08:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:08:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:35338 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:08:51 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:08:52 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:08:52 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:08:52 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:08:52 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:08:52 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:08:52 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:08:52 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:08:52 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:08:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:08:52 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:08:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:08:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:35338 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:08:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:08:52 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:08:53 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:08:54 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:08:55 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:35862] &lt;- [akka.tcp://driverPropsFetcher@hcdnc332:33394]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc332:33394] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc332:33394%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:56 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc332:44468/user/Executor#1978266903]) with ID 1%%0001017/07/18 02:08:56 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:08:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc332, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:08:56 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc332:48676 with 530.0 MB RAM, BlockManagerId(1, hcdnc332, 48676)%%0001017/07/18 02:08:56 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:35862] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:45068]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:45068] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:45068%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc332:48676 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:56 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:56792/user/Executor#-875278384]) with ID 2%%0001017/07/18 02:08:56 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:08:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:08:56 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:42885 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 42885)%%0001017/07/18 02:08:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc332:48676 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:08:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:42885 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:42885 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:08:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1681 ms on hcdnc332 (1/2)%%0001017/07/18 02:08:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1822 ms on hcdnc310 (2/2)%%0001017/07/18 02:08:58 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.404 s%%0001017/07/18 02:08:58 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:58 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.533883 s%%0001017/07/18 02:08:58 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:08:58 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:08:58 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:08:58 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:08:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:08:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:08:58 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:08:58 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:08:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:08:58 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:08:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:08:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:35338 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:08:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:08:58 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:08:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc332, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:08:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:08:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc332:48676 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:08:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:42885 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 333 ms on hcdnc332 (1/2)%%0001017/07/18 02:08:59 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.349 s%%0001017/07/18 02:08:59 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 347 ms on hcdnc310 (2/2)%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:59 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:08:59 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251391, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(4044) called with curMem=258327, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:35338 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc332:48676 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:42885 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc332:44468%%0001017/07/18 02:08:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:56792%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 102 ms on hcdnc310 (1/2)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 111 ms on hcdnc332 (2/2)%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.112 s%%0001017/07/18 02:08:59 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.496176 s%%0001017/07/18 02:08:59 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:08:59 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:08:59 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:08:59 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:08:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262371, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(3903) called with curMem=268891, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:35338 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc332:48676 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:42885 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 97 ms on hcdnc332 (1/2)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 112 ms on hcdnc310 (2/2)%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.113 s%%0001017/07/18 02:08:59 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.126059 s%%0001017/07/18 02:08:59 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:08:59 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:08:59 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:08:59 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:08:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272794, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(4150) called with curMem=279970, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:35338 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc332, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:42885 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc332:48676 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 175 ms on hcdnc310 (1/2)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 180 ms on hcdnc332 (2/2)%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.182 s%%0001017/07/18 02:08:59 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:59 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:59 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:08:59 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284120, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286904, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:35338 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc332:48676 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:42885 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc332:44468%%0001017/07/18 02:08:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 173 bytes%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:56792%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc310 (1/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc332, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 51 ms on hcdnc332 (2/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc310 (3/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc332, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc332 (4/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc310 (5/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc332, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc332 (6/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc310 (7/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc332, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc332 (8/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc310 (9/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc332 (10/10)%%0001017/07/18 02:08:59 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.308151 s%%0001017/07/18 02:08:59 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:08:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:08:59 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:08:59 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:08:59 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:08:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(14512) called with curMem=288517, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.2 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(8051) called with curMem=303029, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.9 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:35338 (size: 7.9 KB, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc332, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc332:48676 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:42885 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc332:44468%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:56792%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 400 ms on hcdnc332 (1/2)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 437 ms on hcdnc310 (2/2)%%0001017/07/18 02:09:00 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:00 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.438 s%%0001017/07/18 02:09:00 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:09:00 INFO DAGScheduler: running: Set()%%0001017/07/18 02:09:00 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:09:00 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:09:00 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:09:00 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:09:00 INFO MemoryStore: ensureFreeSpace(17944) called with curMem=311080, maxMem=556038881%%0001017/07/18 02:09:00 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 530.0 MB)%%0001017/07/18 02:09:00 INFO MemoryStore: ensureFreeSpace(9629) called with curMem=329024, maxMem=556038881%%0001017/07/18 02:09:00 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 530.0 MB)%%0001017/07/18 02:09:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:35338 (size: 9.4 KB, free: 530.2 MB)%%0001017/07/18 02:09:00 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:00 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:09:00 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:42885 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:09:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc332:48676 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:09:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:56792%%0001017/07/18 02:09:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 163 bytes%%0001017/07/18 02:09:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc332:44468%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 107 ms on hcdnc310 (1/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc332, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 108 ms on hcdnc332 (2/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 54 ms on hcdnc310 (3/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc332, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 56 ms on hcdnc332 (4/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 54 ms on hcdnc310 (5/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc332, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 69 ms on hcdnc332 (6/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 57 ms on hcdnc310 (7/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc332, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 54 ms on hcdnc332 (8/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 62 ms on hcdnc310 (9/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 57 ms on hcdnc332 (10/10)%%0001017/07/18 02:09:00 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:00 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.340 s%%0001017/07/18 02:09:00 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.819238 s%%0001017/07/18 02:09:00 INFO SparkContext: Invoking stop() from shutdown hook%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:09:00 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:09:00 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:09:00 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:09:00 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:09:00 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:09:00 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:09:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:35862] &lt;- [akka.tcp://sparkExecutor@hcdnc310:56792]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:56792] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:56792%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:35862] &lt;- [akka.tcp://sparkExecutor@hcdnc332:44468]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc332:44468] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc332:44468%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:09:00 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:09:00 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:09:00 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:09:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:09:00 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:09:00 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:09:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-62698cb2-d96f-409f-9f5b-ddefa1843123%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:09:17 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:09:17 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:09:17 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:09:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:09:18 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:09:18 INFO Remoting: Starting remoting%%0001017/07/18 02:09:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:45061]%%0001017/07/18 02:09:18 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:45061]%%0001017/07/18 02:09:18 INFO Utils: Successfully started service 'sparkDriver' on port 45061.%%0001017/07/18 02:09:18 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:09:18 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:09:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ae547a56-2c2d-4bf9-8f45-0c8fb4fa87d8%%0001017/07/18 02:09:18 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:09:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3b474b11-f20f-4c9d-94f5-3b5704a8eb39/httpd-b162e3f1-88f2-4499-aedf-8ba1370549ef%%0001017/07/18 02:09:18 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:09:18 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:09:18 INFO AbstractConnector: Started SocketConnector@0.0.0.0:44784%%0001017/07/18 02:09:18 INFO Utils: Successfully started service 'HTTP file server' on port 44784.%%0001017/07/18 02:09:18 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:09:18 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:09:18 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:09:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:09:18 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:09:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:09:19 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:09:19 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:09:19 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:09:19 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:09:19 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:09:19 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:09:19 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:09:20 INFO Client: Uploading resource file:/tmp/spark-3b474b11-f20f-4c9d-94f5-3b5704a8eb39/__spark_conf__2376122244754367765.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22141/__spark_conf__2376122244754367765.zip%%0001017/07/18 02:09:20 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:09:20 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:09:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:09:20 INFO Client: Submitting application 22141 to ResourceManager%%0001017/07/18 02:09:21 INFO YarnClientImpl: Submitted application application_1491786134915_22141%%0001017/07/18 02:09:22 INFO Client: Application report for application_1491786134915_22141 (state: ACCEPTED)%%0001017/07/18 02:09:22 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314960843%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22141/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:09:23 INFO Client: Application report for application_1491786134915_22141 (state: ACCEPTED)%%0001017/07/18 02:09:23 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:45892/user/YarnAM#2026689242])%%0001017/07/18 02:09:23 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22141,http://hcnnc117:8088/proxy/application_1491786134915_22141), /proxy/application_1491786134915_22141%%0001017/07/18 02:09:23 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:09:24 INFO Client: Application report for application_1491786134915_22141 (state: RUNNING)%%0001017/07/18 02:09:24 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314960843%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22141/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:09:24 INFO YarnClientSchedulerBackend: Application application_1491786134915_22141 has started running.%%0001017/07/18 02:09:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36561.%%0001017/07/18 02:09:24 INFO NettyBlockTransferService: Server created on 36561%%0001017/07/18 02:09:24 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:09:24 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:09:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:36561 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 36561)%%0001017/07/18 02:09:24 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:09:24 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22141%%0001017/07/18 02:09:24 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:09:24 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:09:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:09:24 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:09:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:09:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:36561 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:09:24 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:09:24 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:09:25 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:09:25 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:09:25 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:09:25 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:09:25 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:09:25 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:09:25 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:09:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:09:25 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:09:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:09:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:36561 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:09:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:09:25 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:09:26 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:09:27 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:09:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:45061] &lt;- [akka.tcp://driverPropsFetcher@hcdnc823:41439]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:41439] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:41439%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:29 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc823:52848/user/Executor#-891399144]) with ID 1%%0001017/07/18 02:09:29 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:09:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc823, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:09:29 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc823:44803 with 530.0 MB RAM, BlockManagerId(1, hcdnc823, 44803)%%0001017/07/18 02:09:29 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:45061] &lt;- [akka.tcp://driverPropsFetcher@hcdnc326:40241]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc326:40241] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc326:40241%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc823:44803 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:29 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc326:50019/user/Executor#-1470298923]) with ID 2%%0001017/07/18 02:09:29 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:09:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc326, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:09:29 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc326:52167 with 530.0 MB RAM, BlockManagerId(2, hcdnc326, 52167)%%0001017/07/18 02:09:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc823:44803 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:09:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc326:52167 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc326:52167 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:09:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1769 ms on hcdnc823 (1/2)%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1706 ms on hcdnc326 (2/2)%%0001017/07/18 02:09:31 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.236 s%%0001017/07/18 02:09:31 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:31 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.356416 s%%0001017/07/18 02:09:31 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:09:31 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:09:31 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:09:31 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:09:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:09:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:36561 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:09:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:09:31 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc823, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc326, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc326:52167 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc823:44803 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 305 ms on hcdnc326 (1/2)%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 346 ms on hcdnc823 (2/2)%%0001017/07/18 02:09:31 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:31 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.348 s%%0001017/07/18 02:09:31 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:09:31 INFO DAGScheduler: running: Set()%%0001017/07/18 02:09:31 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:09:31 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:09:31 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251391, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258327, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:36561 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:09:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:09:31 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc326, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc823:44803 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc326:52167 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:52848%%0001017/07/18 02:09:31 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 02:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc326:50019%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 85 ms on hcdnc326 (1/2)%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 96 ms on hcdnc823 (2/2)%%0001017/07/18 02:09:31 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:31 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.096 s%%0001017/07/18 02:09:31 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.477330 s%%0001017/07/18 02:09:31 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:09:31 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:09:31 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:09:31 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:09:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:09:31 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262370, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268890, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:36561 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:09:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:09:31 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc326, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc326:52167 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc823:44803 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 89 ms on hcdnc326 (1/2)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 142 ms on hcdnc823 (2/2)%%0001017/07/18 02:09:32 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:32 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.144 s%%0001017/07/18 02:09:32 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.156992 s%%0001017/07/18 02:09:32 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:09:32 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:09:32 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:09:32 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:09:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:09:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272792, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279968, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:36561 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:09:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:09:32 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc326, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc823, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc823:44803 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc326:52167 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 210 ms on hcdnc326 (1/2)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 216 ms on hcdnc823 (2/2)%%0001017/07/18 02:09:32 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:32 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.217 s%%0001017/07/18 02:09:32 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:09:32 INFO DAGScheduler: running: Set()%%0001017/07/18 02:09:32 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:09:32 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:09:32 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284117, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286901, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:36561 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:09:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:09:32 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc326, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc823, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc326:52167 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc823:44803 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc326:50019%%0001017/07/18 02:09:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 174 bytes%%0001017/07/18 02:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc823:52848%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc326, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc326 (1/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc823, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc823 (2/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc326, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 13 ms on hcdnc326 (3/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc823 (4/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc326, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc326 (5/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 21 ms on hcdnc823 (6/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc326, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc326 (7/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc823 (8/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc326 (9/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc823 (10/10)%%0001017/07/18 02:09:32 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 02:09:32 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:32 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.341066 s%%0001017/07/18 02:09:32 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:09:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 02:09:32 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:09:32 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:09:32 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:09:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:09:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(14512) called with curMem=288514, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.2 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(8051) called with curMem=303026, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.9 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:36561 (size: 7.9 KB, free: 530.2 MB)%%0001017/07/18 02:09:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:09:32 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc823, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc326, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc326:52167 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc823:44803 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc326:50019%%0001017/07/18 02:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:52848%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 426 ms on hcdnc823 (1/2)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 433 ms on hcdnc326 (2/2)%%0001017/07/18 02:09:32 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:32 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.436 s%%0001017/07/18 02:09:32 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:09:32 INFO DAGScheduler: running: Set()%%0001017/07/18 02:09:32 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:09:32 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:09:32 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(17944) called with curMem=311077, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(9629) called with curMem=329021, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 530.0 MB)%%0001017/07/18 02:09:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:36561 (size: 9.4 KB, free: 530.2 MB)%%0001017/07/18 02:09:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:33 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:09:33 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc326, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc326:52167 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:09:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc823:44803 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc326:50019%%0001017/07/18 02:09:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 02:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc823:52848%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc823, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 118 ms on hcdnc823 (1/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc326, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 126 ms on hcdnc326 (2/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc823, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 56 ms on hcdnc823 (3/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc326, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 61 ms on hcdnc326 (4/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc823, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 53 ms on hcdnc823 (5/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc326, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 54 ms on hcdnc326 (6/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc823, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 57 ms on hcdnc823 (7/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc326, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 55 ms on hcdnc326 (8/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 57 ms on hcdnc823 (9/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 57 ms on hcdnc326 (10/10)%%0001017/07/18 02:09:33 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:33 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.352 s%%0001017/07/18 02:09:33 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.828308 s%%0001017/07/18 02:09:33 INFO SparkContext: Invoking stop() from shutdown hook%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:09:33 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:09:33 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:09:33 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:09:33 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:09:33 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:09:33 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:09:33 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:45061] &lt;- [akka.tcp://sparkExecutor@hcdnc326:50019]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc326:50019] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc326:50019%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:33 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:45061] &lt;- [akka.tcp://sparkExecutor@hcdnc823:52848]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc823:52848] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc823:52848%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:09:33 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:09:33 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:09:33 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:09:33 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:09:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:09:33 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:09:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-3b474b11-f20f-4c9d-94f5-3b5704a8eb39%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:09:48 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:09:48 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:09:48 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:09:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:09:49 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:09:50 INFO Remoting: Starting remoting%%0001017/07/18 02:09:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46308]%%0001017/07/18 02:09:50 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46308]%%0001017/07/18 02:09:50 INFO Utils: Successfully started service 'sparkDriver' on port 46308.%%0001017/07/18 02:09:50 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:09:50 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:09:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2b8bc556-3b37-4caa-89fb-d0d3992ba847%%0001017/07/18 02:09:50 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:09:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ff179f29-d662-45a9-a20b-532fe58d864b/httpd-dad4a19f-bb92-4275-92ca-4fec3ec05295%%0001017/07/18 02:09:50 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:09:50 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:09:50 INFO AbstractConnector: Started SocketConnector@0.0.0.0:43039%%0001017/07/18 02:09:50 INFO Utils: Successfully started service 'HTTP file server' on port 43039.%%0001017/07/18 02:09:50 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:09:50 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:09:50 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:09:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:09:50 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:09:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:09:51 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:09:51 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:09:51 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:09:51 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:09:51 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:09:51 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:09:51 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:09:51 INFO Client: Uploading resource file:/tmp/spark-ff179f29-d662-45a9-a20b-532fe58d864b/__spark_conf__8059959403224073288.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22142/__spark_conf__8059959403224073288.zip%%0001017/07/18 02:09:51 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:09:51 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:09:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:09:51 INFO Client: Submitting application 22142 to ResourceManager%%0001017/07/18 02:09:52 INFO YarnClientImpl: Submitted application application_1491786134915_22142%%0001017/07/18 02:09:53 INFO Client: Application report for application_1491786134915_22142 (state: ACCEPTED)%%0001017/07/18 02:09:53 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314991981%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22142/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:09:54 INFO Client: Application report for application_1491786134915_22142 (state: ACCEPTED)%%0001017/07/18 02:09:55 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:54857/user/YarnAM#-1229027297])%%0001017/07/18 02:09:55 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22142,http://hcnnc117:8088/proxy/application_1491786134915_22142), /proxy/application_1491786134915_22142%%0001017/07/18 02:09:55 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:09:55 INFO Client: Application report for application_1491786134915_22142 (state: RUNNING)%%0001017/07/18 02:09:55 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314991981%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22142/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:09:55 INFO YarnClientSchedulerBackend: Application application_1491786134915_22142 has started running.%%0001017/07/18 02:09:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40445.%%0001017/07/18 02:09:55 INFO NettyBlockTransferService: Server created on 40445%%0001017/07/18 02:09:55 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:09:55 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:09:55 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:40445 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 40445)%%0001017/07/18 02:09:55 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:09:55 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22142%%0001017/07/18 02:09:55 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:09:56 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:09:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:09:56 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:09:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:09:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:40445 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:09:56 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:09:56 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:09:56 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:09:56 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:09:56 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:09:56 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:09:56 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:09:56 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:09:56 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:09:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:09:56 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:09:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:09:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:40445 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:09:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:09:56 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:09:57 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:09:58 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:10:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46308] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:40691]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:40691] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:40691%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:00 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:53210/user/Executor#88896149]) with ID 1%%0001017/07/18 02:10:00 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:10:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:10:00 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:47245 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 47245)%%0001017/07/18 02:10:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46308] &lt;- [akka.tcp://driverPropsFetcher@hcdnc301:39652]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc301:39652] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc301:39652%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:47245 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:01 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc301:52322/user/Executor#1555975613]) with ID 2%%0001017/07/18 02:10:01 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:10:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc301, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:10:01 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc301:39995 with 530.0 MB RAM, BlockManagerId(2, hcdnc301, 39995)%%0001017/07/18 02:10:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:47245 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc301:39995 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc301:39995 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1733 ms on hcdnc310 (1/2)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1837 ms on hcdnc301 (2/2)%%0001017/07/18 02:10:03 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.411 s%%0001017/07/18 02:10:03 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:03 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.535008 s%%0001017/07/18 02:10:03 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:10:03 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:10:03 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:10:03 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:10:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:40445 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:10:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:10:03 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc301, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc301:39995 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:47245 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 283 ms on hcdnc310 (1/2)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 316 ms on hcdnc301 (2/2)%%0001017/07/18 02:10:03 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.318 s%%0001017/07/18 02:10:03 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:03 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:03 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:03 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:10:03 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:03 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251391, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258327, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:40445 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:10:03 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:10:03 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc301, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:47245 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc301:39995 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc301:52322%%0001017/07/18 02:10:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:10:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:53210%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 92 ms on hcdnc301 (1/2)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 99 ms on hcdnc310 (2/2)%%0001017/07/18 02:10:03 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.099 s%%0001017/07/18 02:10:03 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:03 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.449481 s%%0001017/07/18 02:10:03 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:10:03 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:10:03 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:10:03 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:10:03 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262370, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268890, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:40445 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:10:03 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:10:03 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc301, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:47245 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc301:39995 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 98 ms on hcdnc301 (1/2)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 103 ms on hcdnc310 (2/2)%%0001017/07/18 02:10:03 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:03 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.103 s%%0001017/07/18 02:10:03 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.117180 s%%0001017/07/18 02:10:03 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:10:03 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:10:03 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:10:03 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:10:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272792, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279968, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:40445 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:10:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:10:03 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc301, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc301:39995 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:47245 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 176 ms on hcdnc301 (1/2)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 195 ms on hcdnc310 (2/2)%%0001017/07/18 02:10:04 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:04 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.196 s%%0001017/07/18 02:10:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:04 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:04 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:10:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:04 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284117, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286901, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:40445 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:10:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:10:04 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc301, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:47245 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc301:39995 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:53210%%0001017/07/18 02:10:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 173 bytes%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc301:52322%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 42 ms on hcdnc310 (1/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc301, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc301 (2/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc310 (3/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc301, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc301 (4/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 20 ms on hcdnc310 (5/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc301, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc301 (6/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 18 ms on hcdnc310 (7/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc301, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc301 (8/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc310 (9/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc301 (10/10)%%0001017/07/18 02:10:04 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.107 s%%0001017/07/18 02:10:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:04 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.324186 s%%0001017/07/18 02:10:04 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:10:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:10:04 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:10:04 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:10:04 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:10:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:10:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(13536) called with curMem=288514, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(7475) called with curMem=302050, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.3 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:40445 (size: 7.3 KB, free: 530.2 MB)%%0001017/07/18 02:10:04 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:10:04 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc301, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:47245 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc301:39995 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc301:52322%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:53210%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 386 ms on hcdnc301 (1/2)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 402 ms on hcdnc310 (2/2)%%0001017/07/18 02:10:04 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:04 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.404 s%%0001017/07/18 02:10:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:04 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:04 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:10:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:04 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(16760) called with curMem=309525, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.4 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(8915) called with curMem=326285, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.7 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:40445 (size: 8.7 KB, free: 530.2 MB)%%0001017/07/18 02:10:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:10:04 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc301, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc301:39995 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:47245 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc301:52322%%0001017/07/18 02:10:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:53210%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 102 ms on hcdnc310 (1/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc301, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 109 ms on hcdnc301 (2/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 55 ms on hcdnc310 (3/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc301, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 56 ms on hcdnc301 (4/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 60 ms on hcdnc310 (5/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc301, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 54 ms on hcdnc301 (6/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 54 ms on hcdnc310 (7/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc301, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 55 ms on hcdnc301 (8/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 53 ms on hcdnc310 (9/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 57 ms on hcdnc301 (10/10)%%0001017/07/18 02:10:04 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:04 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.328 s%%0001017/07/18 02:10:04 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.759719 s%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:10:05 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:10:05 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:10:05 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:10:05 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:10:05 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:10:05 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:10:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46308] &lt;- [akka.tcp://sparkExecutor@hcdnc310:53210]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:53210] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:53210%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46308] &lt;- [akka.tcp://sparkExecutor@hcdnc301:52322]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc301:52322] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc301:52322%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:10:05 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:10:05 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:10:05 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:10:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:10:05 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:10:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 02:10:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 02:10:05 INFO Remoting: Remoting shut down%%0001017/07/18 02:10:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 02:10:06 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:10:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-ff179f29-d662-45a9-a20b-532fe58d864b%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:10:19 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:10:19 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:10:19 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:10:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:10:20 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:10:20 INFO Remoting: Starting remoting%%0001017/07/18 02:10:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37824]%%0001017/07/18 02:10:20 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37824]%%0001017/07/18 02:10:20 INFO Utils: Successfully started service 'sparkDriver' on port 37824.%%0001017/07/18 02:10:20 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:10:20 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:10:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7bcfbfe0-bf9a-4a37-a5ba-3c1b3a4e5890%%0001017/07/18 02:10:20 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:10:21 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b46ef068-ee07-40f5-922a-7490967da790/httpd-369dcdc8-4fa9-4ee0-9e2e-66c5a01d2ab7%%0001017/07/18 02:10:21 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:10:21 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:10:21 INFO AbstractConnector: Started SocketConnector@0.0.0.0:39805%%0001017/07/18 02:10:21 INFO Utils: Successfully started service 'HTTP file server' on port 39805.%%0001017/07/18 02:10:21 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:10:21 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:10:21 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:10:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:10:21 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:10:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:10:21 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:10:21 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:10:21 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:10:21 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:10:21 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:10:21 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:10:21 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:10:22 INFO Client: Uploading resource file:/tmp/spark-b46ef068-ee07-40f5-922a-7490967da790/__spark_conf__8407631999212019635.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22143/__spark_conf__8407631999212019635.zip%%0001017/07/18 02:10:22 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:10:22 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:10:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:10:22 INFO Client: Submitting application 22143 to ResourceManager%%0001017/07/18 02:10:22 INFO YarnClientImpl: Submitted application application_1491786134915_22143%%0001017/07/18 02:10:23 INFO Client: Application report for application_1491786134915_22143 (state: ACCEPTED)%%0001017/07/18 02:10:23 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500315022752%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22143/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:10:24 INFO Client: Application report for application_1491786134915_22143 (state: ACCEPTED)%%0001017/07/18 02:10:25 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.3.32:49034/user/YarnAM#-1023086785])%%0001017/07/18 02:10:25 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22143,http://hcnnc117:8088/proxy/application_1491786134915_22143), /proxy/application_1491786134915_22143%%0001017/07/18 02:10:25 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:10:25 INFO Client: Application report for application_1491786134915_22143 (state: RUNNING)%%0001017/07/18 02:10:25 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.3.32%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500315022752%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22143/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:10:25 INFO YarnClientSchedulerBackend: Application application_1491786134915_22143 has started running.%%0001017/07/18 02:10:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44328.%%0001017/07/18 02:10:26 INFO NettyBlockTransferService: Server created on 44328%%0001017/07/18 02:10:26 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:10:26 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:10:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:44328 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 44328)%%0001017/07/18 02:10:26 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:10:26 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22143%%0001017/07/18 02:10:26 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:10:27 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:10:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:10:27 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:10:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:10:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:44328 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:10:27 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:10:27 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:10:27 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:10:27 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:10:27 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:10:27 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:10:27 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:10:27 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:10:27 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:10:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:10:27 INFO MemoryStore: ensureFreeSpace(3981) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:10:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:10:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:44328 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:10:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:10:27 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:10:28 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:10:29 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:10:31 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37824] &lt;- [akka.tcp://driverPropsFetcher@hcdnc325:44198]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc325:44198] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc325:44198%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:31 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc325:34475/user/Executor#1671317118]) with ID 1%%0001017/07/18 02:10:31 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:10:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc325, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:10:31 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc325:60273 with 530.0 MB RAM, BlockManagerId(1, hcdnc325, 60273)%%0001017/07/18 02:10:31 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37824] &lt;- [akka.tcp://driverPropsFetcher@hcdnc319:38029]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc319:38029] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc319:38029%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc325:60273 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:32 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc319:45425/user/Executor#502697426]) with ID 2%%0001017/07/18 02:10:32 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:10:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc319, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:10:32 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc319:40647 with 530.0 MB RAM, BlockManagerId(2, hcdnc319, 40647)%%0001017/07/18 02:10:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc325:60273 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc319:40647 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc319:40647 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1746 ms on hcdnc325 (1/2)%%0001017/07/18 02:10:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1895 ms on hcdnc319 (2/2)%%0001017/07/18 02:10:33 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.474 s%%0001017/07/18 02:10:33 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:33 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.597935 s%%0001017/07/18 02:10:33 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:10:33 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:10:33 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:10:33 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:10:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:10:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:10:33 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237417, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246081, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:44328 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc319, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc325, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc319:40647 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc325:60273 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 274 ms on hcdnc325 (1/2)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 334 ms on hcdnc319 (2/2)%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.334 s%%0001017/07/18 02:10:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:34 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:34 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:10:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:34 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251392, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258328, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:44328 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc319, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc325:60273 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc319:40647 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc319:45425%%0001017/07/18 02:10:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:10:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc325:34475%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 101 ms on hcdnc319 (1/2)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 104 ms on hcdnc325 (2/2)%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.105 s%%0001017/07/18 02:10:34 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.471359 s%%0001017/07/18 02:10:34 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:10:34 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:10:34 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:10:34 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:10:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:10:34 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262371, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268891, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:44328 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc319, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc319:40647 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc325:60273 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 89 ms on hcdnc319 (1/2)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 103 ms on hcdnc325 (2/2)%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.104 s%%0001017/07/18 02:10:34 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.117637 s%%0001017/07/18 02:10:34 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:10:34 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:10:34 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:10:34 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:10:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:10:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272793, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279969, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:44328 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc325, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc319, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc319:40647 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc325:60273 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 182 ms on hcdnc325 (1/2)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 184 ms on hcdnc319 (2/2)%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.186 s%%0001017/07/18 02:10:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:34 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:34 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:10:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:34 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284118, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286902, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:44328 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc325, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc319, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc319:40647 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc325:60273 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc319:45425%%0001017/07/18 02:10:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 173 bytes%%0001017/07/18 02:10:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc325:34475%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc319, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 43 ms on hcdnc319 (1/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc325, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 46 ms on hcdnc325 (2/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc319, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc319 (3/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc325, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc325 (4/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc319, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc319 (5/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc325, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc325 (6/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc319, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc319 (7/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc325, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc325 (8/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc319 (9/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc325 (10/10)%%0001017/07/18 02:10:34 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.310260 s%%0001017/07/18 02:10:35 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:10:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:10:35 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:10:35 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:10:35 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:10:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:10:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:10:35 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:10:35 INFO MemoryStore: ensureFreeSpace(13536) called with curMem=288515, maxMem=556038881%%0001017/07/18 02:10:35 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 530.0 MB)%%0001017/07/18 02:10:35 INFO MemoryStore: ensureFreeSpace(7475) called with curMem=302051, maxMem=556038881%%0001017/07/18 02:10:35 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.3 KB, free 530.0 MB)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:44328 (size: 7.3 KB, free: 530.2 MB)%%0001017/07/18 02:10:35 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:10:35 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc325, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc319, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc319:40647 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc325:60273 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc325:34475%%0001017/07/18 02:10:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc319:45425%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 351 ms on hcdnc319 (1/2)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 391 ms on hcdnc325 (2/2)%%0001017/07/18 02:10:35 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:35 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.393 s%%0001017/07/18 02:10:35 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:35 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:35 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:10:35 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:35 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:10:35 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:10:35 INFO MemoryStore: ensureFreeSpace(16760) called with curMem=309526, maxMem=556038881%%0001017/07/18 02:10:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.4 KB, free 530.0 MB)%%0001017/07/18 02:10:35 INFO MemoryStore: ensureFreeSpace(8913) called with curMem=326286, maxMem=556038881%%0001017/07/18 02:10:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.7 KB, free 530.0 MB)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:44328 (size: 8.7 KB, free: 530.2 MB)%%0001017/07/18 02:10:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:35 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:10:35 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc319, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc319:40647 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc325:60273 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:10:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc325:34475%%0001017/07/18 02:10:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 02:10:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc319:45425%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc319, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 96 ms on hcdnc319 (1/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc325, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 98 ms on hcdnc325 (2/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc319, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 54 ms on hcdnc319 (3/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc325, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 57 ms on hcdnc325 (4/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc319, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 53 ms on hcdnc319 (5/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc325, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 55 ms on hcdnc325 (6/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc319, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 53 ms on hcdnc319 (7/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc325, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 54 ms on hcdnc325 (8/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 54 ms on hcdnc319 (9/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 55 ms on hcdnc325 (10/10)%%0001017/07/18 02:10:35 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:35 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.315 s%%0001017/07/18 02:10:35 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.737413 s%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:10:35 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:10:35 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:10:35 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:10:35 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:10:35 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:10:35 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:10:35 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37824] &lt;- [akka.tcp://sparkExecutor@hcdnc325:34475]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc325:34475] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc325:34475%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:35 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37824] &lt;- [akka.tcp://sparkExecutor@hcdnc319:45425]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc319:45425] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc319:45425%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:10:36 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:10:36 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:10:36 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:10:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:10:36 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:10:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 02:10:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 02:10:36 INFO Remoting: Remoting shut down%%0001017/07/18 02:10:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 02:10:36 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:10:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-b46ef068-ee07-40f5-922a-7490967da790%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:10:49 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:10:51 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:10:51 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:10:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:10:51 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:10:52 INFO Remoting: Starting remoting%%0001017/07/18 02:10:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46227]%%0001017/07/18 02:10:52 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46227]%%0001017/07/18 02:10:52 INFO Utils: Successfully started service 'sparkDriver' on port 46227.%%0001017/07/18 02:10:52 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:10:52 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:10:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b9df1c7f-97f7-446a-a5d1-ba8db74051a8%%0001017/07/18 02:10:52 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:10:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-07e76fee-4365-4c0e-b73b-e8f96d35cb4b/httpd-c3d4dd9c-5934-4fd9-9a74-dd00b3bef31d%%0001017/07/18 02:10:52 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:10:52 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:10:52 INFO AbstractConnector: Started SocketConnector@0.0.0.0:40992%%0001017/07/18 02:10:52 INFO Utils: Successfully started service 'HTTP file server' on port 40992.%%0001017/07/18 02:10:52 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:10:52 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:10:52 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:10:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:10:52 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:10:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:10:52 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:10:52 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:10:52 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:10:52 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:10:52 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:10:52 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:10:53 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:10:53 INFO Client: Uploading resource file:/tmp/spark-07e76fee-4365-4c0e-b73b-e8f96d35cb4b/__spark_conf__1527539359832699766.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22144/__spark_conf__1527539359832699766.zip%%0001017/07/18 02:10:54 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:10:54 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:10:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:10:54 INFO Client: Submitting application 22144 to ResourceManager%%0001017/07/18 02:10:54 INFO YarnClientImpl: Submitted application application_1491786134915_22144%%0001017/07/18 02:10:55 INFO Client: Application report for application_1491786134915_22144 (state: ACCEPTED)%%0001017/07/18 02:10:55 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500315054298%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22144/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:10:56 INFO Client: Application report for application_1491786134915_22144 (state: ACCEPTED)%%0001017/07/18 02:10:57 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:35918/user/YarnAM#1415268613])%%0001017/07/18 02:10:57 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22144,http://hcnnc117:8088/proxy/application_1491786134915_22144), /proxy/application_1491786134915_22144%%0001017/07/18 02:10:57 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:10:57 INFO Client: Application report for application_1491786134915_22144 (state: RUNNING)%%0001017/07/18 02:10:57 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500315054298%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22144/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:10:57 INFO YarnClientSchedulerBackend: Application application_1491786134915_22144 has started running.%%0001017/07/18 02:10:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40745.%%0001017/07/18 02:10:57 INFO NettyBlockTransferService: Server created on 40745%%0001017/07/18 02:10:57 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:10:57 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:10:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:40745 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 40745)%%0001017/07/18 02:10:57 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:10:58 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22144%%0001017/07/18 02:10:58 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:10:58 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:10:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:10:58 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:10:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:10:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:40745 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:10:58 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:10:58 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:10:58 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:10:58 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:10:58 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:10:58 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:10:58 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:10:58 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:10:58 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:10:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:10:58 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:10:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:10:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:40745 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:10:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:10:58 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:11:00 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:11:01 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:11:02 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46227] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:36304]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:36304] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:36304%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:11:02 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:57670/user/Executor#-901421741]) with ID 1%%0001017/07/18 02:11:02 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:11:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:11:03 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:39153 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 39153)%%0001017/07/18 02:11:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:39153 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:11:03 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46227] &lt;- [akka.tcp://driverPropsFetcher@hcdnc339:60520]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc339:60520] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc339:60520%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:11:03 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc339:50492/user/Executor#-315769020]) with ID 2%%0001017/07/18 02:11:03 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:11:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc339, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:11:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:39153 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:11:03 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc339:50577 with 530.0 MB RAM, BlockManagerId(2, hcdnc339, 50577)%%0001017/07/18 02:11:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc339:50577 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:11:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1630 ms on hcdnc310 (1/2)%%0001017/07/18 02:11:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc339:50577 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1808 ms on hcdnc339 (2/2)%%0001017/07/18 02:11:05 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.421 s%%0001017/07/18 02:11:05 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:05 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.544384 s%%0001017/07/18 02:11:05 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:11:05 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:11:05 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:11:05 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:11:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:11:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:11:05 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:11:05 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:11:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:11:05 INFO MemoryStore: ensureFreeSpace(5313) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:11:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:40745 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:11:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:11:05 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:11:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:11:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc339, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc339:50577 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:39153 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 285 ms on hcdnc339 (1/2)%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 331 ms on hcdnc310 (2/2)%%0001017/07/18 02:11:05 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:05 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.332 s%%0001017/07/18 02:11:05 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:11:05 INFO DAGScheduler: running: Set()%%0001017/07/18 02:11:05 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:11:05 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:11:05 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:11:05 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:11:05 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251393, maxMem=556038881%%0001017/07/18 02:11:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:11:05 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258329, maxMem=556038881%%0001017/07/18 02:11:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:40745 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:11:05 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:11:05 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:11:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc339, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:39153 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc339:50577 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:57670%%0001017/07/18 02:11:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:11:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc339:50492%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on hcdnc310 (1/2)%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 97 ms on hcdnc339 (2/2)%%0001017/07/18 02:11:05 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:05 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.099 s%%0001017/07/18 02:11:05 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.463175 s%%0001017/07/18 02:11:06 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:11:06 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:11:06 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:11:06 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:11:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262372, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268892, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:40745 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:11:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:11:06 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc339, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc339:50577 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:39153 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 106 ms on hcdnc339 (1/2)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 106 ms on hcdnc310 (2/2)%%0001017/07/18 02:11:06 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.108 s%%0001017/07/18 02:11:06 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:06 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.120617 s%%0001017/07/18 02:11:06 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:11:06 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:11:06 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:11:06 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:11:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272794, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=279970, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:40745 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:11:06 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:11:06 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc339, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc339:50577 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:39153 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 205 ms on hcdnc310 (1/2)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 228 ms on hcdnc339 (2/2)%%0001017/07/18 02:11:06 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:06 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.229 s%%0001017/07/18 02:11:06 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:11:06 INFO DAGScheduler: running: Set()%%0001017/07/18 02:11:06 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:11:06 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284118, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286902, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:40745 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:11:06 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:11:06 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc339, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:39153 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc339:50577 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:57670%%0001017/07/18 02:11:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 173 bytes%%0001017/07/18 02:11:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc339:50492%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 41 ms on hcdnc310 (1/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc339, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 52 ms on hcdnc339 (2/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc310 (3/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc339, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc339 (4/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc310 (5/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc339, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc310 (6/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 22 ms on hcdnc339 (7/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc339, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc339 (8/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc310 (9/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc339 (10/10)%%0001017/07/18 02:11:06 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.111 s%%0001017/07/18 02:11:06 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:06 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.360823 s%%0001017/07/18 02:11:06 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:11:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:11:06 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:11:06 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:11:06 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:11:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(13536) called with curMem=288515, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(7475) called with curMem=302051, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.3 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:40745 (size: 7.3 KB, free: 530.2 MB)%%0001017/07/18 02:11:06 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:11:06 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc339, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:39153 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc339:50577 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:57670%%0001017/07/18 02:11:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc339:50492%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 392 ms on hcdnc310 (1/2)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 393 ms on hcdnc339 (2/2)%%0001017/07/18 02:11:06 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:06 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.395 s%%0001017/07/18 02:11:06 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:11:06 INFO DAGScheduler: running: Set()%%0001017/07/18 02:11:06 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:11:06 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:11:07 INFO MemoryStore: ensureFreeSpace(16760) called with curMem=309526, maxMem=556038881%%0001017/07/18 02:11:07 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.4 KB, free 530.0 MB)%%0001017/07/18 02:11:07 INFO MemoryStore: ensureFreeSpace(8913) called with curMem=326286, maxMem=556038881%%0001017/07/18 02:11:07 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.7 KB, free 530.0 MB)%%0001017/07/18 02:11:07 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:40745 (size: 8.7 KB, free: 530.2 MB)%%0001017/07/18 02:11:07 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:07 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:11:07 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc339, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:39153 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:11:07 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc339:50577 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:11:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:57670%%0001017/07/18 02:11:07 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 02:11:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc339:50492%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 97 ms on hcdnc310 (1/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc339, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 99 ms on hcdnc339 (2/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 55 ms on hcdnc310 (3/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc339, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 54 ms on hcdnc339 (4/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 52 ms on hcdnc310 (5/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc339, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 55 ms on hcdnc339 (6/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc339, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 53 ms on hcdnc339 (7/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 63 ms on hcdnc310 (8/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 54 ms on hcdnc339 (9/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 55 ms on hcdnc310 (10/10)%%0001017/07/18 02:11:07 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:07 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.316 s%%0001017/07/18 02:11:07 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.736539 s%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:11:07 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:11:07 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:11:07 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:11:07 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:11:07 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:11:07 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:11:07 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46227] &lt;- [akka.tcp://sparkExecutor@hcdnc310:57670]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:57670] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:57670%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:11:07 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46227] &lt;- [akka.tcp://sparkExecutor@hcdnc339:50492]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc339:50492] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc339:50492%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:11:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:11:07 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:11:07 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:11:07 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:11:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:11:07 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:11:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 02:11:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 02:11:07 INFO Remoting: Remoting shut down%%0001017/07/18 02:11:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 02:11:08 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:11:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-07e76fee-4365-4c0e-b73b-e8f96d35cb4b%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_1">
<entry key="column_name" type="xstring" value="FailingNodeMessage"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="6"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:08:11 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:08:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:08:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:08:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:08:12 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:08:12 INFO Remoting: Starting remoting%%0001017/07/18 02:08:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46473]%%0001017/07/18 02:08:12 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46473]%%0001017/07/18 02:08:12 INFO Utils: Successfully started service 'sparkDriver' on port 46473.%%0001017/07/18 02:08:12 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:08:12 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:08:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-61cb6407-a356-4d08-8afd-66d83e794b50%%0001017/07/18 02:08:12 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:08:13 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b037b803-129d-4de1-b623-352fe8384519/httpd-4461f793-693a-4a3d-9ee6-d3c070936523%%0001017/07/18 02:08:13 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:08:13 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:08:13 INFO AbstractConnector: Started SocketConnector@0.0.0.0:37752%%0001017/07/18 02:08:13 INFO Utils: Successfully started service 'HTTP file server' on port 37752.%%0001017/07/18 02:08:13 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:08:13 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:08:13 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:08:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:08:13 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:08:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:08:14 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:08:14 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:08:14 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:08:14 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:08:14 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:08:14 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:08:14 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:08:14 INFO Client: Uploading resource file:/tmp/spark-b037b803-129d-4de1-b623-352fe8384519/__spark_conf__3959330619433399621.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22139/__spark_conf__3959330619433399621.zip%%0001017/07/18 02:08:14 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:08:14 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:08:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:08:14 INFO Client: Submitting application 22139 to ResourceManager%%0001017/07/18 02:08:15 INFO YarnClientImpl: Submitted application application_1491786134915_22139%%0001017/07/18 02:08:16 INFO Client: Application report for application_1491786134915_22139 (state: ACCEPTED)%%0001017/07/18 02:08:16 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314894880%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22139/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:08:17 INFO Client: Application report for application_1491786134915_22139 (state: ACCEPTED)%%0001017/07/18 02:08:17 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:36856/user/YarnAM#1533634657])%%0001017/07/18 02:08:17 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22139,http://hcnnc117:8088/proxy/application_1491786134915_22139), /proxy/application_1491786134915_22139%%0001017/07/18 02:08:17 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:08:18 INFO Client: Application report for application_1491786134915_22139 (state: RUNNING)%%0001017/07/18 02:08:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314894880%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22139/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:08:18 INFO YarnClientSchedulerBackend: Application application_1491786134915_22139 has started running.%%0001017/07/18 02:08:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36689.%%0001017/07/18 02:08:18 INFO NettyBlockTransferService: Server created on 36689%%0001017/07/18 02:08:18 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:08:18 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:08:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:36689 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 36689)%%0001017/07/18 02:08:18 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:08:19 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22139%%0001017/07/18 02:08:19 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:08:19 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:08:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:08:19 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:08:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:08:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:36689 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:08:19 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:08:19 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:08:20 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:08:20 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:08:20 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:08:20 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:08:20 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:08:20 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:08:20 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:08:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:08:20 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:08:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:08:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:36689 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:08:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:08:20 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:08:21 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:08:22 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:08:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46473] &lt;- [akka.tcp://driverPropsFetcher@hcdnc318:45434]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc318:45434] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc318:45434%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:24 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc318:51042/user/Executor#96535585]) with ID 1%%0001017/07/18 02:08:24 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:08:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc318, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:08:24 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc318:46705 with 530.0 MB RAM, BlockManagerId(1, hcdnc318, 46705)%%0001017/07/18 02:08:24 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46473] &lt;- [akka.tcp://driverPropsFetcher@hcdnc835:46825]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc835:46825] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc835:46825%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc318:46705 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:24 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc835:32795/user/Executor#-1278415339]) with ID 2%%0001017/07/18 02:08:24 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:08:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc835, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:08:24 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc835:39227 with 530.0 MB RAM, BlockManagerId(2, hcdnc835, 39227)%%0001017/07/18 02:08:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc318:46705 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:08:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc835:39227 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc835:39227 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:08:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1751 ms on hcdnc318 (1/2)%%0001017/07/18 02:08:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1806 ms on hcdnc835 (2/2)%%0001017/07/18 02:08:26 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.412 s%%0001017/07/18 02:08:26 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:26 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.535779 s%%0001017/07/18 02:08:26 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:08:26 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:08:26 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:08:26 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:08:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:08:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:08:26 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:08:26 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:08:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:08:26 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:08:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:36689 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:08:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:08:26 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:08:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc318, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:08:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc835, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc318:46705 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc835:39227 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:08:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 277 ms on hcdnc835 (1/2)%%0001017/07/18 02:08:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 322 ms on hcdnc318 (2/2)%%0001017/07/18 02:08:26 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.323 s%%0001017/07/18 02:08:26 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:26 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:26 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:26 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:08:26 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:26 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:08:26 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:08:26 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251391, maxMem=556038881%%0001017/07/18 02:08:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:08:26 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258327, maxMem=556038881%%0001017/07/18 02:08:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:36689 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:08:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:08:26 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:08:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc318, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc835, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc318:46705 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc835:39227 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc835:32795%%0001017/07/18 02:08:26 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 02:08:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc318:51042%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 89 ms on hcdnc835 (1/2)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 102 ms on hcdnc318 (2/2)%%0001017/07/18 02:08:27 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.103 s%%0001017/07/18 02:08:27 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:27 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.458226 s%%0001017/07/18 02:08:27 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:08:27 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:08:27 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:08:27 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:08:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:08:27 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262370, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268890, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:36689 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:08:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:08:27 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc835, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc318, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc835:39227 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc318:46705 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 101 ms on hcdnc318 (1/2)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 110 ms on hcdnc835 (2/2)%%0001017/07/18 02:08:27 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.110 s%%0001017/07/18 02:08:27 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:27 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.124875 s%%0001017/07/18 02:08:27 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:08:27 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:08:27 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:08:27 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:08:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:08:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272792, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279968, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:36689 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:08:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:08:27 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc318, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc835, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc318:46705 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc835:39227 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 184 ms on hcdnc318 (1/2)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 195 ms on hcdnc835 (2/2)%%0001017/07/18 02:08:27 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:27 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.196 s%%0001017/07/18 02:08:27 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:27 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:27 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:08:27 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:27 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284117, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286901, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:36689 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:08:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:08:27 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc835, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc318, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc318:46705 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc835:39227 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc318:51042%%0001017/07/18 02:08:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 174 bytes%%0001017/07/18 02:08:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc835:32795%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc318, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc835, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc318 (1/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc835 (2/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc318, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc835, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc318 (3/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc835 (4/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc835, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc318, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc835 (5/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 22 ms on hcdnc318 (6/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc318, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc835, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 17 ms on hcdnc318 (7/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 20 ms on hcdnc835 (8/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc835 (9/10)%%0001017/07/18 02:08:27 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc318 (10/10)%%0001017/07/18 02:08:27 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.111 s%%0001017/07/18 02:08:27 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:27 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.329830 s%%0001017/07/18 02:08:27 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:08:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 02:08:27 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:08:27 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:08:27 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:08:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:08:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(14512) called with curMem=288514, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.2 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO MemoryStore: ensureFreeSpace(8051) called with curMem=303026, maxMem=556038881%%0001017/07/18 02:08:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.9 KB, free 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:36689 (size: 7.9 KB, free: 530.2 MB)%%0001017/07/18 02:08:27 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:08:27 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc835, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:27 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc318, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc835:39227 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc318:46705 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc835:32795%%0001017/07/18 02:08:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc318:51042%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 424 ms on hcdnc318 (1/2)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 455 ms on hcdnc835 (2/2)%%0001017/07/18 02:08:28 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:28 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.456 s%%0001017/07/18 02:08:28 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:28 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:28 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:08:28 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:28 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:08:28 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:08:28 INFO MemoryStore: ensureFreeSpace(17944) called with curMem=311077, maxMem=556038881%%0001017/07/18 02:08:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 530.0 MB)%%0001017/07/18 02:08:28 INFO MemoryStore: ensureFreeSpace(9629) called with curMem=329021, maxMem=556038881%%0001017/07/18 02:08:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 530.0 MB)%%0001017/07/18 02:08:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:36689 (size: 9.4 KB, free: 530.2 MB)%%0001017/07/18 02:08:28 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:28 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:08:28 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc318, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc835, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc835:39227 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:08:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc318:46705 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:08:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc835:32795%%0001017/07/18 02:08:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 02:08:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc318:51042%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc835, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 108 ms on hcdnc835 (1/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc318, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 133 ms on hcdnc318 (2/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc835, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 56 ms on hcdnc835 (3/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc318, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 64 ms on hcdnc318 (4/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc835, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 55 ms on hcdnc835 (5/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc835, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 54 ms on hcdnc835 (6/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc318, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 83 ms on hcdnc318 (7/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc835, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 54 ms on hcdnc835 (8/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 53 ms on hcdnc318 (9/10)%%0001017/07/18 02:08:28 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 68 ms on hcdnc835 (10/10)%%0001017/07/18 02:08:28 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:28 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.392 s%%0001017/07/18 02:08:28 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.884791 s%%0001017/07/18 02:08:28 INFO SparkContext: Invoking stop() from shutdown hook%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:08:28 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:08:28 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:08:28 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:08:28 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:08:28 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:08:28 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:08:28 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:08:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46473] &lt;- [akka.tcp://sparkExecutor@hcdnc318:51042]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc318:51042] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc318:51042%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46473] &lt;- [akka.tcp://sparkExecutor@hcdnc835:32795]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc835:32795] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc835:32795%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:08:28 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:08:28 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:08:28 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:08:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:08:28 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:08:28 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:08:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-b037b803-129d-4de1-b623-352fe8384519/pyspark-7ab780e3-2bac-4af7-aaad-cfe5e81a32b9%%0001017/07/18 02:08:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-b037b803-129d-4de1-b623-352fe8384519%%00010"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:08:43 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:08:43 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:08:43 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:08:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:08:44 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:08:44 INFO Remoting: Starting remoting%%0001017/07/18 02:08:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:35862]%%0001017/07/18 02:08:44 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:35862]%%0001017/07/18 02:08:44 INFO Utils: Successfully started service 'sparkDriver' on port 35862.%%0001017/07/18 02:08:44 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:08:44 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:08:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8890d7ac-cc18-4962-825f-fd2081f00b90%%0001017/07/18 02:08:44 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:08:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-62698cb2-d96f-409f-9f5b-ddefa1843123/httpd-8521f33c-e24e-4cac-bfb3-2a0cab705c7e%%0001017/07/18 02:08:44 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:08:44 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:08:44 INFO AbstractConnector: Started SocketConnector@0.0.0.0:41856%%0001017/07/18 02:08:44 INFO Utils: Successfully started service 'HTTP file server' on port 41856.%%0001017/07/18 02:08:44 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:08:44 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:08:45 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:08:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:08:45 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:08:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:08:46 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:08:46 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:08:46 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:08:46 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:08:46 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:08:46 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:08:46 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:08:46 INFO Client: Uploading resource file:/tmp/spark-62698cb2-d96f-409f-9f5b-ddefa1843123/__spark_conf__3258497662408211574.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22140/__spark_conf__3258497662408211574.zip%%0001017/07/18 02:08:46 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:08:46 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:08:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:08:46 INFO Client: Submitting application 22140 to ResourceManager%%0001017/07/18 02:08:47 INFO YarnClientImpl: Submitted application application_1491786134915_22140%%0001017/07/18 02:08:48 INFO Client: Application report for application_1491786134915_22140 (state: ACCEPTED)%%0001017/07/18 02:08:48 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314926893%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22140/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:08:49 INFO Client: Application report for application_1491786134915_22140 (state: ACCEPTED)%%0001017/07/18 02:08:50 INFO Client: Application report for application_1491786134915_22140 (state: ACCEPTED)%%0001017/07/18 02:08:50 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:53899/user/YarnAM#-466894763])%%0001017/07/18 02:08:50 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22140,http://hcnnc117:8088/proxy/application_1491786134915_22140), /proxy/application_1491786134915_22140%%0001017/07/18 02:08:50 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:08:51 INFO Client: Application report for application_1491786134915_22140 (state: RUNNING)%%0001017/07/18 02:08:51 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314926893%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22140/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:08:51 INFO YarnClientSchedulerBackend: Application application_1491786134915_22140 has started running.%%0001017/07/18 02:08:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35338.%%0001017/07/18 02:08:51 INFO NettyBlockTransferService: Server created on 35338%%0001017/07/18 02:08:51 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:08:51 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:08:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:35338 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 35338)%%0001017/07/18 02:08:51 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:08:51 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22140%%0001017/07/18 02:08:51 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:08:51 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:08:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:08:51 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:08:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:08:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:35338 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:08:51 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:08:52 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:08:52 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:08:52 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:08:52 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:08:52 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:08:52 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:08:52 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:08:52 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:08:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:08:52 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:08:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:08:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:35338 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:08:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:08:52 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:08:53 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:08:54 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:08:55 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:35862] &lt;- [akka.tcp://driverPropsFetcher@hcdnc332:33394]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc332:33394] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc332:33394%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:56 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc332:44468/user/Executor#1978266903]) with ID 1%%0001017/07/18 02:08:56 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:08:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc332, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:08:56 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc332:48676 with 530.0 MB RAM, BlockManagerId(1, hcdnc332, 48676)%%0001017/07/18 02:08:56 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:35862] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:45068]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:45068] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:45068%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:08:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc332:48676 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:56 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:56792/user/Executor#-875278384]) with ID 2%%0001017/07/18 02:08:56 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:08:56 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:08:56 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:42885 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 42885)%%0001017/07/18 02:08:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc332:48676 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:08:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:42885 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:42885 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:08:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1681 ms on hcdnc332 (1/2)%%0001017/07/18 02:08:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1822 ms on hcdnc310 (2/2)%%0001017/07/18 02:08:58 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.404 s%%0001017/07/18 02:08:58 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:58 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.533883 s%%0001017/07/18 02:08:58 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:08:58 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:08:58 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:08:58 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:08:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:08:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:08:58 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:08:58 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:08:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:08:58 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:08:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:08:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:35338 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:08:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:08:58 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:08:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc332, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:08:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:08:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc332:48676 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:08:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:42885 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 333 ms on hcdnc332 (1/2)%%0001017/07/18 02:08:59 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.349 s%%0001017/07/18 02:08:59 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 347 ms on hcdnc310 (2/2)%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:59 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:08:59 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251391, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(4044) called with curMem=258327, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:35338 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc332:48676 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:42885 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc332:44468%%0001017/07/18 02:08:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:56792%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 102 ms on hcdnc310 (1/2)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 111 ms on hcdnc332 (2/2)%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.112 s%%0001017/07/18 02:08:59 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.496176 s%%0001017/07/18 02:08:59 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:08:59 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:08:59 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:08:59 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:08:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262371, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(3903) called with curMem=268891, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:35338 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc332:48676 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:42885 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 97 ms on hcdnc332 (1/2)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 112 ms on hcdnc310 (2/2)%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.113 s%%0001017/07/18 02:08:59 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.126059 s%%0001017/07/18 02:08:59 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:08:59 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:08:59 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:08:59 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:08:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272794, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(4150) called with curMem=279970, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:35338 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc332, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:42885 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc332:48676 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 175 ms on hcdnc310 (1/2)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 180 ms on hcdnc332 (2/2)%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.182 s%%0001017/07/18 02:08:59 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:08:59 INFO DAGScheduler: running: Set()%%0001017/07/18 02:08:59 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:08:59 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284120, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286904, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:35338 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc332:48676 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:42885 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc332:44468%%0001017/07/18 02:08:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 173 bytes%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:56792%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc310 (1/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc332, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 51 ms on hcdnc332 (2/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc310 (3/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc332, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc332 (4/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc310 (5/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc332, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc332 (6/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc310 (7/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc332, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc332 (8/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc310 (9/10)%%0001017/07/18 02:08:59 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc332 (10/10)%%0001017/07/18 02:08:59 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 02:08:59 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:08:59 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.308151 s%%0001017/07/18 02:08:59 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:08:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:08:59 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:08:59 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:08:59 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:08:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:08:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(14512) called with curMem=288517, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.2 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO MemoryStore: ensureFreeSpace(8051) called with curMem=303029, maxMem=556038881%%0001017/07/18 02:08:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.9 KB, free 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:35338 (size: 7.9 KB, free: 530.2 MB)%%0001017/07/18 02:08:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:08:59 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc332, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc332:48676 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:42885 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc332:44468%%0001017/07/18 02:08:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:56792%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 400 ms on hcdnc332 (1/2)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 437 ms on hcdnc310 (2/2)%%0001017/07/18 02:09:00 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:00 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.438 s%%0001017/07/18 02:09:00 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:09:00 INFO DAGScheduler: running: Set()%%0001017/07/18 02:09:00 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:09:00 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:09:00 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:09:00 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:09:00 INFO MemoryStore: ensureFreeSpace(17944) called with curMem=311080, maxMem=556038881%%0001017/07/18 02:09:00 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 530.0 MB)%%0001017/07/18 02:09:00 INFO MemoryStore: ensureFreeSpace(9629) called with curMem=329024, maxMem=556038881%%0001017/07/18 02:09:00 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 530.0 MB)%%0001017/07/18 02:09:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:35338 (size: 9.4 KB, free: 530.2 MB)%%0001017/07/18 02:09:00 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:00 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:09:00 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:42885 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:09:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc332:48676 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:09:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:56792%%0001017/07/18 02:09:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 163 bytes%%0001017/07/18 02:09:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc332:44468%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 107 ms on hcdnc310 (1/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc332, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 108 ms on hcdnc332 (2/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 54 ms on hcdnc310 (3/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc332, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 56 ms on hcdnc332 (4/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 54 ms on hcdnc310 (5/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc332, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 69 ms on hcdnc332 (6/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 57 ms on hcdnc310 (7/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc332, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 54 ms on hcdnc332 (8/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 62 ms on hcdnc310 (9/10)%%0001017/07/18 02:09:00 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 57 ms on hcdnc332 (10/10)%%0001017/07/18 02:09:00 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:00 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.340 s%%0001017/07/18 02:09:00 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.819238 s%%0001017/07/18 02:09:00 INFO SparkContext: Invoking stop() from shutdown hook%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:09:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:09:00 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:09:00 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:09:00 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:09:00 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:09:00 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:09:00 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:09:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:35862] &lt;- [akka.tcp://sparkExecutor@hcdnc310:56792]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:56792] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:56792%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:35862] &lt;- [akka.tcp://sparkExecutor@hcdnc332:44468]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc332:44468] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc332:44468%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:09:00 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:09:00 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:09:00 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:09:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:09:00 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:09:00 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:09:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-62698cb2-d96f-409f-9f5b-ddefa1843123%%00010"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:09:17 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:09:17 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:09:17 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:09:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:09:18 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:09:18 INFO Remoting: Starting remoting%%0001017/07/18 02:09:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:45061]%%0001017/07/18 02:09:18 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:45061]%%0001017/07/18 02:09:18 INFO Utils: Successfully started service 'sparkDriver' on port 45061.%%0001017/07/18 02:09:18 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:09:18 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:09:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ae547a56-2c2d-4bf9-8f45-0c8fb4fa87d8%%0001017/07/18 02:09:18 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:09:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3b474b11-f20f-4c9d-94f5-3b5704a8eb39/httpd-b162e3f1-88f2-4499-aedf-8ba1370549ef%%0001017/07/18 02:09:18 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:09:18 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:09:18 INFO AbstractConnector: Started SocketConnector@0.0.0.0:44784%%0001017/07/18 02:09:18 INFO Utils: Successfully started service 'HTTP file server' on port 44784.%%0001017/07/18 02:09:18 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:09:18 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:09:18 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:09:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:09:18 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:09:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:09:19 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:09:19 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:09:19 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:09:19 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:09:19 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:09:19 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:09:19 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:09:20 INFO Client: Uploading resource file:/tmp/spark-3b474b11-f20f-4c9d-94f5-3b5704a8eb39/__spark_conf__2376122244754367765.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22141/__spark_conf__2376122244754367765.zip%%0001017/07/18 02:09:20 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:09:20 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:09:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:09:20 INFO Client: Submitting application 22141 to ResourceManager%%0001017/07/18 02:09:21 INFO YarnClientImpl: Submitted application application_1491786134915_22141%%0001017/07/18 02:09:22 INFO Client: Application report for application_1491786134915_22141 (state: ACCEPTED)%%0001017/07/18 02:09:22 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314960843%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22141/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:09:23 INFO Client: Application report for application_1491786134915_22141 (state: ACCEPTED)%%0001017/07/18 02:09:23 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:45892/user/YarnAM#2026689242])%%0001017/07/18 02:09:23 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22141,http://hcnnc117:8088/proxy/application_1491786134915_22141), /proxy/application_1491786134915_22141%%0001017/07/18 02:09:23 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:09:24 INFO Client: Application report for application_1491786134915_22141 (state: RUNNING)%%0001017/07/18 02:09:24 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314960843%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22141/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:09:24 INFO YarnClientSchedulerBackend: Application application_1491786134915_22141 has started running.%%0001017/07/18 02:09:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36561.%%0001017/07/18 02:09:24 INFO NettyBlockTransferService: Server created on 36561%%0001017/07/18 02:09:24 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:09:24 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:09:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:36561 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 36561)%%0001017/07/18 02:09:24 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:09:24 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22141%%0001017/07/18 02:09:24 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:09:24 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:09:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:09:24 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:09:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:09:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:36561 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:09:24 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:09:24 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:09:25 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:09:25 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:09:25 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:09:25 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:09:25 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:09:25 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:09:25 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:09:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:09:25 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:09:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:09:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:36561 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:09:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:09:25 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:09:26 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:09:27 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:09:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:45061] &lt;- [akka.tcp://driverPropsFetcher@hcdnc823:41439]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:41439] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:41439%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:29 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc823:52848/user/Executor#-891399144]) with ID 1%%0001017/07/18 02:09:29 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:09:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc823, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:09:29 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc823:44803 with 530.0 MB RAM, BlockManagerId(1, hcdnc823, 44803)%%0001017/07/18 02:09:29 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:45061] &lt;- [akka.tcp://driverPropsFetcher@hcdnc326:40241]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc326:40241] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc326:40241%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc823:44803 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:29 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc326:50019/user/Executor#-1470298923]) with ID 2%%0001017/07/18 02:09:29 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:09:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc326, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:09:29 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc326:52167 with 530.0 MB RAM, BlockManagerId(2, hcdnc326, 52167)%%0001017/07/18 02:09:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc823:44803 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:09:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc326:52167 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc326:52167 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:09:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1769 ms on hcdnc823 (1/2)%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1706 ms on hcdnc326 (2/2)%%0001017/07/18 02:09:31 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.236 s%%0001017/07/18 02:09:31 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:31 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.356416 s%%0001017/07/18 02:09:31 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:09:31 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:09:31 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:09:31 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:09:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:09:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:36561 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:09:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:09:31 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc823, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc326, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc326:52167 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc823:44803 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 305 ms on hcdnc326 (1/2)%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 346 ms on hcdnc823 (2/2)%%0001017/07/18 02:09:31 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:31 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.348 s%%0001017/07/18 02:09:31 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:09:31 INFO DAGScheduler: running: Set()%%0001017/07/18 02:09:31 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:09:31 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:09:31 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251391, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258327, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:36561 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:09:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:09:31 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc326, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc823:44803 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc326:52167 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:52848%%0001017/07/18 02:09:31 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 02:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc326:50019%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 85 ms on hcdnc326 (1/2)%%0001017/07/18 02:09:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 96 ms on hcdnc823 (2/2)%%0001017/07/18 02:09:31 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:31 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.096 s%%0001017/07/18 02:09:31 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.477330 s%%0001017/07/18 02:09:31 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:09:31 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:09:31 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:09:31 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:09:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:09:31 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262370, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268890, maxMem=556038881%%0001017/07/18 02:09:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:36561 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:09:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:09:31 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:31 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc326, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc326:52167 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:09:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc823:44803 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 89 ms on hcdnc326 (1/2)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 142 ms on hcdnc823 (2/2)%%0001017/07/18 02:09:32 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:32 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.144 s%%0001017/07/18 02:09:32 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.156992 s%%0001017/07/18 02:09:32 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:09:32 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:09:32 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:09:32 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:09:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:09:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272792, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279968, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:36561 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:09:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:09:32 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc326, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc823, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc823:44803 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc326:52167 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 210 ms on hcdnc326 (1/2)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 216 ms on hcdnc823 (2/2)%%0001017/07/18 02:09:32 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:32 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.217 s%%0001017/07/18 02:09:32 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:09:32 INFO DAGScheduler: running: Set()%%0001017/07/18 02:09:32 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:09:32 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:09:32 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284117, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286901, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:36561 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:09:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:09:32 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc326, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc823, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc326:52167 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc823:44803 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc326:50019%%0001017/07/18 02:09:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 174 bytes%%0001017/07/18 02:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc823:52848%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc326, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc326 (1/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc823, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc823 (2/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc326, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 13 ms on hcdnc326 (3/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc823 (4/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc326, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc326 (5/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 21 ms on hcdnc823 (6/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc326, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc326 (7/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc823 (8/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc326 (9/10)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc823 (10/10)%%0001017/07/18 02:09:32 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 02:09:32 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:32 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.341066 s%%0001017/07/18 02:09:32 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:09:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 02:09:32 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:09:32 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:09:32 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:09:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:09:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(14512) called with curMem=288514, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.2 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(8051) called with curMem=303026, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.9 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:36561 (size: 7.9 KB, free: 530.2 MB)%%0001017/07/18 02:09:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:09:32 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc823, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:09:32 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc326, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc326:52167 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc823:44803 (size: 7.9 KB, free: 530.0 MB)%%0001017/07/18 02:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc326:50019%%0001017/07/18 02:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:52848%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 426 ms on hcdnc823 (1/2)%%0001017/07/18 02:09:32 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 433 ms on hcdnc326 (2/2)%%0001017/07/18 02:09:32 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:32 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.436 s%%0001017/07/18 02:09:32 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:09:32 INFO DAGScheduler: running: Set()%%0001017/07/18 02:09:32 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:09:32 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:09:32 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:09:32 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(17944) called with curMem=311077, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 530.0 MB)%%0001017/07/18 02:09:32 INFO MemoryStore: ensureFreeSpace(9629) called with curMem=329021, maxMem=556038881%%0001017/07/18 02:09:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 530.0 MB)%%0001017/07/18 02:09:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:36561 (size: 9.4 KB, free: 530.2 MB)%%0001017/07/18 02:09:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:33 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:09:33 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc326, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc326:52167 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:09:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc823:44803 (size: 9.4 KB, free: 529.9 MB)%%0001017/07/18 02:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc326:50019%%0001017/07/18 02:09:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 02:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc823:52848%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc823, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 118 ms on hcdnc823 (1/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc326, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 126 ms on hcdnc326 (2/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc823, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 56 ms on hcdnc823 (3/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc326, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 61 ms on hcdnc326 (4/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc823, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 53 ms on hcdnc823 (5/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc326, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 54 ms on hcdnc326 (6/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc823, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 57 ms on hcdnc823 (7/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc326, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 55 ms on hcdnc326 (8/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 57 ms on hcdnc823 (9/10)%%0001017/07/18 02:09:33 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 57 ms on hcdnc326 (10/10)%%0001017/07/18 02:09:33 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:09:33 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.352 s%%0001017/07/18 02:09:33 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.828308 s%%0001017/07/18 02:09:33 INFO SparkContext: Invoking stop() from shutdown hook%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:09:33 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:09:33 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:09:33 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:09:33 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:09:33 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:09:33 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:09:33 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:09:33 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:45061] &lt;- [akka.tcp://sparkExecutor@hcdnc326:50019]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc326:50019] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc326:50019%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:33 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:45061] &lt;- [akka.tcp://sparkExecutor@hcdnc823:52848]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc823:52848] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc823:52848%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:09:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:09:33 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:09:33 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:09:33 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:09:33 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:09:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:09:33 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:09:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-3b474b11-f20f-4c9d-94f5-3b5704a8eb39%%00010"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:09:48 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:09:48 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:09:48 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:09:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:09:49 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:09:50 INFO Remoting: Starting remoting%%0001017/07/18 02:09:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46308]%%0001017/07/18 02:09:50 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46308]%%0001017/07/18 02:09:50 INFO Utils: Successfully started service 'sparkDriver' on port 46308.%%0001017/07/18 02:09:50 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:09:50 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:09:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2b8bc556-3b37-4caa-89fb-d0d3992ba847%%0001017/07/18 02:09:50 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:09:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ff179f29-d662-45a9-a20b-532fe58d864b/httpd-dad4a19f-bb92-4275-92ca-4fec3ec05295%%0001017/07/18 02:09:50 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:09:50 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:09:50 INFO AbstractConnector: Started SocketConnector@0.0.0.0:43039%%0001017/07/18 02:09:50 INFO Utils: Successfully started service 'HTTP file server' on port 43039.%%0001017/07/18 02:09:50 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:09:50 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:09:50 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:09:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:09:50 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:09:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:09:51 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:09:51 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:09:51 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:09:51 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:09:51 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:09:51 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:09:51 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:09:51 INFO Client: Uploading resource file:/tmp/spark-ff179f29-d662-45a9-a20b-532fe58d864b/__spark_conf__8059959403224073288.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22142/__spark_conf__8059959403224073288.zip%%0001017/07/18 02:09:51 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:09:51 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:09:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:09:51 INFO Client: Submitting application 22142 to ResourceManager%%0001017/07/18 02:09:52 INFO YarnClientImpl: Submitted application application_1491786134915_22142%%0001017/07/18 02:09:53 INFO Client: Application report for application_1491786134915_22142 (state: ACCEPTED)%%0001017/07/18 02:09:53 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314991981%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22142/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:09:54 INFO Client: Application report for application_1491786134915_22142 (state: ACCEPTED)%%0001017/07/18 02:09:55 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:54857/user/YarnAM#-1229027297])%%0001017/07/18 02:09:55 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22142,http://hcnnc117:8088/proxy/application_1491786134915_22142), /proxy/application_1491786134915_22142%%0001017/07/18 02:09:55 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:09:55 INFO Client: Application report for application_1491786134915_22142 (state: RUNNING)%%0001017/07/18 02:09:55 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500314991981%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22142/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:09:55 INFO YarnClientSchedulerBackend: Application application_1491786134915_22142 has started running.%%0001017/07/18 02:09:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40445.%%0001017/07/18 02:09:55 INFO NettyBlockTransferService: Server created on 40445%%0001017/07/18 02:09:55 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:09:55 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:09:55 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:40445 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 40445)%%0001017/07/18 02:09:55 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:09:55 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22142%%0001017/07/18 02:09:55 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:09:56 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:09:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:09:56 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:09:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:09:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:40445 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:09:56 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:09:56 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:09:56 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:09:56 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:09:56 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:09:56 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:09:56 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:09:56 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:09:56 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:09:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:09:56 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:09:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:09:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:40445 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:09:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:09:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:09:56 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:09:57 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:09:58 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:10:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46308] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:40691]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:40691] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:40691%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:00 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:53210/user/Executor#88896149]) with ID 1%%0001017/07/18 02:10:00 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:10:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:10:00 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:47245 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 47245)%%0001017/07/18 02:10:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46308] &lt;- [akka.tcp://driverPropsFetcher@hcdnc301:39652]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc301:39652] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc301:39652%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:47245 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:01 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc301:52322/user/Executor#1555975613]) with ID 2%%0001017/07/18 02:10:01 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:10:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc301, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:10:01 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc301:39995 with 530.0 MB RAM, BlockManagerId(2, hcdnc301, 39995)%%0001017/07/18 02:10:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:47245 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc301:39995 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc301:39995 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1733 ms on hcdnc310 (1/2)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1837 ms on hcdnc301 (2/2)%%0001017/07/18 02:10:03 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.411 s%%0001017/07/18 02:10:03 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:03 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.535008 s%%0001017/07/18 02:10:03 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:10:03 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:10:03 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:10:03 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:10:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:40445 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:10:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:10:03 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc301, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc301:39995 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:47245 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 283 ms on hcdnc310 (1/2)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 316 ms on hcdnc301 (2/2)%%0001017/07/18 02:10:03 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.318 s%%0001017/07/18 02:10:03 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:03 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:03 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:03 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:10:03 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:03 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251391, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258327, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:40445 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:10:03 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:10:03 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc301, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:47245 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc301:39995 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc301:52322%%0001017/07/18 02:10:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:10:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:53210%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 92 ms on hcdnc301 (1/2)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 99 ms on hcdnc310 (2/2)%%0001017/07/18 02:10:03 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.099 s%%0001017/07/18 02:10:03 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:03 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.449481 s%%0001017/07/18 02:10:03 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:10:03 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:10:03 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:10:03 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:10:03 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262370, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268890, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:40445 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:10:03 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:10:03 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc301, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:47245 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc301:39995 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 98 ms on hcdnc301 (1/2)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 103 ms on hcdnc310 (2/2)%%0001017/07/18 02:10:03 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:03 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.103 s%%0001017/07/18 02:10:03 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.117180 s%%0001017/07/18 02:10:03 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:10:03 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:10:03 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:10:03 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:10:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272792, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279968, maxMem=556038881%%0001017/07/18 02:10:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:40445 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:10:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:10:03 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:03 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc301, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc301:39995 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:47245 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:10:03 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 176 ms on hcdnc301 (1/2)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 195 ms on hcdnc310 (2/2)%%0001017/07/18 02:10:04 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:04 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.196 s%%0001017/07/18 02:10:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:04 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:04 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:10:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:04 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284117, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286901, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:40445 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:10:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:10:04 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc301, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:47245 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc301:39995 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:53210%%0001017/07/18 02:10:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 173 bytes%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc301:52322%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 42 ms on hcdnc310 (1/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc301, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc301 (2/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc310 (3/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc301, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc301 (4/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 20 ms on hcdnc310 (5/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc301, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc301 (6/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 18 ms on hcdnc310 (7/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc301, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc301 (8/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc310 (9/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc301 (10/10)%%0001017/07/18 02:10:04 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.107 s%%0001017/07/18 02:10:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:04 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.324186 s%%0001017/07/18 02:10:04 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:10:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:10:04 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:10:04 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:10:04 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:10:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:10:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(13536) called with curMem=288514, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(7475) called with curMem=302050, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.3 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:40445 (size: 7.3 KB, free: 530.2 MB)%%0001017/07/18 02:10:04 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:10:04 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc301, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:47245 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc301:39995 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc301:52322%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:53210%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 386 ms on hcdnc301 (1/2)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 402 ms on hcdnc310 (2/2)%%0001017/07/18 02:10:04 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:04 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.404 s%%0001017/07/18 02:10:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:04 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:04 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:10:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:04 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(16760) called with curMem=309525, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.4 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO MemoryStore: ensureFreeSpace(8915) called with curMem=326285, maxMem=556038881%%0001017/07/18 02:10:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.7 KB, free 530.0 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:40445 (size: 8.7 KB, free: 530.2 MB)%%0001017/07/18 02:10:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:10:04 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc301, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc301:39995 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:10:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:47245 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc301:52322%%0001017/07/18 02:10:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 02:10:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:53210%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 102 ms on hcdnc310 (1/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc301, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 109 ms on hcdnc301 (2/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 55 ms on hcdnc310 (3/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc301, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 56 ms on hcdnc301 (4/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 60 ms on hcdnc310 (5/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc301, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 54 ms on hcdnc301 (6/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 54 ms on hcdnc310 (7/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc301, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 55 ms on hcdnc301 (8/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 53 ms on hcdnc310 (9/10)%%0001017/07/18 02:10:04 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 57 ms on hcdnc301 (10/10)%%0001017/07/18 02:10:04 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:04 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.328 s%%0001017/07/18 02:10:04 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.759719 s%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:10:05 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:10:05 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:10:05 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:10:05 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:10:05 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:10:05 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:10:05 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:10:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46308] &lt;- [akka.tcp://sparkExecutor@hcdnc310:53210]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:53210] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:53210%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46308] &lt;- [akka.tcp://sparkExecutor@hcdnc301:52322]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc301:52322] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc301:52322%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:10:05 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:10:05 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:10:05 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:10:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:10:05 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:10:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 02:10:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 02:10:05 INFO Remoting: Remoting shut down%%0001017/07/18 02:10:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 02:10:06 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:10:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-ff179f29-d662-45a9-a20b-532fe58d864b%%00010"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:10:19 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:10:19 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:10:19 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:10:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:10:20 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:10:20 INFO Remoting: Starting remoting%%0001017/07/18 02:10:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37824]%%0001017/07/18 02:10:20 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37824]%%0001017/07/18 02:10:20 INFO Utils: Successfully started service 'sparkDriver' on port 37824.%%0001017/07/18 02:10:20 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:10:20 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:10:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7bcfbfe0-bf9a-4a37-a5ba-3c1b3a4e5890%%0001017/07/18 02:10:20 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:10:21 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b46ef068-ee07-40f5-922a-7490967da790/httpd-369dcdc8-4fa9-4ee0-9e2e-66c5a01d2ab7%%0001017/07/18 02:10:21 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:10:21 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:10:21 INFO AbstractConnector: Started SocketConnector@0.0.0.0:39805%%0001017/07/18 02:10:21 INFO Utils: Successfully started service 'HTTP file server' on port 39805.%%0001017/07/18 02:10:21 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:10:21 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:10:21 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:10:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:10:21 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:10:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:10:21 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:10:21 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:10:21 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:10:21 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:10:21 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:10:21 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:10:21 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:10:22 INFO Client: Uploading resource file:/tmp/spark-b46ef068-ee07-40f5-922a-7490967da790/__spark_conf__8407631999212019635.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22143/__spark_conf__8407631999212019635.zip%%0001017/07/18 02:10:22 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:10:22 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:10:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:10:22 INFO Client: Submitting application 22143 to ResourceManager%%0001017/07/18 02:10:22 INFO YarnClientImpl: Submitted application application_1491786134915_22143%%0001017/07/18 02:10:23 INFO Client: Application report for application_1491786134915_22143 (state: ACCEPTED)%%0001017/07/18 02:10:23 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500315022752%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22143/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:10:24 INFO Client: Application report for application_1491786134915_22143 (state: ACCEPTED)%%0001017/07/18 02:10:25 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.3.32:49034/user/YarnAM#-1023086785])%%0001017/07/18 02:10:25 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22143,http://hcnnc117:8088/proxy/application_1491786134915_22143), /proxy/application_1491786134915_22143%%0001017/07/18 02:10:25 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:10:25 INFO Client: Application report for application_1491786134915_22143 (state: RUNNING)%%0001017/07/18 02:10:25 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.3.32%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500315022752%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22143/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:10:25 INFO YarnClientSchedulerBackend: Application application_1491786134915_22143 has started running.%%0001017/07/18 02:10:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44328.%%0001017/07/18 02:10:26 INFO NettyBlockTransferService: Server created on 44328%%0001017/07/18 02:10:26 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:10:26 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:10:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:44328 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 44328)%%0001017/07/18 02:10:26 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:10:26 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22143%%0001017/07/18 02:10:26 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:10:27 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:10:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:10:27 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:10:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:10:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:44328 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:10:27 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:10:27 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:10:27 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:10:27 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:10:27 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:10:27 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:10:27 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:10:27 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:10:27 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:10:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:10:27 INFO MemoryStore: ensureFreeSpace(3981) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:10:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:10:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:44328 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:10:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:10:27 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:10:28 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:10:29 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:10:31 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37824] &lt;- [akka.tcp://driverPropsFetcher@hcdnc325:44198]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc325:44198] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc325:44198%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:31 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc325:34475/user/Executor#1671317118]) with ID 1%%0001017/07/18 02:10:31 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:10:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc325, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:10:31 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc325:60273 with 530.0 MB RAM, BlockManagerId(1, hcdnc325, 60273)%%0001017/07/18 02:10:31 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37824] &lt;- [akka.tcp://driverPropsFetcher@hcdnc319:38029]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc319:38029] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc319:38029%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc325:60273 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:32 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc319:45425/user/Executor#502697426]) with ID 2%%0001017/07/18 02:10:32 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:10:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc319, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:10:32 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc319:40647 with 530.0 MB RAM, BlockManagerId(2, hcdnc319, 40647)%%0001017/07/18 02:10:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc325:60273 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc319:40647 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc319:40647 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1746 ms on hcdnc325 (1/2)%%0001017/07/18 02:10:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1895 ms on hcdnc319 (2/2)%%0001017/07/18 02:10:33 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.474 s%%0001017/07/18 02:10:33 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:33 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.597935 s%%0001017/07/18 02:10:33 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:10:33 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:10:33 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:10:33 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:10:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:10:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:10:33 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237417, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(5311) called with curMem=246081, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:44328 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc319, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc325, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc319:40647 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc325:60273 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 274 ms on hcdnc325 (1/2)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 334 ms on hcdnc319 (2/2)%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.334 s%%0001017/07/18 02:10:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:34 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:34 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:10:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:34 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251392, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258328, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:44328 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc319, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc325:60273 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc319:40647 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc319:45425%%0001017/07/18 02:10:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:10:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc325:34475%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 101 ms on hcdnc319 (1/2)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 104 ms on hcdnc325 (2/2)%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.105 s%%0001017/07/18 02:10:34 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.471359 s%%0001017/07/18 02:10:34 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:10:34 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:10:34 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:10:34 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:10:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:10:34 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262371, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268891, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:44328 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc319, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc319:40647 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc325:60273 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 89 ms on hcdnc319 (1/2)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 103 ms on hcdnc325 (2/2)%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.104 s%%0001017/07/18 02:10:34 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.117637 s%%0001017/07/18 02:10:34 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:10:34 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:10:34 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:10:34 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:10:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:10:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272793, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279969, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:44328 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc325, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc319, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc319:40647 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc325:60273 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 182 ms on hcdnc325 (1/2)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 184 ms on hcdnc319 (2/2)%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.186 s%%0001017/07/18 02:10:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:34 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:34 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:10:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:34 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284118, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:10:34 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286902, maxMem=556038881%%0001017/07/18 02:10:34 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:44328 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:10:34 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:34 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:10:34 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc325, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc319, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc319:40647 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc325:60273 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:10:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc319:45425%%0001017/07/18 02:10:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 173 bytes%%0001017/07/18 02:10:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc325:34475%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc319, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 43 ms on hcdnc319 (1/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc325, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 46 ms on hcdnc325 (2/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc319, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc319 (3/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc325, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc325 (4/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc319, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc319 (5/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc325, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc325 (6/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc319, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc319 (7/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc325, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc325 (8/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc319 (9/10)%%0001017/07/18 02:10:34 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc325 (10/10)%%0001017/07/18 02:10:34 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 02:10:34 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:34 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.310260 s%%0001017/07/18 02:10:35 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:10:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:10:35 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:10:35 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:10:35 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:10:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:10:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:10:35 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:10:35 INFO MemoryStore: ensureFreeSpace(13536) called with curMem=288515, maxMem=556038881%%0001017/07/18 02:10:35 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 530.0 MB)%%0001017/07/18 02:10:35 INFO MemoryStore: ensureFreeSpace(7475) called with curMem=302051, maxMem=556038881%%0001017/07/18 02:10:35 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.3 KB, free 530.0 MB)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:44328 (size: 7.3 KB, free: 530.2 MB)%%0001017/07/18 02:10:35 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:10:35 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc325, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc319, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc319:40647 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc325:60273 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:10:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc325:34475%%0001017/07/18 02:10:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc319:45425%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 351 ms on hcdnc319 (1/2)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 391 ms on hcdnc325 (2/2)%%0001017/07/18 02:10:35 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:35 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.393 s%%0001017/07/18 02:10:35 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:10:35 INFO DAGScheduler: running: Set()%%0001017/07/18 02:10:35 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:10:35 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:10:35 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:10:35 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:10:35 INFO MemoryStore: ensureFreeSpace(16760) called with curMem=309526, maxMem=556038881%%0001017/07/18 02:10:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.4 KB, free 530.0 MB)%%0001017/07/18 02:10:35 INFO MemoryStore: ensureFreeSpace(8913) called with curMem=326286, maxMem=556038881%%0001017/07/18 02:10:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.7 KB, free 530.0 MB)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:44328 (size: 8.7 KB, free: 530.2 MB)%%0001017/07/18 02:10:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:35 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:10:35 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc319, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc319:40647 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:10:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc325:60273 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:10:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc325:34475%%0001017/07/18 02:10:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 02:10:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc319:45425%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc319, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 96 ms on hcdnc319 (1/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc325, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 98 ms on hcdnc325 (2/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc319, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 54 ms on hcdnc319 (3/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc325, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 57 ms on hcdnc325 (4/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc319, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 53 ms on hcdnc319 (5/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc325, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 55 ms on hcdnc325 (6/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc319, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 53 ms on hcdnc319 (7/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc325, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 54 ms on hcdnc325 (8/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 54 ms on hcdnc319 (9/10)%%0001017/07/18 02:10:35 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 55 ms on hcdnc325 (10/10)%%0001017/07/18 02:10:35 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:10:35 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.315 s%%0001017/07/18 02:10:35 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.737413 s%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:10:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:10:35 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:10:35 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:10:35 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:10:35 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:10:35 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:10:35 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:10:35 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37824] &lt;- [akka.tcp://sparkExecutor@hcdnc325:34475]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc325:34475] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc325:34475%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:35 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37824] &lt;- [akka.tcp://sparkExecutor@hcdnc319:45425]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc319:45425] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc319:45425%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:10:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:10:36 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:10:36 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:10:36 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:10:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:10:36 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:10:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 02:10:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 02:10:36 INFO Remoting: Remoting shut down%%0001017/07/18 02:10:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 02:10:36 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:10:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-b46ef068-ee07-40f5-922a-7490967da790%%00010"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 02:10:49 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 02:10:51 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:10:51 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:10:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:10:51 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 02:10:52 INFO Remoting: Starting remoting%%0001017/07/18 02:10:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46227]%%0001017/07/18 02:10:52 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46227]%%0001017/07/18 02:10:52 INFO Utils: Successfully started service 'sparkDriver' on port 46227.%%0001017/07/18 02:10:52 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 02:10:52 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 02:10:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b9df1c7f-97f7-446a-a5d1-ba8db74051a8%%0001017/07/18 02:10:52 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 02:10:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-07e76fee-4365-4c0e-b73b-e8f96d35cb4b/httpd-c3d4dd9c-5934-4fd9-9a74-dd00b3bef31d%%0001017/07/18 02:10:52 INFO HttpServer: Starting HTTP Server%%0001017/07/18 02:10:52 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:10:52 INFO AbstractConnector: Started SocketConnector@0.0.0.0:40992%%0001017/07/18 02:10:52 INFO Utils: Successfully started service 'HTTP file server' on port 40992.%%0001017/07/18 02:10:52 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 02:10:52 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 02:10:52 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 02:10:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 02:10:52 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 02:10:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 02:10:52 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 02:10:52 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 02:10:52 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 02:10:52 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 02:10:52 INFO Client: Setting up container launch context for our AM%%0001017/07/18 02:10:52 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 02:10:53 INFO Client: Preparing resources for our AM container%%0001017/07/18 02:10:53 INFO Client: Uploading resource file:/tmp/spark-07e76fee-4365-4c0e-b73b-e8f96d35cb4b/__spark_conf__1527539359832699766.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22144/__spark_conf__1527539359832699766.zip%%0001017/07/18 02:10:54 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 02:10:54 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 02:10:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 02:10:54 INFO Client: Submitting application 22144 to ResourceManager%%0001017/07/18 02:10:54 INFO YarnClientImpl: Submitted application application_1491786134915_22144%%0001017/07/18 02:10:55 INFO Client: Application report for application_1491786134915_22144 (state: ACCEPTED)%%0001017/07/18 02:10:55 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500315054298%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22144/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:10:56 INFO Client: Application report for application_1491786134915_22144 (state: ACCEPTED)%%0001017/07/18 02:10:57 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:35918/user/YarnAM#1415268613])%%0001017/07/18 02:10:57 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22144,http://hcnnc117:8088/proxy/application_1491786134915_22144), /proxy/application_1491786134915_22144%%0001017/07/18 02:10:57 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 02:10:57 INFO Client: Application report for application_1491786134915_22144 (state: RUNNING)%%0001017/07/18 02:10:57 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500315054298%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22144/%%00010%%00009 user: y23ycc01%%0001017/07/18 02:10:57 INFO YarnClientSchedulerBackend: Application application_1491786134915_22144 has started running.%%0001017/07/18 02:10:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40745.%%0001017/07/18 02:10:57 INFO NettyBlockTransferService: Server created on 40745%%0001017/07/18 02:10:57 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 02:10:57 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 02:10:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:40745 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 40745)%%0001017/07/18 02:10:57 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 02:10:58 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22144%%0001017/07/18 02:10:58 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 02:10:58 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 02:10:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 02:10:58 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 02:10:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 02:10:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:40745 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 02:10:58 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 02:10:58 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 02:10:58 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 02:10:58 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 02:10:58 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:10:58 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 02:10:58 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:10:58 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 02:10:58 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 02:10:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 02:10:58 INFO MemoryStore: ensureFreeSpace(3980) called with curMem=233436, maxMem=556038881%%0001017/07/18 02:10:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 02:10:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:40745 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 02:10:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:10:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 02:10:58 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 02:11:00 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 02:11:01 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 02:11:02 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46227] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:36304]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:36304] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:36304%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:11:02 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:57670/user/Executor#-901421741]) with ID 1%%0001017/07/18 02:11:02 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 02:11:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:11:03 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:39153 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 39153)%%0001017/07/18 02:11:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:39153 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:11:03 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46227] &lt;- [akka.tcp://driverPropsFetcher@hcdnc339:60520]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc339:60520] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc339:60520%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:11:03 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc339:50492/user/Executor#-315769020]) with ID 2%%0001017/07/18 02:11:03 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 02:11:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc339, partition 1,RACK_LOCAL, 2154 bytes)%%0001017/07/18 02:11:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:39153 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:11:03 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc339:50577 with 530.0 MB RAM, BlockManagerId(2, hcdnc339, 50577)%%0001017/07/18 02:11:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc339:50577 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:11:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1630 ms on hcdnc310 (1/2)%%0001017/07/18 02:11:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc339:50577 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1808 ms on hcdnc339 (2/2)%%0001017/07/18 02:11:05 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 6.421 s%%0001017/07/18 02:11:05 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:05 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 6.544384 s%%0001017/07/18 02:11:05 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 02:11:05 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:11:05 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 02:11:05 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:11:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 02:11:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 02:11:05 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 02:11:05 INFO MemoryStore: ensureFreeSpace(8664) called with curMem=237416, maxMem=556038881%%0001017/07/18 02:11:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 02:11:05 INFO MemoryStore: ensureFreeSpace(5313) called with curMem=246080, maxMem=556038881%%0001017/07/18 02:11:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:40745 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 02:11:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 02:11:05 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 02:11:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:11:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc339, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc339:50577 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:39153 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 285 ms on hcdnc339 (1/2)%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 331 ms on hcdnc310 (2/2)%%0001017/07/18 02:11:05 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:05 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 0.332 s%%0001017/07/18 02:11:05 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:11:05 INFO DAGScheduler: running: Set()%%0001017/07/18 02:11:05 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 02:11:05 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:11:05 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 02:11:05 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 02:11:05 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251393, maxMem=556038881%%0001017/07/18 02:11:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 02:11:05 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258329, maxMem=556038881%%0001017/07/18 02:11:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:40745 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 02:11:05 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 02:11:05 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 02:11:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc339, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:39153 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc339:50577 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 02:11:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:57670%%0001017/07/18 02:11:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:11:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc339:50492%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on hcdnc310 (1/2)%%0001017/07/18 02:11:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 97 ms on hcdnc339 (2/2)%%0001017/07/18 02:11:05 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:05 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.099 s%%0001017/07/18 02:11:05 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 0.463175 s%%0001017/07/18 02:11:06 WARN FPGrowth: Input data is not cached.%%0001017/07/18 02:11:06 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 02:11:06 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 02:11:06 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 02:11:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262372, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268892, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:40745 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 02:11:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 02:11:06 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc339, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc339:50577 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:39153 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 106 ms on hcdnc339 (1/2)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 106 ms on hcdnc310 (2/2)%%0001017/07/18 02:11:06 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.108 s%%0001017/07/18 02:11:06 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:06 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.120617 s%%0001017/07/18 02:11:06 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 02:11:06 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 02:11:06 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 02:11:06 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 02:11:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272794, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=279970, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:40745 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 02:11:06 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 02:11:06 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc339, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc339:50577 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:39153 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 205 ms on hcdnc310 (1/2)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 228 ms on hcdnc339 (2/2)%%0001017/07/18 02:11:06 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:06 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.229 s%%0001017/07/18 02:11:06 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:11:06 INFO DAGScheduler: running: Set()%%0001017/07/18 02:11:06 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 02:11:06 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284118, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286902, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:40745 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 02:11:06 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 02:11:06 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc339, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:39153 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc339:50577 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:57670%%0001017/07/18 02:11:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 173 bytes%%0001017/07/18 02:11:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc339:50492%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 41 ms on hcdnc310 (1/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc339, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 52 ms on hcdnc339 (2/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc310 (3/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc339, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc339 (4/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc310 (5/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc339, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc310 (6/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 22 ms on hcdnc339 (7/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc339, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc339 (8/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc310 (9/10)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc339 (10/10)%%0001017/07/18 02:11:06 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.111 s%%0001017/07/18 02:11:06 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:06 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.360823 s%%0001017/07/18 02:11:06 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 02:11:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 02:11:06 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 02:11:06 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 02:11:06 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:11:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(13536) called with curMem=288515, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO MemoryStore: ensureFreeSpace(7475) called with curMem=302051, maxMem=556038881%%0001017/07/18 02:11:06 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.3 KB, free 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:40745 (size: 7.3 KB, free: 530.2 MB)%%0001017/07/18 02:11:06 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 02:11:06 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc339, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:11:06 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:39153 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc339:50577 (size: 7.3 KB, free: 530.0 MB)%%0001017/07/18 02:11:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:57670%%0001017/07/18 02:11:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc339:50492%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 392 ms on hcdnc310 (1/2)%%0001017/07/18 02:11:06 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 393 ms on hcdnc339 (2/2)%%0001017/07/18 02:11:06 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:06 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 0.395 s%%0001017/07/18 02:11:06 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 02:11:06 INFO DAGScheduler: running: Set()%%0001017/07/18 02:11:06 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 02:11:06 INFO DAGScheduler: failed: Set()%%0001017/07/18 02:11:06 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 02:11:06 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 02:11:07 INFO MemoryStore: ensureFreeSpace(16760) called with curMem=309526, maxMem=556038881%%0001017/07/18 02:11:07 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.4 KB, free 530.0 MB)%%0001017/07/18 02:11:07 INFO MemoryStore: ensureFreeSpace(8913) called with curMem=326286, maxMem=556038881%%0001017/07/18 02:11:07 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.7 KB, free 530.0 MB)%%0001017/07/18 02:11:07 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:40745 (size: 8.7 KB, free: 530.2 MB)%%0001017/07/18 02:11:07 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 02:11:07 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 02:11:07 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc339, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:39153 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:11:07 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc339:50577 (size: 8.7 KB, free: 529.9 MB)%%0001017/07/18 02:11:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:57670%%0001017/07/18 02:11:07 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 02:11:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc339:50492%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 97 ms on hcdnc310 (1/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc339, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 99 ms on hcdnc339 (2/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 55 ms on hcdnc310 (3/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc339, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 54 ms on hcdnc339 (4/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 52 ms on hcdnc310 (5/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc339, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 55 ms on hcdnc339 (6/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc339, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 53 ms on hcdnc339 (7/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 63 ms on hcdnc310 (8/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 54 ms on hcdnc339 (9/10)%%0001017/07/18 02:11:07 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 55 ms on hcdnc310 (10/10)%%0001017/07/18 02:11:07 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 02:11:07 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.316 s%%0001017/07/18 02:11:07 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 0.736539 s%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 02:11:07 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 02:11:07 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 02:11:07 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 02:11:07 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 02:11:07 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 02:11:07 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 02:11:07 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 02:11:07 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46227] &lt;- [akka.tcp://sparkExecutor@hcdnc310:57670]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:57670] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:57670%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:11:07 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46227] &lt;- [akka.tcp://sparkExecutor@hcdnc339:50492]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc339:50492] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc339:50492%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 02:11:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 02:11:07 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 02:11:07 INFO BlockManager: BlockManager stopped%%0001017/07/18 02:11:07 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 02:11:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 02:11:07 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 02:11:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 02:11:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 02:11:07 INFO Remoting: Remoting shut down%%0001017/07/18 02:11:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 02:11:08 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 02:11:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-07e76fee-4365-4c0e-b73b-e8f96d35cb4b%%00010"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_2">
<entry key="column_name" type="xstring" value="FailingNode"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Bash"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_3">
<entry key="column_name" type="xstring" value="currentIteration"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.IntCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="5"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_4">
<entry key="column_name" type="xstring" value="maxIterations"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.IntCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="6"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="6"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_5">
<entry key="column_name" type="xstring" value="index_of_drugColumn"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="7.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="7.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_6">
<entry key="column_name" type="xstring" value="minSupport"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.005"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.0075"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_7">
<entry key="column_name" type="xstring" value="minConfidence"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.2"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.4000000000000001"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_8">
<entry key="column_name" type="xstring" value="cmd"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="6"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.endometriosis.csv 7 0.005 0.2"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.endometriosis.csv 7 0.005 0.3"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.endometriosis.csv 7 0.005 0.4"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.endometriosis.csv 7 0.0075 0.2"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.endometriosis.csv 7 0.0075 0.3"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.endometriosis.csv 7 0.0075 0.4"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_9">
<entry key="column_name" type="xstring" value="RowID"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="6"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="0"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="2"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="3"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="4"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="5"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_10">
<entry key="column_name" type="xstring" value="config_host_ip"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="140.110.30.32"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_11">
<entry key="column_name" type="xstring" value="task_minConfidenceLower"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="20.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="20.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_12">
<entry key="column_name" type="xstring" value="task_local_attr_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.feature.TCM.summary.level123.QiFlavorMeri.20170621.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_13">
<entry key="column_name" type="xstring" value="config_password"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1q2w3e4r"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_14">
<entry key="column_name" type="xstring" value="config_local_NHIcode_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.TCM.HF_SH.20170703.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_15">
<entry key="column_name" type="xstring" value="config_local_metadata_fullpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_16">
<entry key="column_name" type="xstring" value="task_minConfidenceStep"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="10.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="10.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_17">
<entry key="column_name" type="xstring" value="task_local_keyword_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.keyword.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_18">
<entry key="column_name" type="xstring" value="task_drugColumnIndex"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="7.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="7.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_19">
<entry key="column_name" type="xstring" value="task_updateCachedDataFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_20">
<entry key="column_name" type="xstring" value="task_name_Ch"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="子宮內膜異位中醫治療圖譜"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_21">
<entry key="column_name" type="xstring" value="config_local_output_fullpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData/Sample"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_22">
<entry key="column_name" type="xstring" value="task_minSupportUpper"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="1.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="1.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_23">
<entry key="column_name" type="xstring" value="task_local_cachedData_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.cachedData.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_24">
<entry key="column_name" type="xstring" value="task_updateCachedPubmedFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="N"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_25">
<entry key="column_name" type="xstring" value="task_name"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="endometriosis"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_26">
<entry key="column_name" type="xstring" value="task_minConfidenceUpper"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="50.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="50.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_27">
<entry key="column_name" type="xstring" value="config_local_translation_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.NAME.translation_shortform.20170625.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_28">
<entry key="column_name" type="xstring" value="task_local_translation_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.NAME.translation_shortform.20170625.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_29">
<entry key="column_name" type="xstring" value="config_graphspace_id"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="yuchn.chen@gmail.com"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_30">
<entry key="column_name" type="xstring" value="task_local_NHIcode_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.TCM.HF_SH.20170703.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_31">
<entry key="column_name" type="xstring" value="config_graphspace_pwd"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1q2w3e4r"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_32">
<entry key="column_name" type="xstring" value="task_local_cachedPubmed_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.cachedPubmed.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_33">
<entry key="column_name" type="xstring" value="config_local_cachedData_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.cachedData.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_34">
<entry key="column_name" type="xstring" value="task_remote_srcFilemname"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="/home_i1/y23ycc01/incoming/tid.endometriosis.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_35">
<entry key="column_name" type="xstring" value="config_local_cachedPubmed_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.cachedPubmed.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_36">
<entry key="column_name" type="xstring" value="task_remote_srcFilepath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="/home_i1/y23ycc01/incoming"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_37">
<entry key="column_name" type="xstring" value="config_user_id"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="y23ycc01"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_38">
<entry key="column_name" type="xstring" value="task_forceReanalyze"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_39">
<entry key="column_name" type="xstring" value="config_workpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="incoming"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_40">
<entry key="column_name" type="xstring" value="task_reuploadSrcFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_41">
<entry key="column_name" type="xstring" value="task_minSupportLower"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.5"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.5"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_42">
<entry key="column_name" type="xstring" value="config_local_keyword_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.keyword.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_43">
<entry key="column_name" type="xstring" value="task_minSupportStep"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.25"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.25"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_44">
<entry key="column_name" type="xstring" value="config_local_attr_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.feature.TCM.summary.level123.QiFlavorMeri.20170621.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_45">
<entry key="column_name" type="xstring" value="task_srcDirectory"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Dropbox\1.Projects\Cytoscape\testData\Sample"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_46">
<entry key="column_name" type="xstring" value="task_srcFilename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="tid.endometriosis"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_47">
<entry key="column_name" type="xstring" value="task_srcFileExt"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value=".csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_48">
<entry key="column_name" type="xstring" value="task_local_srcfilename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Dropbox\1.Projects\Cytoscape\testData\Sample\tid.endometriosis.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_49">
<entry key="column_name" type="xstring" value="knime.workspace"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Users\yuchn\knime-workspace"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
</config>
