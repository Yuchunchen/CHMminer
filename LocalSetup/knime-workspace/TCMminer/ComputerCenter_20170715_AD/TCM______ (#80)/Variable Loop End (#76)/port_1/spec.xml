<?xml version="1.0" encoding="UTF-8"?>
<config xmlns="http://www.knime.org/2008/09/XMLConfig" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.knime.org/2008/09/XMLConfig http://www.knime.org/XMLConfig_2008_09.xsd" key="spec.xml">
<entry key="spec_name" type="xstring" value="default"/>
<entry key="number_columns" type="xint" value="50"/>
<config key="column_spec_0">
<entry key="column_name" type="xstring" value="FailingNodeStackTrace"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:58:36 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:58:37 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:58:37 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:58:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:58:37 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:58:37 INFO Remoting: Starting remoting%%0001017/07/18 00:58:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:41894]%%0001017/07/18 00:58:37 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:41894]%%0001017/07/18 00:58:37 INFO Utils: Successfully started service 'sparkDriver' on port 41894.%%0001017/07/18 00:58:37 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:58:37 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:58:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d599f2fc-391e-4cce-812a-7e1a8a178511%%0001017/07/18 00:58:37 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:58:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-945fd0ae-0b4b-41c7-9a8f-7098d62d7a82/httpd-2f5a02f5-2cb4-4f86-9276-4f03b46f5b7e%%0001017/07/18 00:58:38 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:58:38 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:58:38 INFO AbstractConnector: Started SocketConnector@0.0.0.0:42145%%0001017/07/18 00:58:38 INFO Utils: Successfully started service 'HTTP file server' on port 42145.%%0001017/07/18 00:58:38 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:58:38 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:58:38 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:58:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:58:38 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:58:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:58:39 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:58:39 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:58:39 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:58:39 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:58:39 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:58:39 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:58:39 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:58:39 INFO Client: Uploading resource file:/tmp/spark-945fd0ae-0b4b-41c7-9a8f-7098d62d7a82/__spark_conf__2724005607677665489.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22121/__spark_conf__2724005607677665489.zip%%0001017/07/18 00:58:39 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:58:39 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:58:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:58:39 INFO Client: Submitting application 22121 to ResourceManager%%0001017/07/18 00:58:40 INFO YarnClientImpl: Submitted application application_1491786134915_22121%%0001017/07/18 00:58:41 INFO Client: Application report for application_1491786134915_22121 (state: ACCEPTED)%%0001017/07/18 00:58:41 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310719917%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22121/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:58:42 INFO Client: Application report for application_1491786134915_22121 (state: ACCEPTED)%%0001017/07/18 00:58:42 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33726/user/YarnAM#216039712])%%0001017/07/18 00:58:42 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22121,http://hcnnc117:8088/proxy/application_1491786134915_22121), /proxy/application_1491786134915_22121%%0001017/07/18 00:58:42 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:58:43 INFO Client: Application report for application_1491786134915_22121 (state: RUNNING)%%0001017/07/18 00:58:43 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310719917%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22121/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:58:43 INFO YarnClientSchedulerBackend: Application application_1491786134915_22121 has started running.%%0001017/07/18 00:58:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37831.%%0001017/07/18 00:58:43 INFO NettyBlockTransferService: Server created on 37831%%0001017/07/18 00:58:43 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:58:43 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:58:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:37831 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 37831)%%0001017/07/18 00:58:43 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:58:43 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22121%%0001017/07/18 00:58:43 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:58:44 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:58:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:58:44 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:58:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:58:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:37831 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:58:44 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:58:44 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:58:44 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:58:44 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:58:44 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:58:44 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:58:44 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:58:44 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:58:44 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:58:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:58:44 INFO MemoryStore: ensureFreeSpace(3970) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:58:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:58:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:37831 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:58:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:58:44 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:58:46 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:58:47 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:58:48 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41894] &lt;- [akka.tcp://driverPropsFetcher@hcdnc322:45318]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc322:45318] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc322:45318%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:58:48 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc322:54212/user/Executor#899018777]) with ID 1%%0001017/07/18 00:58:48 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:58:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc322, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:58:49 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc322:37154 with 530.0 MB RAM, BlockManagerId(1, hcdnc322, 37154)%%0001017/07/18 00:58:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc322:37154 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:58:49 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41894] &lt;- [akka.tcp://driverPropsFetcher@hcdnc312:33440]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc312:33440] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc312:33440%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:58:49 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc312:40806/user/Executor#-955518488]) with ID 2%%0001017/07/18 00:58:49 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:58:49 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc312, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:58:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc322:37154 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:58:49 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc312:34149 with 530.0 MB RAM, BlockManagerId(2, hcdnc312, 34149)%%0001017/07/18 00:58:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc312:34149 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:58:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2760 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc312:34149 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:58:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 3844 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:53 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 8.531 s%%0001017/07/18 00:58:53 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:53 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 8.652188 s%%0001017/07/18 00:58:53 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:58:53 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:58:53 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:58:53 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:58:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:58:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:58:53 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:58:53 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237398, maxMem=556038881%%0001017/07/18 00:58:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 00:58:53 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246046, maxMem=556038881%%0001017/07/18 00:58:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:58:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:37831 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:58:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:58:53 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:58:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc312, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 00:58:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc322, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 00:58:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc312:34149 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:58:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc322:37154 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1406 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1418 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:55 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:55 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.419 s%%0001017/07/18 00:58:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:58:55 INFO DAGScheduler: running: Set()%%0001017/07/18 00:58:55 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:58:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:58:55 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251346, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258282, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:37831 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:58:55 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:58:55 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc312, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc322, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc312:34149 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc322:37154 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc312:40806%%0001017/07/18 00:58:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 00:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc322:54212%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 165 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 175 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:55 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:55 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.176 s%%0001017/07/18 00:58:55 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.627709 s%%0001017/07/18 00:58:55 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:58:55 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:58:55 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:58:55 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:58:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:58:55 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262325, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268845, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:37831 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:58:55 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:58:55 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc312, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc322, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc322:37154 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc312:34149 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 261 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 272 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:55 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:55 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.272 s%%0001017/07/18 00:58:55 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.285431 s%%0001017/07/18 00:58:55 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:58:55 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:58:55 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:58:55 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:58:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:58:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272747, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(4150) called with curMem=279923, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:37831 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:58:55 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:58:55 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc312, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc322, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc322:37154 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc312:34149 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 310 ms on hcdnc312 (1/2)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 330 ms on hcdnc322 (2/2)%%0001017/07/18 00:58:55 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:55 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.331 s%%0001017/07/18 00:58:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:58:55 INFO DAGScheduler: running: Set()%%0001017/07/18 00:58:55 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:58:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:58:55 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284073, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286857, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:37831 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:58:55 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:58:55 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc312, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc322, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc322:37154 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc312:34149 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:58:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc322:54212%%0001017/07/18 00:58:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:58:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc312:40806%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc322, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 36 ms on hcdnc322 (1/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc312, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 43 ms on hcdnc312 (2/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc322, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc322 (3/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc312, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc312 (4/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc322, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc322 (5/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc312, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 15 ms on hcdnc312 (6/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc322, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 11 ms on hcdnc322 (7/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc312, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 14 ms on hcdnc312 (8/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc322 (9/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 12 ms on hcdnc312 (10/10)%%0001017/07/18 00:58:56 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:56 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.092 s%%0001017/07/18 00:58:56 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.444636 s%%0001017/07/18 00:58:56 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:58:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 00:58:56 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:58:56 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:58:56 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:58:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:58:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:58:56 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:58:56 INFO MemoryStore: ensureFreeSpace(14040) called with curMem=288470, maxMem=556038881%%0001017/07/18 00:58:56 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:58:56 INFO MemoryStore: ensureFreeSpace(7748) called with curMem=302510, maxMem=556038881%%0001017/07/18 00:58:56 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:37831 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:58:56 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:58:56 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc312, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc322, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc312:34149 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc322:37154 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:58:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc312:40806%%0001017/07/18 00:58:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc322:54212%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1359 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1408 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:57 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:57 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.409 s%%0001017/07/18 00:58:57 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:58:57 INFO DAGScheduler: running: Set()%%0001017/07/18 00:58:57 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:58:57 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:58:57 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:58:57 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:58:57 INFO MemoryStore: ensureFreeSpace(17368) called with curMem=310258, maxMem=556038881%%0001017/07/18 00:58:57 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.0 KB, free 530.0 MB)%%0001017/07/18 00:58:57 INFO MemoryStore: ensureFreeSpace(9264) called with curMem=327626, maxMem=556038881%%0001017/07/18 00:58:57 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 00:58:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:37831 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 00:58:57 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:57 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:58:57 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc322, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc312, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc312:34149 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:58:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc322:37154 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:58:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc312:40806%%0001017/07/18 00:58:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 160 bytes%%0001017/07/18 00:58:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc322:54212%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc312, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 173 ms on hcdnc312 (1/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc322, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 199 ms on hcdnc322 (2/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc312, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 103 ms on hcdnc312 (3/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc322, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 106 ms on hcdnc322 (4/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc322, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 74 ms on hcdnc322 (5/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc312, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 107 ms on hcdnc312 (6/10)%%0001017/07/18 00:58:58 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc322, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:58 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 84 ms on hcdnc322 (7/10)%%0001017/07/18 00:58:58 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc312, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:58 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 93 ms on hcdnc312 (8/10)%%0001017/07/18 00:58:58 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 78 ms on hcdnc322 (9/10)%%0001017/07/18 00:58:58 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 92 ms on hcdnc312 (10/10)%%0001017/07/18 00:58:58 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:58 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.566 s%%0001017/07/18 00:58:58 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 2.006053 s%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:58:58 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:58:58 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:58:58 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:58:58 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:58:58 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:58:58 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:58:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41894] &lt;- [akka.tcp://sparkExecutor@hcdnc322:54212]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc322:54212] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc322:54212%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:58:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41894] &lt;- [akka.tcp://sparkExecutor@hcdnc312:40806]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc312:40806] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc312:40806%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:58:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:58:58 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:58:58 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:58:58 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:58:58 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:58:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:58:58 INFO Remoting: Remoting shut down%%0001017/07/18 00:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:58:59 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:58:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-945fd0ae-0b4b-41c7-9a8f-7098d62d7a82%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:59:11 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:59:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:59:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:59:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:59:12 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:59:12 INFO Remoting: Starting remoting%%0001017/07/18 00:59:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:34841]%%0001017/07/18 00:59:13 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:34841]%%0001017/07/18 00:59:13 INFO Utils: Successfully started service 'sparkDriver' on port 34841.%%0001017/07/18 00:59:13 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:59:13 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:59:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9f14e528-21e1-4be7-a76c-22f18b4d627b%%0001017/07/18 00:59:13 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:59:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-14ce477c-7bb9-41c0-bdc5-2999c553f9be/httpd-8eb7ca7c-89c7-4dec-ae6c-5d9ae0bbaeaf%%0001017/07/18 00:59:14 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:59:14 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:59:14 INFO AbstractConnector: Started SocketConnector@0.0.0.0:43666%%0001017/07/18 00:59:14 INFO Utils: Successfully started service 'HTTP file server' on port 43666.%%0001017/07/18 00:59:14 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:59:14 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:59:14 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:59:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:59:14 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:59:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:59:14 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:59:14 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:59:14 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:59:14 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:59:14 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:59:14 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:59:14 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:59:15 INFO Client: Uploading resource file:/tmp/spark-14ce477c-7bb9-41c0-bdc5-2999c553f9be/__spark_conf__3494930077158750309.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22122/__spark_conf__3494930077158750309.zip%%0001017/07/18 00:59:15 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:59:15 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:59:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:59:15 INFO Client: Submitting application 22122 to ResourceManager%%0001017/07/18 00:59:15 INFO YarnClientImpl: Submitted application application_1491786134915_22122%%0001017/07/18 00:59:16 INFO Client: Application report for application_1491786134915_22122 (state: ACCEPTED)%%0001017/07/18 00:59:16 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310755578%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22122/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:59:17 INFO Client: Application report for application_1491786134915_22122 (state: ACCEPTED)%%0001017/07/18 00:59:18 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:60450/user/YarnAM#1905483698])%%0001017/07/18 00:59:18 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22122,http://hcnnc117:8088/proxy/application_1491786134915_22122), /proxy/application_1491786134915_22122%%0001017/07/18 00:59:18 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:59:18 INFO Client: Application report for application_1491786134915_22122 (state: RUNNING)%%0001017/07/18 00:59:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310755578%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22122/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:59:18 INFO YarnClientSchedulerBackend: Application application_1491786134915_22122 has started running.%%0001017/07/18 00:59:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37958.%%0001017/07/18 00:59:18 INFO NettyBlockTransferService: Server created on 37958%%0001017/07/18 00:59:18 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:59:18 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:59:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:37958 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 37958)%%0001017/07/18 00:59:18 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:59:19 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22122%%0001017/07/18 00:59:19 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:59:20 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:59:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:59:20 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:59:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:59:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:37958 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:59:20 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:59:20 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:59:20 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:59:20 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:59:20 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:59:20 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:59:20 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:59:20 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:59:20 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:59:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:59:20 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:59:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:59:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:37958 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:59:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:59:20 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:59:21 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:59:22 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:59:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34841] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:35275]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:35275] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:35275%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:24 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:47483/user/Executor#-687957287]) with ID 1%%0001017/07/18 00:59:24 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:59:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:59:24 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:55907 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 55907)%%0001017/07/18 00:59:25 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34841] &lt;- [akka.tcp://driverPropsFetcher@hcdnc301:50503]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc301:50503] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc301:50503%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:55907 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:25 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc301:37815/user/Executor#1886793639]) with ID 2%%0001017/07/18 00:59:25 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:59:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc301, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:59:25 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc301:42911 with 530.0 MB RAM, BlockManagerId(2, hcdnc301, 42911)%%0001017/07/18 00:59:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:55907 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:59:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc301:42911 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc301:42911 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:59:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3078 ms on hcdnc310 (1/2)%%0001017/07/18 00:59:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2534 ms on hcdnc301 (2/2)%%0001017/07/18 00:59:27 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.493 s%%0001017/07/18 00:59:27 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:27 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.620983 s%%0001017/07/18 00:59:27 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:59:27 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:59:27 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:59:27 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:59:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:59:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:59:27 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:59:27 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 00:59:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 00:59:27 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246045, maxMem=556038881%%0001017/07/18 00:59:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:59:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:37958 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:59:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:59:27 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:59:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 00:59:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc301, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 00:59:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc301:42911 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:59:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:55907 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1363 ms on hcdnc301 (1/2)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1463 ms on hcdnc310 (2/2)%%0001017/07/18 00:59:29 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:29 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.464 s%%0001017/07/18 00:59:29 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:59:29 INFO DAGScheduler: running: Set()%%0001017/07/18 00:59:29 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:59:29 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:59:29 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251347, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(4044) called with curMem=258283, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:37958 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:59:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:59:29 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc301, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:55907 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc301:42911 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc301:37815%%0001017/07/18 00:59:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:59:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:47483%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on hcdnc310 (1/2)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 170 ms on hcdnc301 (2/2)%%0001017/07/18 00:59:29 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:29 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.171 s%%0001017/07/18 00:59:29 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.666344 s%%0001017/07/18 00:59:29 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:59:29 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:59:29 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:59:29 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:59:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:59:29 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262327, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268847, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:37958 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:59:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:59:29 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc301, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:55907 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc301:42911 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 212 ms on hcdnc301 (1/2)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 218 ms on hcdnc310 (2/2)%%0001017/07/18 00:59:29 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:29 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.219 s%%0001017/07/18 00:59:29 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.233994 s%%0001017/07/18 00:59:29 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:59:29 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:59:29 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:59:29 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:59:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:59:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272749, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(4151) called with curMem=279925, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:37958 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:59:29 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:59:29 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc301, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:55907 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc301:42911 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 289 ms on hcdnc301 (1/2)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 297 ms on hcdnc310 (2/2)%%0001017/07/18 00:59:30 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:30 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.297 s%%0001017/07/18 00:59:30 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:59:30 INFO DAGScheduler: running: Set()%%0001017/07/18 00:59:30 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:59:30 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:59:30 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:59:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:59:30 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284076, maxMem=556038881%%0001017/07/18 00:59:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:59:30 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286860, maxMem=556038881%%0001017/07/18 00:59:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:37958 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:59:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:59:30 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc301, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc301:42911 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:55907 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc301:37815%%0001017/07/18 00:59:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:59:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:47483%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc301, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc301 (1/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc310 (2/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc301, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc301 (3/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 18 ms on hcdnc310 (4/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc301, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc301 (5/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc310 (6/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc301, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc301 (7/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 12 ms on hcdnc310 (8/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 12 ms on hcdnc301 (9/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc310 (10/10)%%0001017/07/18 00:59:30 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:59:30 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:30 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.420535 s%%0001017/07/18 00:59:30 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:59:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:59:30 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:59:30 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:59:30 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:59:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:59:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:59:30 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:59:30 INFO MemoryStore: ensureFreeSpace(14040) called with curMem=288473, maxMem=556038881%%0001017/07/18 00:59:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:59:30 INFO MemoryStore: ensureFreeSpace(7754) called with curMem=302513, maxMem=556038881%%0001017/07/18 00:59:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:37958 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:59:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:59:30 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc301, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc301:42911 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:55907 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc301:37815%%0001017/07/18 00:59:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:47483%%0001017/07/18 00:59:31 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1405 ms on hcdnc310 (1/2)%%0001017/07/18 00:59:31 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1418 ms on hcdnc301 (2/2)%%0001017/07/18 00:59:31 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:31 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.420 s%%0001017/07/18 00:59:31 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:59:31 INFO DAGScheduler: running: Set()%%0001017/07/18 00:59:31 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:59:31 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:59:31 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:59:31 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:59:31 INFO MemoryStore: ensureFreeSpace(17368) called with curMem=310267, maxMem=556038881%%0001017/07/18 00:59:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.0 KB, free 530.0 MB)%%0001017/07/18 00:59:31 INFO MemoryStore: ensureFreeSpace(9273) called with curMem=327635, maxMem=556038881%%0001017/07/18 00:59:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 530.0 MB)%%0001017/07/18 00:59:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:37958 (size: 9.1 KB, free: 530.2 MB)%%0001017/07/18 00:59:31 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:31 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:59:31 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:59:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:31 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc301, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc301:42911 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 00:59:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:55907 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 00:59:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc301:37815%%0001017/07/18 00:59:31 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:59:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:47483%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc301, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 172 ms on hcdnc301 (1/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 183 ms on hcdnc310 (2/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc301, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 98 ms on hcdnc301 (3/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 109 ms on hcdnc310 (4/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc301, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 92 ms on hcdnc301 (5/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 78 ms on hcdnc310 (6/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 83 ms on hcdnc310 (7/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc301, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 94 ms on hcdnc301 (8/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 70 ms on hcdnc310 (9/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 90 ms on hcdnc301 (10/10)%%0001017/07/18 00:59:32 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:32 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.544 s%%0001017/07/18 00:59:32 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 2.009967 s%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:59:32 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:59:32 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:59:32 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:59:32 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:59:32 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:59:32 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:59:32 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34841] &lt;- [akka.tcp://sparkExecutor@hcdnc301:37815]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc301:37815] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc301:37815%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:32 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34841] &lt;- [akka.tcp://sparkExecutor@hcdnc310:47483]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:47483] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:47483%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:59:32 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:59:32 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:59:32 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:59:32 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:59:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:59:32 INFO Remoting: Remoting shut down%%0001017/07/18 00:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:59:33 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:59:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-14ce477c-7bb9-41c0-bdc5-2999c553f9be%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:59:46 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:59:47 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:59:47 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:59:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:59:48 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:59:48 INFO Remoting: Starting remoting%%0001017/07/18 00:59:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46322]%%0001017/07/18 00:59:48 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46322]%%0001017/07/18 00:59:48 INFO Utils: Successfully started service 'sparkDriver' on port 46322.%%0001017/07/18 00:59:48 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:59:48 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:59:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d5ed5769-52e5-4ab2-962c-7ac721f4b93a%%0001017/07/18 00:59:48 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:59:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-69c136b8-a39c-41bb-ac99-5507670550d4/httpd-fecbdb6d-8e88-4a1a-9a50-9abb2a1f5941%%0001017/07/18 00:59:48 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:59:48 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:59:48 INFO AbstractConnector: Started SocketConnector@0.0.0.0:37553%%0001017/07/18 00:59:48 INFO Utils: Successfully started service 'HTTP file server' on port 37553.%%0001017/07/18 00:59:48 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:59:48 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:59:48 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:59:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:59:48 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:59:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:59:49 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:59:49 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:59:49 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:59:49 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:59:49 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:59:49 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:59:49 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:59:49 INFO Client: Uploading resource file:/tmp/spark-69c136b8-a39c-41bb-ac99-5507670550d4/__spark_conf__3794827948942308694.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22123/__spark_conf__3794827948942308694.zip%%0001017/07/18 00:59:49 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:59:49 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:59:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:59:50 INFO Client: Submitting application 22123 to ResourceManager%%0001017/07/18 00:59:50 INFO YarnClientImpl: Submitted application application_1491786134915_22123%%0001017/07/18 00:59:51 INFO Client: Application report for application_1491786134915_22123 (state: ACCEPTED)%%0001017/07/18 00:59:51 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310790015%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22123/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:59:52 INFO Client: Application report for application_1491786134915_22123 (state: ACCEPTED)%%0001017/07/18 00:59:52 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:48755/user/YarnAM#726856124])%%0001017/07/18 00:59:52 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22123,http://hcnnc117:8088/proxy/application_1491786134915_22123), /proxy/application_1491786134915_22123%%0001017/07/18 00:59:52 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:59:53 INFO Client: Application report for application_1491786134915_22123 (state: RUNNING)%%0001017/07/18 00:59:53 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310790015%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22123/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:59:53 INFO YarnClientSchedulerBackend: Application application_1491786134915_22123 has started running.%%0001017/07/18 00:59:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44610.%%0001017/07/18 00:59:53 INFO NettyBlockTransferService: Server created on 44610%%0001017/07/18 00:59:53 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:59:53 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:59:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:44610 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 44610)%%0001017/07/18 00:59:53 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:59:54 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22123%%0001017/07/18 00:59:54 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:59:54 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:59:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:59:54 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:59:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:59:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:44610 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:59:54 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:59:54 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:59:54 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:59:54 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:59:54 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:59:54 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:59:54 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:59:54 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:59:54 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:59:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:59:54 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:59:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:59:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:44610 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:59:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:59:54 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:59:55 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:59:56 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:59:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46322] &lt;- [akka.tcp://driverPropsFetcher@hcdnc306:57979]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:57979] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:57979%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:58 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc306:45851/user/Executor#-731006208]) with ID 1%%0001017/07/18 00:59:58 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:59:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc306, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:59:58 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc306:42233 with 530.0 MB RAM, BlockManagerId(1, hcdnc306, 42233)%%0001017/07/18 00:59:59 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46322] &lt;- [akka.tcp://driverPropsFetcher@hcdnc332:43046]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc332:43046] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc332:43046%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc306:42233 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:59 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc332:39807/user/Executor#-1990043594]) with ID 2%%0001017/07/18 00:59:59 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:59:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc332, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:59:59 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc332:49447 with 530.0 MB RAM, BlockManagerId(2, hcdnc332, 49447)%%0001017/07/18 00:59:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc306:42233 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:59:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc332:49447 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc332:49447 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2613 ms on hcdnc306 (1/2)%%0001017/07/18 01:00:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2645 ms on hcdnc332 (2/2)%%0001017/07/18 01:00:02 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:02 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.177 s%%0001017/07/18 01:00:02 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.297618 s%%0001017/07/18 01:00:02 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:00:02 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:00:02 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:00:02 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:00:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:00:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:00:02 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:00:02 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:00:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:00:02 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:00:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:00:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:44610 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:00:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:00:02 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:00:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc306, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:00:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc332, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:00:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc332:49447 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:00:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc306:42233 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:00:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1386 ms on hcdnc332 (1/2)%%0001017/07/18 01:00:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1445 ms on hcdnc306 (2/2)%%0001017/07/18 01:00:03 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:03 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.445 s%%0001017/07/18 01:00:03 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:03 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:03 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:00:03 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:03 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:00:03 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:00:03 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:00:03 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:00:03 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:00:03 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:44610 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:00:03 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:00:03 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:00:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc332, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc306:42233 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc332:49447 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc332:39807%%0001017/07/18 01:00:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:00:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:45851%%0001017/07/18 01:00:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 157 ms on hcdnc332 (1/2)%%0001017/07/18 01:00:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 161 ms on hcdnc306 (2/2)%%0001017/07/18 01:00:03 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:03 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.162 s%%0001017/07/18 01:00:03 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.640625 s%%0001017/07/18 01:00:03 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:00:03 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:00:03 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:00:03 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:00:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:00:03 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:00:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:00:03 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:00:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:00:03 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:00:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:44610 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:00:03 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:00:03 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:00:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:03 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc306, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc306:42233 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc332:49447 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 219 ms on hcdnc332 (1/2)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 241 ms on hcdnc306 (2/2)%%0001017/07/18 01:00:04 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:04 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.243 s%%0001017/07/18 01:00:04 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.255927 s%%0001017/07/18 01:00:04 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:00:04 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:00:04 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:00:04 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:00:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:00:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:44610 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:00:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:00:04 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc332, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc306, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc306:42233 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc332:49447 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 293 ms on hcdnc306 (1/2)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 294 ms on hcdnc332 (2/2)%%0001017/07/18 01:00:04 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:04 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.295 s%%0001017/07/18 01:00:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:04 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:04 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:00:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:04 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:44610 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:00:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:00:04 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc306, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc306:42233 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc332:49447 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc306:45851%%0001017/07/18 01:00:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 01:00:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc332:39807%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc332, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc306, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 47 ms on hcdnc332 (1/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc306 (2/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc306, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc332, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc306 (3/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 18 ms on hcdnc332 (4/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc332, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc306, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc332 (5/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc306 (6/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc332, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc332 (7/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc306, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc306 (8/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 12 ms on hcdnc332 (9/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc306 (10/10)%%0001017/07/18 01:00:04 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:00:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:04 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.421983 s%%0001017/07/18 01:00:04 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:00:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:00:04 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:00:04 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:00:04 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:00:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:00:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(14040) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(7745) called with curMem=302508, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:44610 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:00:04 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:00:04 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc306, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc332, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc306:42233 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc332:49447 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:45851%%0001017/07/18 01:00:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc332:39807%%0001017/07/18 01:00:05 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1385 ms on hcdnc306 (1/2)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1423 ms on hcdnc332 (2/2)%%0001017/07/18 01:00:06 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:06 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.425 s%%0001017/07/18 01:00:06 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:06 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:06 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:00:06 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:06 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:00:06 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:00:06 INFO MemoryStore: ensureFreeSpace(17368) called with curMem=310253, maxMem=556038881%%0001017/07/18 01:00:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.0 KB, free 530.0 MB)%%0001017/07/18 01:00:06 INFO MemoryStore: ensureFreeSpace(9263) called with curMem=327621, maxMem=556038881%%0001017/07/18 01:00:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 01:00:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:44610 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 01:00:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:06 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:00:06 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc332, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc332:49447 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 01:00:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc306:42233 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 01:00:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc332:39807%%0001017/07/18 01:00:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 01:00:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc306:45851%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc332, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 186 ms on hcdnc332 (1/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc306, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 202 ms on hcdnc306 (2/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc332, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 102 ms on hcdnc332 (3/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc306, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 116 ms on hcdnc306 (4/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc332, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 106 ms on hcdnc332 (5/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc306, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 97 ms on hcdnc306 (6/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc332, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 93 ms on hcdnc332 (7/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc306, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 90 ms on hcdnc306 (8/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 84 ms on hcdnc332 (9/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 108 ms on hcdnc306 (10/10)%%0001017/07/18 01:00:06 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:06 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.609 s%%0001017/07/18 01:00:06 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 2.061650 s%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:00:06 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:00:06 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:00:06 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:00:06 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:00:06 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:00:06 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:00:06 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46322] &lt;- [akka.tcp://sparkExecutor@hcdnc306:45851]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc306:45851] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc306:45851%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:06 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46322] &lt;- [akka.tcp://sparkExecutor@hcdnc332:39807]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc332:39807] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc332:39807%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:00:07 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:00:07 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:00:07 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:00:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:00:07 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:00:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:00:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:00:07 INFO Remoting: Remoting shut down%%0001017/07/18 01:00:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:00:07 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:00:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-69c136b8-a39c-41bb-ac99-5507670550d4/pyspark-120512f4-97ed-4e5c-9946-281910c82162%%0001017/07/18 01:00:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-69c136b8-a39c-41bb-ac99-5507670550d4%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:00:20 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:00:21 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:00:21 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:00:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:00:22 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:00:22 INFO Remoting: Starting remoting%%0001017/07/18 01:00:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38334]%%0001017/07/18 01:00:22 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38334]%%0001017/07/18 01:00:22 INFO Utils: Successfully started service 'sparkDriver' on port 38334.%%0001017/07/18 01:00:22 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:00:22 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:00:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9d4612b9-d133-4de7-a071-93eabce92373%%0001017/07/18 01:00:22 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:00:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-db4ae7f2-6ef3-4c18-b1f4-d7d9562b2ddb/httpd-629b969e-6340-408c-a5e1-d7ae96bbf04b%%0001017/07/18 01:00:23 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:00:23 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:00:23 INFO AbstractConnector: Started SocketConnector@0.0.0.0:41736%%0001017/07/18 01:00:23 INFO Utils: Successfully started service 'HTTP file server' on port 41736.%%0001017/07/18 01:00:23 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:00:23 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:00:23 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:00:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:00:23 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:00:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:00:23 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:00:23 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:00:23 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:00:23 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:00:23 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:00:23 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:00:23 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:00:24 INFO Client: Uploading resource file:/tmp/spark-db4ae7f2-6ef3-4c18-b1f4-d7d9562b2ddb/__spark_conf__8308912685360785187.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22124/__spark_conf__8308912685360785187.zip%%0001017/07/18 01:00:24 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:00:24 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:00:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:00:24 INFO Client: Submitting application 22124 to ResourceManager%%0001017/07/18 01:00:24 INFO YarnClientImpl: Submitted application application_1491786134915_22124%%0001017/07/18 01:00:25 INFO Client: Application report for application_1491786134915_22124 (state: ACCEPTED)%%0001017/07/18 01:00:25 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310824404%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22124/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:00:26 INFO Client: Application report for application_1491786134915_22124 (state: ACCEPTED)%%0001017/07/18 01:00:27 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:46039/user/YarnAM#1846180369])%%0001017/07/18 01:00:27 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22124,http://hcnnc117:8088/proxy/application_1491786134915_22124), /proxy/application_1491786134915_22124%%0001017/07/18 01:00:27 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:00:27 INFO Client: Application report for application_1491786134915_22124 (state: RUNNING)%%0001017/07/18 01:00:27 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310824404%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22124/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:00:27 INFO YarnClientSchedulerBackend: Application application_1491786134915_22124 has started running.%%0001017/07/18 01:00:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36384.%%0001017/07/18 01:00:28 INFO NettyBlockTransferService: Server created on 36384%%0001017/07/18 01:00:28 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:00:28 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:00:28 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:36384 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 36384)%%0001017/07/18 01:00:28 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:00:29 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22124%%0001017/07/18 01:00:29 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:00:30 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:00:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:00:30 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:00:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:00:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:36384 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:00:30 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:00:30 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:00:30 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:00:30 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:00:30 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:00:30 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:00:30 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:00:30 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:00:30 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:00:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:00:30 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:00:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:00:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:36384 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:00:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:00:30 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:00:31 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:00:32 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:00:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38334] &lt;- [akka.tcp://driverPropsFetcher@hcdnc317:37184]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc317:37184] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc317:37184%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:34 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc317:34686/user/Executor#-1375685926]) with ID 1%%0001017/07/18 01:00:34 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:00:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc317, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:00:34 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc317:38934 with 530.0 MB RAM, BlockManagerId(1, hcdnc317, 38934)%%0001017/07/18 01:00:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38334] &lt;- [akka.tcp://driverPropsFetcher@hcdnc829:42919]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc829:42919] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc829:42919%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc317:38934 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:35 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc829:40549/user/Executor#-623538127]) with ID 2%%0001017/07/18 01:00:35 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:00:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc829, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:00:35 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc829:52881 with 530.0 MB RAM, BlockManagerId(2, hcdnc829, 52881)%%0001017/07/18 01:00:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc317:38934 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc829:52881 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc829:52881 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2532 ms on hcdnc317 (1/2)%%0001017/07/18 01:00:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2567 ms on hcdnc829 (2/2)%%0001017/07/18 01:00:37 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.143 s%%0001017/07/18 01:00:37 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:37 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.263072 s%%0001017/07/18 01:00:37 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:00:37 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:00:37 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:00:37 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:00:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:00:37 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:00:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:00:37 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:00:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:00:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:36384 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:00:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:00:37 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:00:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc829, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:00:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc317, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:00:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc829:52881 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:00:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc317:38934 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1357 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1374 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:39 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.376 s%%0001017/07/18 01:00:39 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:39 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:39 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:39 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:00:39 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:39 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251347, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(4044) called with curMem=258283, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:36384 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:00:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:00:39 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc317, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc829, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc317:38934 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc829:52881 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc317:34686%%0001017/07/18 01:00:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc829:40549%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 160 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 163 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:39 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:39 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.164 s%%0001017/07/18 01:00:39 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.571603 s%%0001017/07/18 01:00:39 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:00:39 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:00:39 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:00:39 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:00:39 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262327, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268847, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:36384 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:00:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:00:39 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc317, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc829, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc829:52881 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc317:38934 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 227 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 237 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:39 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:39 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.238 s%%0001017/07/18 01:00:39 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.251470 s%%0001017/07/18 01:00:39 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:00:39 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:00:39 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:00:39 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:00:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272749, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279925, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:36384 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:00:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:00:39 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc829, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc317, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc317:38934 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc829:52881 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 302 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 316 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:39 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:39 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.319 s%%0001017/07/18 01:00:39 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:39 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:39 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:00:39 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:39 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284074, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286858, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:36384 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:00:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:00:39 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc317, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc829, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc829:52881 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc317:38934 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc829:40549%%0001017/07/18 01:00:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 167 bytes%%0001017/07/18 01:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc317:34686%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc829, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 44 ms on hcdnc829 (1/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc317, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 48 ms on hcdnc317 (2/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc829, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc317, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 19 ms on hcdnc829 (3/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 18 ms on hcdnc317 (4/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc317, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 14 ms on hcdnc317 (5/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc829, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc829 (6/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc829, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc317, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc829 (7/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 17 ms on hcdnc317 (8/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc829 (9/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc317 (10/10)%%0001017/07/18 01:00:40 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:00:40 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:40 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.444318 s%%0001017/07/18 01:00:40 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:00:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:00:40 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:00:40 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:00:40 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:00:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:00:40 INFO MemoryStore: ensureFreeSpace(12960) called with curMem=288471, maxMem=556038881%%0001017/07/18 01:00:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:00:40 INFO MemoryStore: ensureFreeSpace(7129) called with curMem=301431, maxMem=556038881%%0001017/07/18 01:00:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:00:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:36384 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:00:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:00:40 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc829, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc317, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc829:52881 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:00:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc317:38934 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc317:34686%%0001017/07/18 01:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc829:40549%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1154 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1179 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:41 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:41 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.180 s%%0001017/07/18 01:00:41 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:41 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:41 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:00:41 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:41 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:00:41 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:00:41 INFO MemoryStore: ensureFreeSpace(16040) called with curMem=308560, maxMem=556038881%%0001017/07/18 01:00:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:00:41 INFO MemoryStore: ensureFreeSpace(8485) called with curMem=324600, maxMem=556038881%%0001017/07/18 01:00:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:00:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:36384 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:00:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:00:41 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc829, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc317, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc317:38934 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc829:52881 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc829:40549%%0001017/07/18 01:00:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 158 bytes%%0001017/07/18 01:00:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc317:34686%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc829, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 157 ms on hcdnc829 (1/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc317, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 164 ms on hcdnc317 (2/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc829, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 95 ms on hcdnc829 (3/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc317, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 91 ms on hcdnc317 (4/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc317, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 76 ms on hcdnc317 (5/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc829, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 81 ms on hcdnc829 (6/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc317, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 84 ms on hcdnc317 (7/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc829, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 85 ms on hcdnc829 (8/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 77 ms on hcdnc317 (9/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 85 ms on hcdnc829 (10/10)%%0001017/07/18 01:00:41 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:41 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.499 s%%0001017/07/18 01:00:41 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.706801 s%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:00:42 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:00:42 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:00:42 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:00:42 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:00:42 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:00:42 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:00:42 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38334] &lt;- [akka.tcp://sparkExecutor@hcdnc317:34686]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc317:34686] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc317:34686%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:42 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38334] &lt;- [akka.tcp://sparkExecutor@hcdnc829:40549]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc829:40549] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc829:40549%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:00:42 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:00:42 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:00:42 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:00:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:00:42 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:00:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:00:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:00:42 INFO Remoting: Remoting shut down%%0001017/07/18 01:00:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:00:42 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:00:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-db4ae7f2-6ef3-4c18-b1f4-d7d9562b2ddb%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:00:56 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:00:57 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:00:57 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:00:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:00:57 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:00:57 INFO Remoting: Starting remoting%%0001017/07/18 01:00:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38063]%%0001017/07/18 01:00:57 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38063]%%0001017/07/18 01:00:57 INFO Utils: Successfully started service 'sparkDriver' on port 38063.%%0001017/07/18 01:00:57 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:00:57 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:00:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d29de68e-9175-4593-b9da-48a253aeb042%%0001017/07/18 01:00:57 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:00:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-5f98fef7-5c07-4074-a1fb-4fc9d3ed32a5/httpd-6d927e21-f266-4c0a-bee1-197589e4ce0f%%0001017/07/18 01:00:58 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:00:58 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:00:58 INFO AbstractConnector: Started SocketConnector@0.0.0.0:41321%%0001017/07/18 01:00:58 INFO Utils: Successfully started service 'HTTP file server' on port 41321.%%0001017/07/18 01:00:58 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:00:58 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:00:59 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:00:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:00:59 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:00:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:00:59 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:00:59 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:00:59 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:00:59 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:00:59 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:00:59 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:00:59 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:01:05 INFO Client: Uploading resource file:/tmp/spark-5f98fef7-5c07-4074-a1fb-4fc9d3ed32a5/__spark_conf__4023830525756384668.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22125/__spark_conf__4023830525756384668.zip%%0001017/07/18 01:01:05 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:01:05 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:01:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:01:05 INFO Client: Submitting application 22125 to ResourceManager%%0001017/07/18 01:01:05 INFO YarnClientImpl: Submitted application application_1491786134915_22125%%0001017/07/18 01:01:06 INFO Client: Application report for application_1491786134915_22125 (state: ACCEPTED)%%0001017/07/18 01:01:06 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310865461%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22125/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:01:07 INFO Client: Application report for application_1491786134915_22125 (state: ACCEPTED)%%0001017/07/18 01:01:08 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:59844/user/YarnAM#327302571])%%0001017/07/18 01:01:08 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22125,http://hcnnc117:8088/proxy/application_1491786134915_22125), /proxy/application_1491786134915_22125%%0001017/07/18 01:01:08 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:01:08 INFO Client: Application report for application_1491786134915_22125 (state: RUNNING)%%0001017/07/18 01:01:08 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310865461%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22125/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:01:08 INFO YarnClientSchedulerBackend: Application application_1491786134915_22125 has started running.%%0001017/07/18 01:01:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38815.%%0001017/07/18 01:01:08 INFO NettyBlockTransferService: Server created on 38815%%0001017/07/18 01:01:08 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:01:08 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:01:08 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:38815 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 38815)%%0001017/07/18 01:01:08 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:01:09 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22125%%0001017/07/18 01:01:09 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:01:09 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:01:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:01:09 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:01:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:01:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:38815 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:01:09 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:01:09 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:01:09 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:01:09 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:01:09 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:01:09 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:01:09 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:01:09 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:01:09 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:01:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:01:09 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:01:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:01:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:38815 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:01:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:01:09 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:01:10 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:01:11 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:01:13 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38063] &lt;- [akka.tcp://driverPropsFetcher@hcdnc307:50881]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc307:50881] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc307:50881%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:13 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc307:34044/user/Executor#-1553745944]) with ID 1%%0001017/07/18 01:01:13 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:01:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc307, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:01:13 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc307:37015 with 530.0 MB RAM, BlockManagerId(1, hcdnc307, 37015)%%0001017/07/18 01:01:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc307:37015 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:14 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38063] &lt;- [akka.tcp://driverPropsFetcher@hcdnc302:51351]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc302:51351] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc302:51351%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:14 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc302:53448/user/Executor#-730180379]) with ID 2%%0001017/07/18 01:01:14 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:01:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc302, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:01:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc307:37015 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:14 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc302:35937 with 530.0 MB RAM, BlockManagerId(2, hcdnc302, 35937)%%0001017/07/18 01:01:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc302:35937 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc302:35937 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2502 ms on hcdnc307 (1/2)%%0001017/07/18 01:01:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2716 ms on hcdnc302 (2/2)%%0001017/07/18 01:01:17 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.290 s%%0001017/07/18 01:01:17 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:17 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.417031 s%%0001017/07/18 01:01:17 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:01:17 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:01:17 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:01:17 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:01:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:01:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:01:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:01:17 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:01:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:01:17 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:01:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:01:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:38815 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:01:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:01:17 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:01:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc302, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:01:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc307, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:01:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc302:35937 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:01:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc307:37015 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:01:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1391 ms on hcdnc307 (1/2)%%0001017/07/18 01:01:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1461 ms on hcdnc302 (2/2)%%0001017/07/18 01:01:18 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:18 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.462 s%%0001017/07/18 01:01:18 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:18 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:18 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:01:18 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:18 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:01:18 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:01:18 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:01:18 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:01:18 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:01:18 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:38815 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:01:18 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:01:18 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:01:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc302, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc302:35937 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc307:37015 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc302:53448%%0001017/07/18 01:01:18 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:01:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc307:34044%%0001017/07/18 01:01:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 166 ms on hcdnc302 (1/2)%%0001017/07/18 01:01:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on hcdnc307 (2/2)%%0001017/07/18 01:01:18 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:18 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.169 s%%0001017/07/18 01:01:18 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.662871 s%%0001017/07/18 01:01:18 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:01:18 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:01:18 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:01:18 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:01:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:01:18 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:01:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:01:18 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:01:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:01:18 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:01:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:38815 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:01:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:01:18 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:01:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc307, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:18 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc302, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc307:37015 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc302:35937 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 210 ms on hcdnc307 (1/2)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 214 ms on hcdnc302 (2/2)%%0001017/07/18 01:01:19 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.215 s%%0001017/07/18 01:01:19 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:19 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.227653 s%%0001017/07/18 01:01:19 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:01:19 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:01:19 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:01:19 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:01:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:01:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:38815 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:01:19 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:01:19 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc307, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc302, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc302:35937 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc307:37015 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 289 ms on hcdnc302 (1/2)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 301 ms on hcdnc307 (2/2)%%0001017/07/18 01:01:19 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:19 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.301 s%%0001017/07/18 01:01:19 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:19 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:19 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:01:19 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:19 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:38815 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:01:19 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:01:19 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc302, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc302:35937 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc307:37015 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc302:53448%%0001017/07/18 01:01:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:01:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc307:34044%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc302, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc302 (1/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc307, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc307 (2/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc302, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc302 (3/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc307, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc307 (4/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc302, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc302 (5/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc307, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc307 (6/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc302, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc302 (7/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc307, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc307 (8/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc302 (9/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc307 (10/10)%%0001017/07/18 01:01:19 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 01:01:19 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:19 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.425487 s%%0001017/07/18 01:01:19 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:01:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:01:19 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:01:19 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:01:19 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:01:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:01:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(12960) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(7122) called with curMem=301428, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:38815 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:01:19 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:01:19 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc302, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc307, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc302:35937 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc307:37015 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc307:34044%%0001017/07/18 01:01:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc302:53448%%0001017/07/18 01:01:20 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1133 ms on hcdnc307 (1/2)%%0001017/07/18 01:01:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1169 ms on hcdnc302 (2/2)%%0001017/07/18 01:01:20 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:20 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.170 s%%0001017/07/18 01:01:20 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:20 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:20 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:01:20 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:20 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:01:20 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:01:20 INFO MemoryStore: ensureFreeSpace(16040) called with curMem=308550, maxMem=556038881%%0001017/07/18 01:01:20 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:01:20 INFO MemoryStore: ensureFreeSpace(8479) called with curMem=324590, maxMem=556038881%%0001017/07/18 01:01:20 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:01:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:38815 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:01:20 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:20 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:01:20 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:01:20 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc307, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:20 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc302, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc307:37015 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc302:35937 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc307:34044%%0001017/07/18 01:01:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 156 bytes%%0001017/07/18 01:01:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc302:53448%%0001017/07/18 01:01:20 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc302, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:20 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 147 ms on hcdnc302 (1/10)%%0001017/07/18 01:01:20 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc307, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:20 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 177 ms on hcdnc307 (2/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc302, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 92 ms on hcdnc302 (3/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc307, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 90 ms on hcdnc307 (4/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc302, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 83 ms on hcdnc302 (5/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc307, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 82 ms on hcdnc307 (6/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc302, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 68 ms on hcdnc302 (7/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc307, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 81 ms on hcdnc307 (8/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 70 ms on hcdnc302 (9/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 82 ms on hcdnc307 (10/10)%%0001017/07/18 01:01:21 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:21 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.510 s%%0001017/07/18 01:01:21 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.706753 s%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:01:21 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:01:21 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:01:21 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:01:21 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:01:21 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:01:21 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:01:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38063] &lt;- [akka.tcp://sparkExecutor@hcdnc302:53448]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc302:53448] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc302:53448%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38063] &lt;- [akka.tcp://sparkExecutor@hcdnc307:34044]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc307:34044] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc307:34044%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:01:21 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:01:21 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:01:21 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:01:21 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:01:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:01:21 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:01:21 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:01:21 INFO Remoting: Remoting shut down%%0001017/07/18 01:01:21 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:01:22 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:01:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-5f98fef7-5c07-4074-a1fb-4fc9d3ed32a5/pyspark-bc39a5e1-6e1f-41ae-b196-3d60b85a0e9c%%0001017/07/18 01:01:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-5f98fef7-5c07-4074-a1fb-4fc9d3ed32a5%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:01:36 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:01:36 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:01:36 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:01:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:01:37 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:01:37 INFO Remoting: Starting remoting%%0001017/07/18 01:01:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38398]%%0001017/07/18 01:01:37 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38398]%%0001017/07/18 01:01:37 INFO Utils: Successfully started service 'sparkDriver' on port 38398.%%0001017/07/18 01:01:37 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:01:37 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:01:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e6d2321a-0f4a-49de-bf29-48e2623acdc4%%0001017/07/18 01:01:37 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:01:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3ac9960f-6317-48e8-bcc6-c426506c2750/httpd-c1625aa5-f9d5-4089-a635-2868dea4831f%%0001017/07/18 01:01:37 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:01:37 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:01:37 INFO AbstractConnector: Started SocketConnector@0.0.0.0:38083%%0001017/07/18 01:01:37 INFO Utils: Successfully started service 'HTTP file server' on port 38083.%%0001017/07/18 01:01:37 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:01:37 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:01:38 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:01:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:01:38 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:01:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:01:39 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:01:39 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:01:39 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:01:39 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:01:39 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:01:39 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:01:39 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:01:39 INFO Client: Uploading resource file:/tmp/spark-3ac9960f-6317-48e8-bcc6-c426506c2750/__spark_conf__4234702571674566785.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22126/__spark_conf__4234702571674566785.zip%%0001017/07/18 01:01:40 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:01:40 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:01:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:01:40 INFO Client: Submitting application 22126 to ResourceManager%%0001017/07/18 01:01:40 INFO YarnClientImpl: Submitted application application_1491786134915_22126%%0001017/07/18 01:01:41 INFO Client: Application report for application_1491786134915_22126 (state: ACCEPTED)%%0001017/07/18 01:01:41 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310900025%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22126/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:01:42 INFO Client: Application report for application_1491786134915_22126 (state: ACCEPTED)%%0001017/07/18 01:01:42 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:53623/user/YarnAM#2101407535])%%0001017/07/18 01:01:42 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22126,http://hcnnc117:8088/proxy/application_1491786134915_22126), /proxy/application_1491786134915_22126%%0001017/07/18 01:01:42 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:01:43 INFO Client: Application report for application_1491786134915_22126 (state: RUNNING)%%0001017/07/18 01:01:43 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310900025%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22126/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:01:43 INFO YarnClientSchedulerBackend: Application application_1491786134915_22126 has started running.%%0001017/07/18 01:01:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46768.%%0001017/07/18 01:01:43 INFO NettyBlockTransferService: Server created on 46768%%0001017/07/18 01:01:43 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:01:43 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:01:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:46768 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 46768)%%0001017/07/18 01:01:43 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:01:43 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22126%%0001017/07/18 01:01:43 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:01:44 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:01:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:01:44 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:01:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:01:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:46768 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:01:44 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:01:44 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:01:44 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:01:44 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:01:44 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:01:44 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:01:44 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:01:44 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:01:44 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:01:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:01:44 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:01:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:01:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:46768 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:01:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:01:44 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:01:45 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:01:46 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:01:47 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38398] &lt;- [akka.tcp://driverPropsFetcher@hcdnc235:45113]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc235:45113] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc235:45113%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:48 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc235:33898/user/Executor#-96060902]) with ID 1%%0001017/07/18 01:01:48 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:01:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc235, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:01:48 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc235:48007 with 530.0 MB RAM, BlockManagerId(1, hcdnc235, 48007)%%0001017/07/18 01:01:48 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38398] &lt;- [akka.tcp://driverPropsFetcher@hcdnc230:53638]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:53638] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:53638%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc235:48007 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:48 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc230:35554/user/Executor#-617472644]) with ID 2%%0001017/07/18 01:01:48 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:01:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc230, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:01:48 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc230:50101 with 530.0 MB RAM, BlockManagerId(2, hcdnc230, 50101)%%0001017/07/18 01:01:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc235:48007 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc230:50101 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc230:50101 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2612 ms on hcdnc235 (1/2)%%0001017/07/18 01:01:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2587 ms on hcdnc230 (2/2)%%0001017/07/18 01:01:51 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:51 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.102 s%%0001017/07/18 01:01:51 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.224415 s%%0001017/07/18 01:01:51 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:01:51 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:01:51 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:01:51 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:01:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:01:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:01:51 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:01:51 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:01:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:01:51 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:01:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:01:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:46768 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:01:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:01:51 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:01:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc235, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:01:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc230, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:01:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc235:48007 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:01:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc230:50101 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:01:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1377 ms on hcdnc230 (1/2)%%0001017/07/18 01:01:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1412 ms on hcdnc235 (2/2)%%0001017/07/18 01:01:52 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:52 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.413 s%%0001017/07/18 01:01:52 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:52 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:52 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:01:52 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:52 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:01:52 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:01:52 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:01:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:01:52 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:01:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:01:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:46768 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:01:52 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:01:52 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:01:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc230, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc235, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc230:50101 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc235:48007 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:35554%%0001017/07/18 01:01:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:01:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc235:33898%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 149 ms on hcdnc230 (1/2)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 156 ms on hcdnc235 (2/2)%%0001017/07/18 01:01:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.157 s%%0001017/07/18 01:01:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.600734 s%%0001017/07/18 01:01:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:01:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:01:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:01:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:01:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:01:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:46768 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:01:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:01:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc235, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc235:48007 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc230:50101 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 213 ms on hcdnc235 (1/2)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 216 ms on hcdnc230 (2/2)%%0001017/07/18 01:01:53 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:53 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.217 s%%0001017/07/18 01:01:53 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.230347 s%%0001017/07/18 01:01:53 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:01:53 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:01:53 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:01:53 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:01:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:01:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:46768 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:01:53 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:01:53 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc235, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc230, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc230:50101 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc235:48007 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 282 ms on hcdnc230 (1/2)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 295 ms on hcdnc235 (2/2)%%0001017/07/18 01:01:53 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:53 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.296 s%%0001017/07/18 01:01:53 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:53 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:53 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:01:53 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:53 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:46768 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:01:53 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:01:53 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc235, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc230:50101 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc235:48007 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc230:35554%%0001017/07/18 01:01:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:01:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc235:33898%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc235, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc230, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 45 ms on hcdnc235 (1/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc230 (2/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc230, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc230 (3/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc235, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 17 ms on hcdnc235 (4/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc230, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc230 (5/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc235, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc235 (6/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc230, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc230 (7/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc235, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc235 (8/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 12 ms on hcdnc230 (9/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc235 (10/10)%%0001017/07/18 01:01:53 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.102 s%%0001017/07/18 01:01:53 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:53 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.419592 s%%0001017/07/18 01:01:53 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:01:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:01:53 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:01:53 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:01:53 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:01:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:01:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(12960) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(7122) called with curMem=301428, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:46768 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:01:53 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:01:53 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc230, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc235, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc230:50101 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc235:48007 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:35554%%0001017/07/18 01:01:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc235:33898%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1171 ms on hcdnc230 (1/2)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1185 ms on hcdnc235 (2/2)%%0001017/07/18 01:01:55 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:55 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.187 s%%0001017/07/18 01:01:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:55 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:55 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:01:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:55 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:01:55 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:01:55 INFO MemoryStore: ensureFreeSpace(16040) called with curMem=308550, maxMem=556038881%%0001017/07/18 01:01:55 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:01:55 INFO MemoryStore: ensureFreeSpace(8479) called with curMem=324590, maxMem=556038881%%0001017/07/18 01:01:55 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:01:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:46768 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:01:55 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:01:55 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc230, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc235, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc235:48007 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc230:50101 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc235:33898%%0001017/07/18 01:01:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 156 bytes%%0001017/07/18 01:01:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc230:35554%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc230, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 153 ms on hcdnc230 (1/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc235, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 212 ms on hcdnc235 (2/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc230, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 95 ms on hcdnc230 (3/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc235, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 99 ms on hcdnc235 (4/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc230, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 84 ms on hcdnc230 (5/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc235, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 78 ms on hcdnc235 (6/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc230, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 84 ms on hcdnc230 (7/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc235, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 72 ms on hcdnc235 (8/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 80 ms on hcdnc230 (9/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 84 ms on hcdnc235 (10/10)%%0001017/07/18 01:01:55 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:55 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.543 s%%0001017/07/18 01:01:55 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.755613 s%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:01:55 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:01:55 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:01:55 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:01:55 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:01:55 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:01:55 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:01:55 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38398] &lt;- [akka.tcp://sparkExecutor@hcdnc230:35554]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc230:35554] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc230:35554%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:55 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38398] &lt;- [akka.tcp://sparkExecutor@hcdnc235:33898]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc235:33898] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc235:33898%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:01:55 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:01:55 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:01:55 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:01:55 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:01:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:01:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:01:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:01:56 INFO Remoting: Remoting shut down%%0001017/07/18 01:01:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:01:56 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:01:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-3ac9960f-6317-48e8-bcc6-c426506c2750%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:02:09 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:02:11 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:02:11 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:02:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:02:11 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:02:11 INFO Remoting: Starting remoting%%0001017/07/18 01:02:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:40981]%%0001017/07/18 01:02:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:40981]%%0001017/07/18 01:02:11 INFO Utils: Successfully started service 'sparkDriver' on port 40981.%%0001017/07/18 01:02:11 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:02:11 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:02:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-45afc13b-79d5-4d0e-b102-fd55ca7e4608%%0001017/07/18 01:02:11 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:02:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-55121f53-3784-459f-bb8e-8da5de24aa6c/httpd-e42eebbd-9843-45ca-9536-925f9968bd04%%0001017/07/18 01:02:12 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:02:12 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:02:12 INFO AbstractConnector: Started SocketConnector@0.0.0.0:46331%%0001017/07/18 01:02:12 INFO Utils: Successfully started service 'HTTP file server' on port 46331.%%0001017/07/18 01:02:12 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:02:12 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:02:12 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:02:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:02:12 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:02:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:02:12 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:02:12 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:02:12 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:02:12 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:02:12 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:02:12 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:02:12 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:02:13 INFO Client: Uploading resource file:/tmp/spark-55121f53-3784-459f-bb8e-8da5de24aa6c/__spark_conf__711084175241420902.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22127/__spark_conf__711084175241420902.zip%%0001017/07/18 01:02:13 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:02:13 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:02:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:02:13 INFO Client: Submitting application 22127 to ResourceManager%%0001017/07/18 01:02:14 INFO YarnClientImpl: Submitted application application_1491786134915_22127%%0001017/07/18 01:02:15 INFO Client: Application report for application_1491786134915_22127 (state: ACCEPTED)%%0001017/07/18 01:02:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310933958%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22127/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:02:16 INFO Client: Application report for application_1491786134915_22127 (state: ACCEPTED)%%0001017/07/18 01:02:17 INFO Client: Application report for application_1491786134915_22127 (state: ACCEPTED)%%0001017/07/18 01:02:17 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:50161/user/YarnAM#-573720868])%%0001017/07/18 01:02:17 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22127,http://hcnnc117:8088/proxy/application_1491786134915_22127), /proxy/application_1491786134915_22127%%0001017/07/18 01:02:17 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:02:18 INFO Client: Application report for application_1491786134915_22127 (state: RUNNING)%%0001017/07/18 01:02:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310933958%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22127/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:02:18 INFO YarnClientSchedulerBackend: Application application_1491786134915_22127 has started running.%%0001017/07/18 01:02:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40663.%%0001017/07/18 01:02:18 INFO NettyBlockTransferService: Server created on 40663%%0001017/07/18 01:02:18 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:02:18 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:02:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:40663 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 40663)%%0001017/07/18 01:02:18 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:02:18 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22127%%0001017/07/18 01:02:18 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:02:19 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:02:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:02:19 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:02:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:02:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:40663 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:02:19 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:02:19 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:02:19 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:02:19 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:02:19 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:02:19 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:02:19 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:02:19 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:02:19 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:02:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:02:19 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:02:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:02:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:40663 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:02:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:02:19 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:02:20 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:02:21 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:02:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40981] &lt;- [akka.tcp://driverPropsFetcher@hcdnc305:43081]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc305:43081] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc305:43081%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:23 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc305:50901/user/Executor#2121170639]) with ID 1%%0001017/07/18 01:02:23 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:02:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc305, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:02:23 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc305:35239 with 530.0 MB RAM, BlockManagerId(1, hcdnc305, 35239)%%0001017/07/18 01:02:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40981] &lt;- [akka.tcp://driverPropsFetcher@hcdnc230:53226]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:53226] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:53226%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc305:35239 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:24 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc230:39137/user/Executor#149559000]) with ID 2%%0001017/07/18 01:02:24 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:02:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc230, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:02:24 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc230:41986 with 530.0 MB RAM, BlockManagerId(2, hcdnc230, 41986)%%0001017/07/18 01:02:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc305:35239 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:02:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc230:41986 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc230:41986 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:02:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2639 ms on hcdnc305 (1/2)%%0001017/07/18 01:02:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2543 ms on hcdnc230 (2/2)%%0001017/07/18 01:02:26 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.076 s%%0001017/07/18 01:02:26 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:26 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.204321 s%%0001017/07/18 01:02:26 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:02:26 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:02:26 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:02:26 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:02:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:02:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:02:26 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:02:26 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:02:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:02:26 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:02:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:02:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:40663 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:02:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:02:26 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:02:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc230, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:02:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc305, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:02:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc230:41986 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:02:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc305:35239 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1394 ms on hcdnc230 (1/2)%%0001017/07/18 01:02:28 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.446 s%%0001017/07/18 01:02:28 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:02:28 INFO DAGScheduler: running: Set()%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1444 ms on hcdnc305 (2/2)%%0001017/07/18 01:02:28 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:02:28 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:28 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:02:28 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:40663 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:02:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:02:28 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc230:41986 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc305:35239 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:39137%%0001017/07/18 01:02:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:02:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc305:50901%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 160 ms on hcdnc230 (1/2)%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 173 ms on hcdnc305 (2/2)%%0001017/07/18 01:02:28 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:28 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.173 s%%0001017/07/18 01:02:28 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.657309 s%%0001017/07/18 01:02:28 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:02:28 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:02:28 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:02:28 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:02:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:02:28 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:40663 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:02:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:02:28 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc230:41986 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc305:35239 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 219 ms on hcdnc305 (1/2)%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 232 ms on hcdnc230 (2/2)%%0001017/07/18 01:02:28 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:28 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.233 s%%0001017/07/18 01:02:28 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.246260 s%%0001017/07/18 01:02:28 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:02:28 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:02:28 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:02:28 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:02:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:02:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:40663 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:02:28 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:02:28 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc230, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc305, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc305:35239 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc230:41986 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 289 ms on hcdnc305 (1/2)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 295 ms on hcdnc230 (2/2)%%0001017/07/18 01:02:29 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:29 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.296 s%%0001017/07/18 01:02:29 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:02:29 INFO DAGScheduler: running: Set()%%0001017/07/18 01:02:29 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:02:29 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:02:29 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:02:29 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:02:29 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:02:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:02:29 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:02:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:40663 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:02:29 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:29 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:02:29 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc230, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc305, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc230:41986 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc305:35239 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc230:39137%%0001017/07/18 01:02:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 167 bytes%%0001017/07/18 01:02:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc305:50901%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc305, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc305 (1/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc230, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 50 ms on hcdnc230 (2/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc305, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc305 (3/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc230, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 18 ms on hcdnc230 (4/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc305, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc305 (5/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc230, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc230 (6/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc305, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc305 (7/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc230, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 11 ms on hcdnc230 (8/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc305 (9/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc230 (10/10)%%0001017/07/18 01:02:29 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:02:29 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:29 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.422138 s%%0001017/07/18 01:02:29 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:02:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:02:29 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:02:29 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:02:29 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:02:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:02:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:02:29 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:02:29 INFO MemoryStore: ensureFreeSpace(12160) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:02:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.9 KB, free 530.0 MB)%%0001017/07/18 01:02:29 INFO MemoryStore: ensureFreeSpace(6686) called with curMem=300628, maxMem=556038881%%0001017/07/18 01:02:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 530.0 MB)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:40663 (size: 6.5 KB, free: 530.2 MB)%%0001017/07/18 01:02:29 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:02:29 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc230, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc305, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc230:41986 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc305:35239 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:39137%%0001017/07/18 01:02:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc305:50901%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1008 ms on hcdnc230 (1/2)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1055 ms on hcdnc305 (2/2)%%0001017/07/18 01:02:30 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:30 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.057 s%%0001017/07/18 01:02:30 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:02:30 INFO DAGScheduler: running: Set()%%0001017/07/18 01:02:30 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:02:30 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:02:30 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:02:30 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:02:30 INFO MemoryStore: ensureFreeSpace(15072) called with curMem=307314, maxMem=556038881%%0001017/07/18 01:02:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.7 KB, free 530.0 MB)%%0001017/07/18 01:02:30 INFO MemoryStore: ensureFreeSpace(7941) called with curMem=322386, maxMem=556038881%%0001017/07/18 01:02:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 01:02:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:40663 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 01:02:30 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:02:30 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc305:35239 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:02:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc230:41986 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:02:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc230:39137%%0001017/07/18 01:02:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 01:02:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc305:50901%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc230, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 129 ms on hcdnc230 (1/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc305, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 153 ms on hcdnc305 (2/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc230, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 70 ms on hcdnc230 (3/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc305, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 75 ms on hcdnc305 (4/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc230, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 70 ms on hcdnc230 (5/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc305, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 73 ms on hcdnc305 (6/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc230, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 71 ms on hcdnc230 (7/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc305, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 70 ms on hcdnc305 (8/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 77 ms on hcdnc230 (9/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 71 ms on hcdnc305 (10/10)%%0001017/07/18 01:02:30 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:30 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.440 s%%0001017/07/18 01:02:30 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.522938 s%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:02:30 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:02:30 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:02:30 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:02:30 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:02:30 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:02:30 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:02:30 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40981] &lt;- [akka.tcp://sparkExecutor@hcdnc305:50901]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc305:50901] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc305:50901%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:30 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40981] &lt;- [akka.tcp://sparkExecutor@hcdnc230:39137]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc230:39137] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc230:39137%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:02:31 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:02:31 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:02:31 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:02:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:02:31 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:02:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:02:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:02:31 INFO Remoting: Remoting shut down%%0001017/07/18 01:02:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:02:31 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:02:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-55121f53-3784-459f-bb8e-8da5de24aa6c%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:02:44 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:02:45 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:02:45 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:02:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:02:46 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:02:46 INFO Remoting: Starting remoting%%0001017/07/18 01:02:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:36859]%%0001017/07/18 01:02:46 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:36859]%%0001017/07/18 01:02:46 INFO Utils: Successfully started service 'sparkDriver' on port 36859.%%0001017/07/18 01:02:46 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:02:46 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:02:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d02d0bb1-923d-4ccc-b831-57ca41b14193%%0001017/07/18 01:02:46 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:02:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-81ff0a2c-3bbc-4d52-b8d8-845a6954872c/httpd-a1ee8b62-d23e-4bdb-857a-d7af9c2b9f44%%0001017/07/18 01:02:46 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:02:46 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:02:46 INFO AbstractConnector: Started SocketConnector@0.0.0.0:41843%%0001017/07/18 01:02:46 INFO Utils: Successfully started service 'HTTP file server' on port 41843.%%0001017/07/18 01:02:46 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:02:47 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:02:47 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:02:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:02:47 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:02:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:02:47 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:02:47 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:02:47 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:02:47 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:02:47 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:02:47 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:02:47 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:02:47 INFO Client: Uploading resource file:/tmp/spark-81ff0a2c-3bbc-4d52-b8d8-845a6954872c/__spark_conf__5809201309927949376.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22128/__spark_conf__5809201309927949376.zip%%0001017/07/18 01:02:48 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:02:48 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:02:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:02:48 INFO Client: Submitting application 22128 to ResourceManager%%0001017/07/18 01:02:48 INFO YarnClientImpl: Submitted application application_1491786134915_22128%%0001017/07/18 01:02:49 INFO Client: Application report for application_1491786134915_22128 (state: ACCEPTED)%%0001017/07/18 01:02:49 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310968356%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22128/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:02:50 INFO Client: Application report for application_1491786134915_22128 (state: ACCEPTED)%%0001017/07/18 01:02:51 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:38053/user/YarnAM#-560803277])%%0001017/07/18 01:02:51 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22128,http://hcnnc117:8088/proxy/application_1491786134915_22128), /proxy/application_1491786134915_22128%%0001017/07/18 01:02:51 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:02:51 INFO Client: Application report for application_1491786134915_22128 (state: RUNNING)%%0001017/07/18 01:02:51 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310968356%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22128/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:02:51 INFO YarnClientSchedulerBackend: Application application_1491786134915_22128 has started running.%%0001017/07/18 01:02:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35752.%%0001017/07/18 01:02:51 INFO NettyBlockTransferService: Server created on 35752%%0001017/07/18 01:02:51 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:02:51 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:02:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:35752 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 35752)%%0001017/07/18 01:02:51 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:02:51 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22128%%0001017/07/18 01:02:51 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:02:52 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:02:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:02:53 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:02:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:02:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:35752 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:02:53 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:02:53 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:02:53 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:02:53 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:02:53 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:02:53 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:02:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:02:53 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:02:53 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:02:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:02:53 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:02:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:02:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:35752 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:02:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:02:53 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:02:54 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:02:55 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:02:57 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36859] &lt;- [akka.tcp://driverPropsFetcher@hcdnc226:46401]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc226:46401] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc226:46401%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:57 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc226:43327/user/Executor#1408387231]) with ID 1%%0001017/07/18 01:02:57 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:02:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc226, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:02:57 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc226:42776 with 530.0 MB RAM, BlockManagerId(1, hcdnc226, 42776)%%0001017/07/18 01:02:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc226:42776 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:57 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36859] &lt;- [akka.tcp://driverPropsFetcher@hcdnc230:40258]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:40258] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:40258%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:58 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc230:49732/user/Executor#447563130]) with ID 2%%0001017/07/18 01:02:58 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:02:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc230, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:02:58 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc230:34529 with 530.0 MB RAM, BlockManagerId(2, hcdnc230, 34529)%%0001017/07/18 01:02:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc226:42776 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:02:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc230:34529 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc230:34529 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:03:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2602 ms on hcdnc226 (1/2)%%0001017/07/18 01:03:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2646 ms on hcdnc230 (2/2)%%0001017/07/18 01:03:00 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.365 s%%0001017/07/18 01:03:00 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:00 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.487755 s%%0001017/07/18 01:03:00 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:03:00 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:03:00 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:03:00 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:03:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:03:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:03:00 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:03:00 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:03:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:03:00 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:03:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:03:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:35752 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:03:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:03:00 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:03:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc226, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:03:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc230, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:03:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc230:34529 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:03:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc226:42776 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1384 ms on hcdnc226 (1/2)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1397 ms on hcdnc230 (2/2)%%0001017/07/18 01:03:02 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.399 s%%0001017/07/18 01:03:02 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:02 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:02 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:02 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:03:02 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:02 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:35752 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:03:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:03:02 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc230, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc226, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc230:34529 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc226:42776 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:49732%%0001017/07/18 01:03:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:03:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc226:43327%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 158 ms on hcdnc230 (1/2)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 163 ms on hcdnc226 (2/2)%%0001017/07/18 01:03:02 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:02 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.164 s%%0001017/07/18 01:03:02 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.595057 s%%0001017/07/18 01:03:02 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:03:02 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:03:02 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:03:02 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:03:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:03:02 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:35752 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:03:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:03:02 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc226, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc226:42776 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc230:34529 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 214 ms on hcdnc226 (1/2)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 234 ms on hcdnc230 (2/2)%%0001017/07/18 01:03:02 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:02 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.235 s%%0001017/07/18 01:03:02 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.248418 s%%0001017/07/18 01:03:02 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:03:02 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:03:02 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:03:02 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:03:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:03:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:35752 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:03:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:03:02 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc226, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc230, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc226:42776 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc230:34529 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 295 ms on hcdnc226 (1/2)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 297 ms on hcdnc230 (2/2)%%0001017/07/18 01:03:03 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:03 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.298 s%%0001017/07/18 01:03:03 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:03 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:03 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:03:03 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:03 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:03:03 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:03:03 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:03:03 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:03:03 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:03:03 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:35752 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:03:03 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:03 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:03:03 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc226, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc226:42776 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc230:34529 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc226:43327%%0001017/07/18 01:03:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 01:03:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc230:49732%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc230, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc230 (1/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc226, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc226 (2/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc226, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc230, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc226 (3/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 19 ms on hcdnc230 (4/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc226, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc226 (5/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc230, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc230 (6/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc226, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc230, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 17 ms on hcdnc226 (7/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc230 (8/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc226 (9/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 15 ms on hcdnc230 (10/10)%%0001017/07/18 01:03:03 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:03 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.108 s%%0001017/07/18 01:03:03 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.427805 s%%0001017/07/18 01:03:03 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:03:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:03:03 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:03:03 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:03:03 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:03:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:03:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:03:03 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:03:03 INFO MemoryStore: ensureFreeSpace(12160) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:03:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.9 KB, free 530.0 MB)%%0001017/07/18 01:03:03 INFO MemoryStore: ensureFreeSpace(6686) called with curMem=300628, maxMem=556038881%%0001017/07/18 01:03:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 530.0 MB)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:35752 (size: 6.5 KB, free: 530.2 MB)%%0001017/07/18 01:03:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:03:03 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc230, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc226, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc230:34529 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc226:42776 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc226:43327%%0001017/07/18 01:03:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:49732%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1025 ms on hcdnc230 (1/2)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1066 ms on hcdnc226 (2/2)%%0001017/07/18 01:03:04 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:04 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.067 s%%0001017/07/18 01:03:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:04 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:04 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:03:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:04 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:03:04 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:03:04 INFO MemoryStore: ensureFreeSpace(15072) called with curMem=307314, maxMem=556038881%%0001017/07/18 01:03:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.7 KB, free 530.0 MB)%%0001017/07/18 01:03:04 INFO MemoryStore: ensureFreeSpace(7941) called with curMem=322386, maxMem=556038881%%0001017/07/18 01:03:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 01:03:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:35752 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 01:03:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:03:04 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc226, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc230:34529 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc226:42776 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc230:49732%%0001017/07/18 01:03:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 160 bytes%%0001017/07/18 01:03:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc226:43327%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc230, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 135 ms on hcdnc230 (1/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc226, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 153 ms on hcdnc226 (2/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc230, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 75 ms on hcdnc230 (3/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc226, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 75 ms on hcdnc226 (4/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc230, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 79 ms on hcdnc230 (5/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc226, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 77 ms on hcdnc226 (6/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc230, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 76 ms on hcdnc230 (7/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc226, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 62 ms on hcdnc226 (8/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 59 ms on hcdnc226 (9/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 67 ms on hcdnc230 (10/10)%%0001017/07/18 01:03:04 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:04 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.430 s%%0001017/07/18 01:03:04 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.526431 s%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:03:05 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:03:05 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:03:05 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:03:05 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:03:05 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:03:05 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:03:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36859] &lt;- [akka.tcp://sparkExecutor@hcdnc226:43327]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc226:43327] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc226:43327%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36859] &lt;- [akka.tcp://sparkExecutor@hcdnc230:49732]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc230:49732] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc230:49732%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:03:05 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:03:05 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:03:05 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:03:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:03:05 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:03:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:03:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:03:05 INFO Remoting: Remoting shut down%%0001017/07/18 01:03:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:03:06 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:03:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-81ff0a2c-3bbc-4d52-b8d8-845a6954872c%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:03:19 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:03:19 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:03:19 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:03:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:03:20 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:03:20 INFO Remoting: Starting remoting%%0001017/07/18 01:03:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:34207]%%0001017/07/18 01:03:20 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:34207]%%0001017/07/18 01:03:20 INFO Utils: Successfully started service 'sparkDriver' on port 34207.%%0001017/07/18 01:03:20 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:03:20 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:03:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a15af27d-5dad-4a6a-b83b-3555dd6496c4%%0001017/07/18 01:03:20 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:03:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-c2ecc338-eb9f-459e-a4e2-a9f983ed0422/httpd-dd7c8cc6-256e-49e1-b3ee-f3076f92d56f%%0001017/07/18 01:03:20 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:03:20 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:03:20 INFO AbstractConnector: Started SocketConnector@0.0.0.0:43766%%0001017/07/18 01:03:20 INFO Utils: Successfully started service 'HTTP file server' on port 43766.%%0001017/07/18 01:03:20 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:03:21 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:03:21 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:03:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:03:21 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:03:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:03:22 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:03:22 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:03:22 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:03:22 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:03:22 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:03:22 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:03:22 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:03:22 INFO Client: Uploading resource file:/tmp/spark-c2ecc338-eb9f-459e-a4e2-a9f983ed0422/__spark_conf__1208396064862074825.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22129/__spark_conf__1208396064862074825.zip%%0001017/07/18 01:03:22 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:03:22 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:03:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:03:22 INFO Client: Submitting application 22129 to ResourceManager%%0001017/07/18 01:03:23 INFO YarnClientImpl: Submitted application application_1491786134915_22129%%0001017/07/18 01:03:24 INFO Client: Application report for application_1491786134915_22129 (state: ACCEPTED)%%0001017/07/18 01:03:24 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311002976%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22129/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:03:25 INFO Client: Application report for application_1491786134915_22129 (state: ACCEPTED)%%0001017/07/18 01:03:26 INFO Client: Application report for application_1491786134915_22129 (state: ACCEPTED)%%0001017/07/18 01:03:26 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33276/user/YarnAM#-1593142571])%%0001017/07/18 01:03:26 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22129,http://hcnnc117:8088/proxy/application_1491786134915_22129), /proxy/application_1491786134915_22129%%0001017/07/18 01:03:26 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:03:27 INFO Client: Application report for application_1491786134915_22129 (state: RUNNING)%%0001017/07/18 01:03:27 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311002976%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22129/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:03:27 INFO YarnClientSchedulerBackend: Application application_1491786134915_22129 has started running.%%0001017/07/18 01:03:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41302.%%0001017/07/18 01:03:27 INFO NettyBlockTransferService: Server created on 41302%%0001017/07/18 01:03:27 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:03:27 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:03:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41302 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41302)%%0001017/07/18 01:03:27 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:03:27 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22129%%0001017/07/18 01:03:27 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:03:27 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:03:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:03:28 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:03:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:03:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41302 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:03:28 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:03:28 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:03:28 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:03:28 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:03:28 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:03:28 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:03:28 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:03:28 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:03:28 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:03:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:03:28 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:03:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:03:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41302 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:03:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:03:28 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:03:29 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:03:30 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:03:31 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34207] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:53203]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:53203] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:53203%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:32 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:58328/user/Executor#-1160705187]) with ID 1%%0001017/07/18 01:03:32 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:03:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:03:32 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:60294 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 60294)%%0001017/07/18 01:03:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:60294 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:03:32 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34207] &lt;- [akka.tcp://driverPropsFetcher@hcdnc335:46797]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc335:46797] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc335:46797%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:60294 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:03:32 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc335:33257/user/Executor#-1323336664]) with ID 2%%0001017/07/18 01:03:32 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:03:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc335, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:03:33 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc335:57385 with 530.0 MB RAM, BlockManagerId(2, hcdnc335, 57385)%%0001017/07/18 01:03:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc335:57385 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:03:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc335:57385 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:03:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2793 ms on hcdnc310 (1/2)%%0001017/07/18 01:03:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2495 ms on hcdnc335 (2/2)%%0001017/07/18 01:03:35 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.208 s%%0001017/07/18 01:03:35 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:35 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.334202 s%%0001017/07/18 01:03:35 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:03:35 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:03:35 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:03:35 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:03:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:03:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:03:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:03:35 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:03:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:03:35 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:03:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:03:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41302 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:03:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:03:35 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:03:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:03:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc335, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:03:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:60294 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:03:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc335:57385 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:03:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1374 ms on hcdnc335 (1/2)%%0001017/07/18 01:03:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1396 ms on hcdnc310 (2/2)%%0001017/07/18 01:03:36 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.397 s%%0001017/07/18 01:03:36 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:36 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:36 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:36 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:03:36 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:36 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:03:36 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:03:36 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:03:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:03:36 INFO MemoryStore: ensureFreeSpace(4048) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:03:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 530.0 MB)%%0001017/07/18 01:03:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41302 (size: 4.0 KB, free: 530.2 MB)%%0001017/07/18 01:03:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:03:36 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:03:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc335, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:60294 (size: 4.0 KB, free: 530.0 MB)%%0001017/07/18 01:03:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc335:57385 (size: 4.0 KB, free: 530.0 MB)%%0001017/07/18 01:03:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:58328%%0001017/07/18 01:03:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:03:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc335:33257%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 158 ms on hcdnc335 (1/2)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 157 ms on hcdnc310 (2/2)%%0001017/07/18 01:03:37 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:37 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.159 s%%0001017/07/18 01:03:37 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.588102 s%%0001017/07/18 01:03:37 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:03:37 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:03:37 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:03:37 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:03:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:03:37 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262329, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268849, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41302 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:03:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:03:37 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc335, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:60294 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc335:57385 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 194 ms on hcdnc335 (1/2)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 205 ms on hcdnc310 (2/2)%%0001017/07/18 01:03:37 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.206 s%%0001017/07/18 01:03:37 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:37 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.219133 s%%0001017/07/18 01:03:37 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:03:37 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:03:37 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:03:37 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:03:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:03:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272751, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279927, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41302 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:03:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:03:37 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc335, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:60294 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc335:57385 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 297 ms on hcdnc310 (1/2)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 310 ms on hcdnc335 (2/2)%%0001017/07/18 01:03:37 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:37 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.311 s%%0001017/07/18 01:03:37 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:37 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:37 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:03:37 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:37 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284076, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286860, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41302 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:03:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:03:37 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc335, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc335:57385 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:60294 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc335:33257%%0001017/07/18 01:03:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 01:03:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:58328%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc335, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc335 (1/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc310 (2/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc335, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc335 (3/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc310 (4/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc335, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc335 (5/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc310 (6/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc335, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc335 (7/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc310 (8/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc335 (9/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc310 (10/10)%%0001017/07/18 01:03:37 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:03:37 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:37 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.438700 s%%0001017/07/18 01:03:37 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:03:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:03:37 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:03:37 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:03:37 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:03:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:03:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(12160) called with curMem=288473, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.9 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(6686) called with curMem=300633, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41302 (size: 6.5 KB, free: 530.2 MB)%%0001017/07/18 01:03:37 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:03:37 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc335, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc335:57385 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:60294 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc335:33257%%0001017/07/18 01:03:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:58328%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1096 ms on hcdnc310 (1/2)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1157 ms on hcdnc335 (2/2)%%0001017/07/18 01:03:39 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:39 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.157 s%%0001017/07/18 01:03:39 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:39 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:39 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:03:39 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:39 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:03:39 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:03:39 INFO MemoryStore: ensureFreeSpace(15072) called with curMem=307319, maxMem=556038881%%0001017/07/18 01:03:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.7 KB, free 530.0 MB)%%0001017/07/18 01:03:39 INFO MemoryStore: ensureFreeSpace(7941) called with curMem=322391, maxMem=556038881%%0001017/07/18 01:03:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 01:03:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41302 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 01:03:39 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:39 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:03:39 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc335, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:60294 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc335:57385 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:58328%%0001017/07/18 01:03:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 160 bytes%%0001017/07/18 01:03:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc335:33257%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc335, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 144 ms on hcdnc335 (1/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 148 ms on hcdnc310 (2/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc335, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 81 ms on hcdnc335 (3/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 80 ms on hcdnc310 (4/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc335, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 72 ms on hcdnc335 (5/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 77 ms on hcdnc310 (6/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc335, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 71 ms on hcdnc335 (7/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 68 ms on hcdnc310 (8/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 74 ms on hcdnc335 (9/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 70 ms on hcdnc310 (10/10)%%0001017/07/18 01:03:39 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:39 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.442 s%%0001017/07/18 01:03:39 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.626414 s%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:03:39 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:03:39 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:03:39 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:03:39 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:03:39 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:03:39 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:03:39 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34207] &lt;- [akka.tcp://sparkExecutor@hcdnc335:33257]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc335:33257] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc335:33257%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:39 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34207] &lt;- [akka.tcp://sparkExecutor@hcdnc310:58328]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:58328] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:58328%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:03:39 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:03:39 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:03:39 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:03:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:03:39 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:03:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:03:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:03:39 INFO Remoting: Remoting shut down%%0001017/07/18 01:03:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:03:40 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:03:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-c2ecc338-eb9f-459e-a4e2-a9f983ed0422%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_1">
<entry key="column_name" type="xstring" value="FailingNodeMessage"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:58:36 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:58:37 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:58:37 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:58:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:58:37 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:58:37 INFO Remoting: Starting remoting%%0001017/07/18 00:58:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:41894]%%0001017/07/18 00:58:37 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:41894]%%0001017/07/18 00:58:37 INFO Utils: Successfully started service 'sparkDriver' on port 41894.%%0001017/07/18 00:58:37 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:58:37 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:58:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d599f2fc-391e-4cce-812a-7e1a8a178511%%0001017/07/18 00:58:37 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:58:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-945fd0ae-0b4b-41c7-9a8f-7098d62d7a82/httpd-2f5a02f5-2cb4-4f86-9276-4f03b46f5b7e%%0001017/07/18 00:58:38 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:58:38 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:58:38 INFO AbstractConnector: Started SocketConnector@0.0.0.0:42145%%0001017/07/18 00:58:38 INFO Utils: Successfully started service 'HTTP file server' on port 42145.%%0001017/07/18 00:58:38 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:58:38 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:58:38 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:58:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:58:38 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:58:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:58:39 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:58:39 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:58:39 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:58:39 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:58:39 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:58:39 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:58:39 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:58:39 INFO Client: Uploading resource file:/tmp/spark-945fd0ae-0b4b-41c7-9a8f-7098d62d7a82/__spark_conf__2724005607677665489.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22121/__spark_conf__2724005607677665489.zip%%0001017/07/18 00:58:39 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:58:39 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:58:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:58:39 INFO Client: Submitting application 22121 to ResourceManager%%0001017/07/18 00:58:40 INFO YarnClientImpl: Submitted application application_1491786134915_22121%%0001017/07/18 00:58:41 INFO Client: Application report for application_1491786134915_22121 (state: ACCEPTED)%%0001017/07/18 00:58:41 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310719917%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22121/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:58:42 INFO Client: Application report for application_1491786134915_22121 (state: ACCEPTED)%%0001017/07/18 00:58:42 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33726/user/YarnAM#216039712])%%0001017/07/18 00:58:42 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22121,http://hcnnc117:8088/proxy/application_1491786134915_22121), /proxy/application_1491786134915_22121%%0001017/07/18 00:58:42 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:58:43 INFO Client: Application report for application_1491786134915_22121 (state: RUNNING)%%0001017/07/18 00:58:43 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310719917%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22121/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:58:43 INFO YarnClientSchedulerBackend: Application application_1491786134915_22121 has started running.%%0001017/07/18 00:58:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37831.%%0001017/07/18 00:58:43 INFO NettyBlockTransferService: Server created on 37831%%0001017/07/18 00:58:43 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:58:43 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:58:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:37831 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 37831)%%0001017/07/18 00:58:43 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:58:43 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22121%%0001017/07/18 00:58:43 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:58:44 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:58:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:58:44 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:58:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:58:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:37831 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:58:44 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:58:44 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:58:44 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:58:44 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:58:44 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:58:44 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:58:44 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:58:44 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:58:44 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:58:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:58:44 INFO MemoryStore: ensureFreeSpace(3970) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:58:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:58:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:37831 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:58:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:58:44 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:58:46 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:58:47 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:58:48 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41894] &lt;- [akka.tcp://driverPropsFetcher@hcdnc322:45318]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc322:45318] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc322:45318%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:58:48 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc322:54212/user/Executor#899018777]) with ID 1%%0001017/07/18 00:58:48 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:58:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc322, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:58:49 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc322:37154 with 530.0 MB RAM, BlockManagerId(1, hcdnc322, 37154)%%0001017/07/18 00:58:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc322:37154 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:58:49 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41894] &lt;- [akka.tcp://driverPropsFetcher@hcdnc312:33440]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc312:33440] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc312:33440%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:58:49 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc312:40806/user/Executor#-955518488]) with ID 2%%0001017/07/18 00:58:49 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:58:49 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc312, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:58:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc322:37154 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:58:49 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc312:34149 with 530.0 MB RAM, BlockManagerId(2, hcdnc312, 34149)%%0001017/07/18 00:58:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc312:34149 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:58:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2760 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc312:34149 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:58:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 3844 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:53 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 8.531 s%%0001017/07/18 00:58:53 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:53 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 8.652188 s%%0001017/07/18 00:58:53 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:58:53 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:58:53 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:58:53 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:58:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:58:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:58:53 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:58:53 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237398, maxMem=556038881%%0001017/07/18 00:58:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 00:58:53 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246046, maxMem=556038881%%0001017/07/18 00:58:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:58:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:37831 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:58:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:58:53 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:58:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc312, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 00:58:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc322, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 00:58:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc312:34149 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:58:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc322:37154 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1406 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1418 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:55 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:55 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.419 s%%0001017/07/18 00:58:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:58:55 INFO DAGScheduler: running: Set()%%0001017/07/18 00:58:55 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:58:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:58:55 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251346, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258282, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:37831 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:58:55 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:58:55 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc312, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc322, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc312:34149 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc322:37154 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc312:40806%%0001017/07/18 00:58:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 00:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc322:54212%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 165 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 175 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:55 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:55 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.176 s%%0001017/07/18 00:58:55 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.627709 s%%0001017/07/18 00:58:55 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:58:55 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:58:55 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:58:55 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:58:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:58:55 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262325, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268845, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:37831 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:58:55 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:58:55 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc312, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc322, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc322:37154 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc312:34149 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 261 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 272 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:55 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:55 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.272 s%%0001017/07/18 00:58:55 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.285431 s%%0001017/07/18 00:58:55 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:58:55 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:58:55 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:58:55 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:58:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:58:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272747, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(4150) called with curMem=279923, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:37831 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:58:55 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:58:55 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc312, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc322, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc322:37154 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc312:34149 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 310 ms on hcdnc312 (1/2)%%0001017/07/18 00:58:55 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 330 ms on hcdnc322 (2/2)%%0001017/07/18 00:58:55 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:55 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.331 s%%0001017/07/18 00:58:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:58:55 INFO DAGScheduler: running: Set()%%0001017/07/18 00:58:55 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:58:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:58:55 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284073, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:58:55 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286857, maxMem=556038881%%0001017/07/18 00:58:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:58:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:37831 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:58:55 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:58:55 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc312, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:55 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc322, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc322:37154 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc312:34149 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:58:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc322:54212%%0001017/07/18 00:58:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:58:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc312:40806%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc322, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 36 ms on hcdnc322 (1/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc312, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 43 ms on hcdnc312 (2/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc322, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc322 (3/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc312, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc312 (4/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc322, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc322 (5/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc312, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 15 ms on hcdnc312 (6/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc322, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 11 ms on hcdnc322 (7/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc312, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 14 ms on hcdnc312 (8/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc322 (9/10)%%0001017/07/18 00:58:56 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 12 ms on hcdnc312 (10/10)%%0001017/07/18 00:58:56 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:56 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.092 s%%0001017/07/18 00:58:56 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.444636 s%%0001017/07/18 00:58:56 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:58:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 00:58:56 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:58:56 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:58:56 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:58:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:58:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:58:56 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:58:56 INFO MemoryStore: ensureFreeSpace(14040) called with curMem=288470, maxMem=556038881%%0001017/07/18 00:58:56 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:58:56 INFO MemoryStore: ensureFreeSpace(7748) called with curMem=302510, maxMem=556038881%%0001017/07/18 00:58:56 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:37831 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:58:56 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:58:56 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc312, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:58:56 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc322, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc312:34149 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:58:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc322:37154 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:58:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc312:40806%%0001017/07/18 00:58:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc322:54212%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1359 ms on hcdnc322 (1/2)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1408 ms on hcdnc312 (2/2)%%0001017/07/18 00:58:57 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:57 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.409 s%%0001017/07/18 00:58:57 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:58:57 INFO DAGScheduler: running: Set()%%0001017/07/18 00:58:57 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:58:57 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:58:57 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:58:57 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:58:57 INFO MemoryStore: ensureFreeSpace(17368) called with curMem=310258, maxMem=556038881%%0001017/07/18 00:58:57 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.0 KB, free 530.0 MB)%%0001017/07/18 00:58:57 INFO MemoryStore: ensureFreeSpace(9264) called with curMem=327626, maxMem=556038881%%0001017/07/18 00:58:57 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 00:58:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:37831 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 00:58:57 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:58:57 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:58:57 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc322, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc312, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc312:34149 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:58:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc322:37154 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:58:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc312:40806%%0001017/07/18 00:58:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 160 bytes%%0001017/07/18 00:58:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc322:54212%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc312, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 173 ms on hcdnc312 (1/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc322, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 199 ms on hcdnc322 (2/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc312, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 103 ms on hcdnc312 (3/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc322, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 106 ms on hcdnc322 (4/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc322, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 74 ms on hcdnc322 (5/10)%%0001017/07/18 00:58:57 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc312, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:57 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 107 ms on hcdnc312 (6/10)%%0001017/07/18 00:58:58 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc322, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:58 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 84 ms on hcdnc322 (7/10)%%0001017/07/18 00:58:58 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc312, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:58:58 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 93 ms on hcdnc312 (8/10)%%0001017/07/18 00:58:58 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 78 ms on hcdnc322 (9/10)%%0001017/07/18 00:58:58 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 92 ms on hcdnc312 (10/10)%%0001017/07/18 00:58:58 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:58:58 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.566 s%%0001017/07/18 00:58:58 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 2.006053 s%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:58:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:58:58 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:58:58 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:58:58 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:58:58 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:58:58 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:58:58 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:58:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41894] &lt;- [akka.tcp://sparkExecutor@hcdnc322:54212]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc322:54212] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc322:54212%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:58:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41894] &lt;- [akka.tcp://sparkExecutor@hcdnc312:40806]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc312:40806] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc312:40806%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:58:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:58:58 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:58:58 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:58:58 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:58:58 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:58:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:58:58 INFO Remoting: Remoting shut down%%0001017/07/18 00:58:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:58:59 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:58:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-945fd0ae-0b4b-41c7-9a8f-7098d62d7a82%%00010"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:59:11 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:59:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:59:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:59:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:59:12 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:59:12 INFO Remoting: Starting remoting%%0001017/07/18 00:59:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:34841]%%0001017/07/18 00:59:13 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:34841]%%0001017/07/18 00:59:13 INFO Utils: Successfully started service 'sparkDriver' on port 34841.%%0001017/07/18 00:59:13 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:59:13 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:59:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9f14e528-21e1-4be7-a76c-22f18b4d627b%%0001017/07/18 00:59:13 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:59:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-14ce477c-7bb9-41c0-bdc5-2999c553f9be/httpd-8eb7ca7c-89c7-4dec-ae6c-5d9ae0bbaeaf%%0001017/07/18 00:59:14 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:59:14 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:59:14 INFO AbstractConnector: Started SocketConnector@0.0.0.0:43666%%0001017/07/18 00:59:14 INFO Utils: Successfully started service 'HTTP file server' on port 43666.%%0001017/07/18 00:59:14 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:59:14 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:59:14 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:59:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:59:14 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:59:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:59:14 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:59:14 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:59:14 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:59:14 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:59:14 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:59:14 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:59:14 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:59:15 INFO Client: Uploading resource file:/tmp/spark-14ce477c-7bb9-41c0-bdc5-2999c553f9be/__spark_conf__3494930077158750309.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22122/__spark_conf__3494930077158750309.zip%%0001017/07/18 00:59:15 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:59:15 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:59:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:59:15 INFO Client: Submitting application 22122 to ResourceManager%%0001017/07/18 00:59:15 INFO YarnClientImpl: Submitted application application_1491786134915_22122%%0001017/07/18 00:59:16 INFO Client: Application report for application_1491786134915_22122 (state: ACCEPTED)%%0001017/07/18 00:59:16 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310755578%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22122/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:59:17 INFO Client: Application report for application_1491786134915_22122 (state: ACCEPTED)%%0001017/07/18 00:59:18 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:60450/user/YarnAM#1905483698])%%0001017/07/18 00:59:18 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22122,http://hcnnc117:8088/proxy/application_1491786134915_22122), /proxy/application_1491786134915_22122%%0001017/07/18 00:59:18 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:59:18 INFO Client: Application report for application_1491786134915_22122 (state: RUNNING)%%0001017/07/18 00:59:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310755578%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22122/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:59:18 INFO YarnClientSchedulerBackend: Application application_1491786134915_22122 has started running.%%0001017/07/18 00:59:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37958.%%0001017/07/18 00:59:18 INFO NettyBlockTransferService: Server created on 37958%%0001017/07/18 00:59:18 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:59:18 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:59:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:37958 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 37958)%%0001017/07/18 00:59:18 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:59:19 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22122%%0001017/07/18 00:59:19 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:59:20 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:59:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:59:20 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:59:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:59:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:37958 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:59:20 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:59:20 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:59:20 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:59:20 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:59:20 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:59:20 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:59:20 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:59:20 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:59:20 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:59:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:59:20 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:59:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:59:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:37958 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:59:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:59:20 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:59:21 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:59:22 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:59:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34841] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:35275]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:35275] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:35275%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:24 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:47483/user/Executor#-687957287]) with ID 1%%0001017/07/18 00:59:24 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:59:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:59:24 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:55907 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 55907)%%0001017/07/18 00:59:25 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34841] &lt;- [akka.tcp://driverPropsFetcher@hcdnc301:50503]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc301:50503] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc301:50503%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:55907 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:25 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc301:37815/user/Executor#1886793639]) with ID 2%%0001017/07/18 00:59:25 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:59:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc301, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:59:25 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc301:42911 with 530.0 MB RAM, BlockManagerId(2, hcdnc301, 42911)%%0001017/07/18 00:59:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:55907 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:59:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc301:42911 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc301:42911 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:59:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3078 ms on hcdnc310 (1/2)%%0001017/07/18 00:59:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2534 ms on hcdnc301 (2/2)%%0001017/07/18 00:59:27 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.493 s%%0001017/07/18 00:59:27 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:27 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.620983 s%%0001017/07/18 00:59:27 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:59:27 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:59:27 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:59:27 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:59:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:59:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:59:27 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:59:27 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 00:59:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 00:59:27 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246045, maxMem=556038881%%0001017/07/18 00:59:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:59:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:37958 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:59:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:59:27 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:59:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 00:59:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc301, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 00:59:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc301:42911 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:59:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:55907 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1363 ms on hcdnc301 (1/2)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1463 ms on hcdnc310 (2/2)%%0001017/07/18 00:59:29 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:29 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.464 s%%0001017/07/18 00:59:29 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:59:29 INFO DAGScheduler: running: Set()%%0001017/07/18 00:59:29 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:59:29 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:59:29 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251347, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(4044) called with curMem=258283, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:37958 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:59:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:59:29 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc301, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:55907 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc301:42911 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc301:37815%%0001017/07/18 00:59:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:59:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:47483%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on hcdnc310 (1/2)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 170 ms on hcdnc301 (2/2)%%0001017/07/18 00:59:29 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:29 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.171 s%%0001017/07/18 00:59:29 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.666344 s%%0001017/07/18 00:59:29 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:59:29 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:59:29 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:59:29 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:59:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:59:29 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262327, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268847, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:37958 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:59:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:59:29 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc301, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:55907 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc301:42911 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 212 ms on hcdnc301 (1/2)%%0001017/07/18 00:59:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 218 ms on hcdnc310 (2/2)%%0001017/07/18 00:59:29 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:29 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.219 s%%0001017/07/18 00:59:29 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.233994 s%%0001017/07/18 00:59:29 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:59:29 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:59:29 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:59:29 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:59:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:59:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272749, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO MemoryStore: ensureFreeSpace(4151) called with curMem=279925, maxMem=556038881%%0001017/07/18 00:59:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:37958 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:59:29 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:59:29 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:59:29 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc301, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:55907 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:59:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc301:42911 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 289 ms on hcdnc301 (1/2)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 297 ms on hcdnc310 (2/2)%%0001017/07/18 00:59:30 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:30 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.297 s%%0001017/07/18 00:59:30 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:59:30 INFO DAGScheduler: running: Set()%%0001017/07/18 00:59:30 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:59:30 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:59:30 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:59:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:59:30 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284076, maxMem=556038881%%0001017/07/18 00:59:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:59:30 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286860, maxMem=556038881%%0001017/07/18 00:59:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:37958 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:59:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:59:30 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc301, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc301:42911 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:55907 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc301:37815%%0001017/07/18 00:59:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:59:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:47483%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc301, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc301 (1/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc310 (2/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc301, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc301 (3/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 18 ms on hcdnc310 (4/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc301, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc301 (5/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc310 (6/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc301, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc301 (7/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 12 ms on hcdnc310 (8/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 12 ms on hcdnc301 (9/10)%%0001017/07/18 00:59:30 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc310 (10/10)%%0001017/07/18 00:59:30 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:59:30 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:30 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.420535 s%%0001017/07/18 00:59:30 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:59:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:59:30 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:59:30 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:59:30 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:59:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:59:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:59:30 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:59:30 INFO MemoryStore: ensureFreeSpace(14040) called with curMem=288473, maxMem=556038881%%0001017/07/18 00:59:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:59:30 INFO MemoryStore: ensureFreeSpace(7754) called with curMem=302513, maxMem=556038881%%0001017/07/18 00:59:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:37958 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:59:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:59:30 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:59:30 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc301, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc301:42911 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:55907 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:59:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc301:37815%%0001017/07/18 00:59:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:47483%%0001017/07/18 00:59:31 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1405 ms on hcdnc310 (1/2)%%0001017/07/18 00:59:31 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1418 ms on hcdnc301 (2/2)%%0001017/07/18 00:59:31 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:31 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.420 s%%0001017/07/18 00:59:31 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:59:31 INFO DAGScheduler: running: Set()%%0001017/07/18 00:59:31 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:59:31 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:59:31 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:59:31 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:59:31 INFO MemoryStore: ensureFreeSpace(17368) called with curMem=310267, maxMem=556038881%%0001017/07/18 00:59:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.0 KB, free 530.0 MB)%%0001017/07/18 00:59:31 INFO MemoryStore: ensureFreeSpace(9273) called with curMem=327635, maxMem=556038881%%0001017/07/18 00:59:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 530.0 MB)%%0001017/07/18 00:59:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:37958 (size: 9.1 KB, free: 530.2 MB)%%0001017/07/18 00:59:31 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:31 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:59:31 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:59:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:31 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc301, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc301:42911 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 00:59:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:55907 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 00:59:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc301:37815%%0001017/07/18 00:59:31 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:59:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:47483%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc301, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 172 ms on hcdnc301 (1/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 183 ms on hcdnc310 (2/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc301, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 98 ms on hcdnc301 (3/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 109 ms on hcdnc310 (4/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc301, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 92 ms on hcdnc301 (5/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 78 ms on hcdnc310 (6/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 83 ms on hcdnc310 (7/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc301, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 94 ms on hcdnc301 (8/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 70 ms on hcdnc310 (9/10)%%0001017/07/18 00:59:32 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 90 ms on hcdnc301 (10/10)%%0001017/07/18 00:59:32 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:59:32 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.544 s%%0001017/07/18 00:59:32 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 2.009967 s%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:59:32 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:59:32 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:59:32 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:59:32 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:59:32 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:59:32 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:59:32 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:59:32 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34841] &lt;- [akka.tcp://sparkExecutor@hcdnc301:37815]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc301:37815] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc301:37815%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:32 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34841] &lt;- [akka.tcp://sparkExecutor@hcdnc310:47483]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:47483] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:47483%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:59:32 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:59:32 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:59:32 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:59:32 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:59:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:59:32 INFO Remoting: Remoting shut down%%0001017/07/18 00:59:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:59:33 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:59:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-14ce477c-7bb9-41c0-bdc5-2999c553f9be%%00010"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:59:46 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:59:47 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:59:47 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:59:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:59:48 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:59:48 INFO Remoting: Starting remoting%%0001017/07/18 00:59:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46322]%%0001017/07/18 00:59:48 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46322]%%0001017/07/18 00:59:48 INFO Utils: Successfully started service 'sparkDriver' on port 46322.%%0001017/07/18 00:59:48 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:59:48 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:59:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d5ed5769-52e5-4ab2-962c-7ac721f4b93a%%0001017/07/18 00:59:48 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:59:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-69c136b8-a39c-41bb-ac99-5507670550d4/httpd-fecbdb6d-8e88-4a1a-9a50-9abb2a1f5941%%0001017/07/18 00:59:48 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:59:48 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:59:48 INFO AbstractConnector: Started SocketConnector@0.0.0.0:37553%%0001017/07/18 00:59:48 INFO Utils: Successfully started service 'HTTP file server' on port 37553.%%0001017/07/18 00:59:48 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:59:48 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:59:48 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:59:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:59:48 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:59:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:59:49 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:59:49 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:59:49 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:59:49 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:59:49 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:59:49 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:59:49 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:59:49 INFO Client: Uploading resource file:/tmp/spark-69c136b8-a39c-41bb-ac99-5507670550d4/__spark_conf__3794827948942308694.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22123/__spark_conf__3794827948942308694.zip%%0001017/07/18 00:59:49 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:59:49 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:59:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:59:50 INFO Client: Submitting application 22123 to ResourceManager%%0001017/07/18 00:59:50 INFO YarnClientImpl: Submitted application application_1491786134915_22123%%0001017/07/18 00:59:51 INFO Client: Application report for application_1491786134915_22123 (state: ACCEPTED)%%0001017/07/18 00:59:51 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310790015%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22123/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:59:52 INFO Client: Application report for application_1491786134915_22123 (state: ACCEPTED)%%0001017/07/18 00:59:52 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:48755/user/YarnAM#726856124])%%0001017/07/18 00:59:52 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22123,http://hcnnc117:8088/proxy/application_1491786134915_22123), /proxy/application_1491786134915_22123%%0001017/07/18 00:59:52 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:59:53 INFO Client: Application report for application_1491786134915_22123 (state: RUNNING)%%0001017/07/18 00:59:53 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310790015%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22123/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:59:53 INFO YarnClientSchedulerBackend: Application application_1491786134915_22123 has started running.%%0001017/07/18 00:59:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44610.%%0001017/07/18 00:59:53 INFO NettyBlockTransferService: Server created on 44610%%0001017/07/18 00:59:53 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:59:53 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:59:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:44610 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 44610)%%0001017/07/18 00:59:53 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:59:54 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22123%%0001017/07/18 00:59:54 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:59:54 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:59:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:59:54 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:59:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:59:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:44610 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:59:54 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:59:54 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:59:54 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:59:54 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:59:54 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:59:54 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:59:54 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:59:54 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:59:54 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:59:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:59:54 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:59:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:59:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:44610 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:59:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:59:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:59:54 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:59:55 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:59:56 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:59:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46322] &lt;- [akka.tcp://driverPropsFetcher@hcdnc306:57979]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:57979] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:57979%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:58 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc306:45851/user/Executor#-731006208]) with ID 1%%0001017/07/18 00:59:58 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:59:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc306, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:59:58 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc306:42233 with 530.0 MB RAM, BlockManagerId(1, hcdnc306, 42233)%%0001017/07/18 00:59:59 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46322] &lt;- [akka.tcp://driverPropsFetcher@hcdnc332:43046]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc332:43046] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc332:43046%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:59:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc306:42233 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:59:59 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc332:39807/user/Executor#-1990043594]) with ID 2%%0001017/07/18 00:59:59 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:59:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc332, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 00:59:59 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc332:49447 with 530.0 MB RAM, BlockManagerId(2, hcdnc332, 49447)%%0001017/07/18 00:59:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc306:42233 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:59:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc332:49447 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc332:49447 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2613 ms on hcdnc306 (1/2)%%0001017/07/18 01:00:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2645 ms on hcdnc332 (2/2)%%0001017/07/18 01:00:02 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:02 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.177 s%%0001017/07/18 01:00:02 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.297618 s%%0001017/07/18 01:00:02 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:00:02 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:00:02 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:00:02 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:00:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:00:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:00:02 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:00:02 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:00:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:00:02 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:00:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:00:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:44610 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:00:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:00:02 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:00:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc306, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:00:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc332, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:00:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc332:49447 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:00:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc306:42233 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:00:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1386 ms on hcdnc332 (1/2)%%0001017/07/18 01:00:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1445 ms on hcdnc306 (2/2)%%0001017/07/18 01:00:03 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:03 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.445 s%%0001017/07/18 01:00:03 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:03 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:03 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:00:03 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:03 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:00:03 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:00:03 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:00:03 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:00:03 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:00:03 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:44610 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:00:03 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:00:03 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:00:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc332, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc306:42233 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc332:49447 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc332:39807%%0001017/07/18 01:00:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:00:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:45851%%0001017/07/18 01:00:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 157 ms on hcdnc332 (1/2)%%0001017/07/18 01:00:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 161 ms on hcdnc306 (2/2)%%0001017/07/18 01:00:03 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:03 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.162 s%%0001017/07/18 01:00:03 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.640625 s%%0001017/07/18 01:00:03 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:00:03 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:00:03 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:00:03 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:00:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:00:03 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:00:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:00:03 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:00:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:00:03 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:00:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:44610 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:00:03 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:00:03 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:00:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:03 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc306, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc306:42233 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:00:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc332:49447 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 219 ms on hcdnc332 (1/2)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 241 ms on hcdnc306 (2/2)%%0001017/07/18 01:00:04 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:04 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.243 s%%0001017/07/18 01:00:04 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.255927 s%%0001017/07/18 01:00:04 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:00:04 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:00:04 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:00:04 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:00:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:00:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:44610 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:00:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:00:04 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc332, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc306, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc306:42233 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc332:49447 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 293 ms on hcdnc306 (1/2)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 294 ms on hcdnc332 (2/2)%%0001017/07/18 01:00:04 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:04 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.295 s%%0001017/07/18 01:00:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:04 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:04 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:00:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:04 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:44610 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:00:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:00:04 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc332, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc306, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc306:42233 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc332:49447 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc306:45851%%0001017/07/18 01:00:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 01:00:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc332:39807%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc332, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc306, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 47 ms on hcdnc332 (1/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc306 (2/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc306, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc332, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc306 (3/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 18 ms on hcdnc332 (4/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc332, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc306, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc332 (5/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc306 (6/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc332, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc332 (7/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc306, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc306 (8/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 12 ms on hcdnc332 (9/10)%%0001017/07/18 01:00:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc306 (10/10)%%0001017/07/18 01:00:04 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:00:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:04 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.421983 s%%0001017/07/18 01:00:04 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:00:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:00:04 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:00:04 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:00:04 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:00:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:00:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(14040) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO MemoryStore: ensureFreeSpace(7745) called with curMem=302508, maxMem=556038881%%0001017/07/18 01:00:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:44610 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:00:04 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:00:04 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc306, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:04 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc332, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc306:42233 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc332:49447 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:00:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:45851%%0001017/07/18 01:00:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc332:39807%%0001017/07/18 01:00:05 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1385 ms on hcdnc306 (1/2)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1423 ms on hcdnc332 (2/2)%%0001017/07/18 01:00:06 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:06 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.425 s%%0001017/07/18 01:00:06 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:06 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:06 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:00:06 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:06 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:00:06 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:00:06 INFO MemoryStore: ensureFreeSpace(17368) called with curMem=310253, maxMem=556038881%%0001017/07/18 01:00:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.0 KB, free 530.0 MB)%%0001017/07/18 01:00:06 INFO MemoryStore: ensureFreeSpace(9263) called with curMem=327621, maxMem=556038881%%0001017/07/18 01:00:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 01:00:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:44610 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 01:00:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:06 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:00:06 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc332, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc332:49447 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 01:00:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc306:42233 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 01:00:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc332:39807%%0001017/07/18 01:00:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 01:00:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc306:45851%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc332, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 186 ms on hcdnc332 (1/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc306, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 202 ms on hcdnc306 (2/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc332, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 102 ms on hcdnc332 (3/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc306, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 116 ms on hcdnc306 (4/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc332, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 106 ms on hcdnc332 (5/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc306, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 97 ms on hcdnc306 (6/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc332, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 93 ms on hcdnc332 (7/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc306, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 90 ms on hcdnc306 (8/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 84 ms on hcdnc332 (9/10)%%0001017/07/18 01:00:06 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 108 ms on hcdnc306 (10/10)%%0001017/07/18 01:00:06 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:06 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.609 s%%0001017/07/18 01:00:06 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 2.061650 s%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:00:06 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:00:06 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:00:06 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:00:06 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:00:06 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:00:06 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:00:06 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:00:06 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46322] &lt;- [akka.tcp://sparkExecutor@hcdnc306:45851]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc306:45851] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc306:45851%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:06 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46322] &lt;- [akka.tcp://sparkExecutor@hcdnc332:39807]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc332:39807] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc332:39807%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:00:07 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:00:07 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:00:07 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:00:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:00:07 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:00:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:00:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:00:07 INFO Remoting: Remoting shut down%%0001017/07/18 01:00:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:00:07 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:00:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-69c136b8-a39c-41bb-ac99-5507670550d4/pyspark-120512f4-97ed-4e5c-9946-281910c82162%%0001017/07/18 01:00:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-69c136b8-a39c-41bb-ac99-5507670550d4%%00010"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:00:20 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:00:21 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:00:21 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:00:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:00:22 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:00:22 INFO Remoting: Starting remoting%%0001017/07/18 01:00:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38334]%%0001017/07/18 01:00:22 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38334]%%0001017/07/18 01:00:22 INFO Utils: Successfully started service 'sparkDriver' on port 38334.%%0001017/07/18 01:00:22 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:00:22 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:00:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9d4612b9-d133-4de7-a071-93eabce92373%%0001017/07/18 01:00:22 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:00:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-db4ae7f2-6ef3-4c18-b1f4-d7d9562b2ddb/httpd-629b969e-6340-408c-a5e1-d7ae96bbf04b%%0001017/07/18 01:00:23 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:00:23 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:00:23 INFO AbstractConnector: Started SocketConnector@0.0.0.0:41736%%0001017/07/18 01:00:23 INFO Utils: Successfully started service 'HTTP file server' on port 41736.%%0001017/07/18 01:00:23 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:00:23 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:00:23 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:00:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:00:23 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:00:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:00:23 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:00:23 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:00:23 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:00:23 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:00:23 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:00:23 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:00:23 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:00:24 INFO Client: Uploading resource file:/tmp/spark-db4ae7f2-6ef3-4c18-b1f4-d7d9562b2ddb/__spark_conf__8308912685360785187.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22124/__spark_conf__8308912685360785187.zip%%0001017/07/18 01:00:24 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:00:24 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:00:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:00:24 INFO Client: Submitting application 22124 to ResourceManager%%0001017/07/18 01:00:24 INFO YarnClientImpl: Submitted application application_1491786134915_22124%%0001017/07/18 01:00:25 INFO Client: Application report for application_1491786134915_22124 (state: ACCEPTED)%%0001017/07/18 01:00:25 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310824404%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22124/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:00:26 INFO Client: Application report for application_1491786134915_22124 (state: ACCEPTED)%%0001017/07/18 01:00:27 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:46039/user/YarnAM#1846180369])%%0001017/07/18 01:00:27 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22124,http://hcnnc117:8088/proxy/application_1491786134915_22124), /proxy/application_1491786134915_22124%%0001017/07/18 01:00:27 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:00:27 INFO Client: Application report for application_1491786134915_22124 (state: RUNNING)%%0001017/07/18 01:00:27 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310824404%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22124/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:00:27 INFO YarnClientSchedulerBackend: Application application_1491786134915_22124 has started running.%%0001017/07/18 01:00:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36384.%%0001017/07/18 01:00:28 INFO NettyBlockTransferService: Server created on 36384%%0001017/07/18 01:00:28 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:00:28 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:00:28 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:36384 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 36384)%%0001017/07/18 01:00:28 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:00:29 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22124%%0001017/07/18 01:00:29 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:00:30 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:00:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:00:30 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:00:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:00:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:36384 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:00:30 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:00:30 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:00:30 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:00:30 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:00:30 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:00:30 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:00:30 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:00:30 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:00:30 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:00:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:00:30 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:00:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:00:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:36384 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:00:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:00:30 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:00:31 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:00:32 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:00:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38334] &lt;- [akka.tcp://driverPropsFetcher@hcdnc317:37184]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc317:37184] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc317:37184%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:34 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc317:34686/user/Executor#-1375685926]) with ID 1%%0001017/07/18 01:00:34 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:00:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc317, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:00:34 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc317:38934 with 530.0 MB RAM, BlockManagerId(1, hcdnc317, 38934)%%0001017/07/18 01:00:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38334] &lt;- [akka.tcp://driverPropsFetcher@hcdnc829:42919]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc829:42919] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc829:42919%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc317:38934 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:35 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc829:40549/user/Executor#-623538127]) with ID 2%%0001017/07/18 01:00:35 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:00:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc829, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:00:35 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc829:52881 with 530.0 MB RAM, BlockManagerId(2, hcdnc829, 52881)%%0001017/07/18 01:00:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc317:38934 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc829:52881 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc829:52881 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2532 ms on hcdnc317 (1/2)%%0001017/07/18 01:00:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2567 ms on hcdnc829 (2/2)%%0001017/07/18 01:00:37 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.143 s%%0001017/07/18 01:00:37 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:37 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.263072 s%%0001017/07/18 01:00:37 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:00:37 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:00:37 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:00:37 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:00:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:00:37 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:00:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:00:37 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:00:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:00:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:36384 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:00:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:00:37 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:00:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc829, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:00:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc317, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:00:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc829:52881 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:00:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc317:38934 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1357 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1374 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:39 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.376 s%%0001017/07/18 01:00:39 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:39 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:39 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:39 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:00:39 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:39 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251347, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(4044) called with curMem=258283, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:36384 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:00:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:00:39 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc317, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc829, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc317:38934 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc829:52881 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc317:34686%%0001017/07/18 01:00:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc829:40549%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 160 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 163 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:39 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:39 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.164 s%%0001017/07/18 01:00:39 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.571603 s%%0001017/07/18 01:00:39 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:00:39 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:00:39 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:00:39 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:00:39 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262327, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268847, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:36384 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:00:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:00:39 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc317, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc829, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc829:52881 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc317:38934 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 227 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 237 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:39 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:39 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.238 s%%0001017/07/18 01:00:39 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.251470 s%%0001017/07/18 01:00:39 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:00:39 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:00:39 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:00:39 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:00:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272749, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279925, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:36384 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:00:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:00:39 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc829, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc317, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc317:38934 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc829:52881 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 302 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:39 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 316 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:39 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:39 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.319 s%%0001017/07/18 01:00:39 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:39 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:39 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:00:39 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:39 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284074, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:00:39 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286858, maxMem=556038881%%0001017/07/18 01:00:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:36384 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:00:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:39 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:00:39 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc317, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc829, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc829:52881 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc317:38934 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc829:40549%%0001017/07/18 01:00:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 167 bytes%%0001017/07/18 01:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc317:34686%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc829, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 44 ms on hcdnc829 (1/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc317, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 48 ms on hcdnc317 (2/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc829, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc317, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 19 ms on hcdnc829 (3/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 18 ms on hcdnc317 (4/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc317, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 14 ms on hcdnc317 (5/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc829, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc829 (6/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc829, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc317, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc829 (7/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 17 ms on hcdnc317 (8/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc829 (9/10)%%0001017/07/18 01:00:40 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc317 (10/10)%%0001017/07/18 01:00:40 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:00:40 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:40 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.444318 s%%0001017/07/18 01:00:40 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:00:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:00:40 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:00:40 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:00:40 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:00:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:00:40 INFO MemoryStore: ensureFreeSpace(12960) called with curMem=288471, maxMem=556038881%%0001017/07/18 01:00:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:00:40 INFO MemoryStore: ensureFreeSpace(7129) called with curMem=301431, maxMem=556038881%%0001017/07/18 01:00:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:00:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:36384 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:00:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:00:40 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc829, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:40 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc317, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:00:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc829:52881 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:00:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc317:38934 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc317:34686%%0001017/07/18 01:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc829:40549%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1154 ms on hcdnc829 (1/2)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1179 ms on hcdnc317 (2/2)%%0001017/07/18 01:00:41 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:41 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.180 s%%0001017/07/18 01:00:41 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:00:41 INFO DAGScheduler: running: Set()%%0001017/07/18 01:00:41 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:00:41 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:00:41 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:00:41 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:00:41 INFO MemoryStore: ensureFreeSpace(16040) called with curMem=308560, maxMem=556038881%%0001017/07/18 01:00:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:00:41 INFO MemoryStore: ensureFreeSpace(8485) called with curMem=324600, maxMem=556038881%%0001017/07/18 01:00:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:00:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:36384 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:00:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:00:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:00:41 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc829, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc317, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc317:38934 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc829:52881 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:00:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc829:40549%%0001017/07/18 01:00:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 158 bytes%%0001017/07/18 01:00:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc317:34686%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc829, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 157 ms on hcdnc829 (1/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc317, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 164 ms on hcdnc317 (2/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc829, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 95 ms on hcdnc829 (3/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc317, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 91 ms on hcdnc317 (4/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc317, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 76 ms on hcdnc317 (5/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc829, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 81 ms on hcdnc829 (6/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc317, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 84 ms on hcdnc317 (7/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc829, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 85 ms on hcdnc829 (8/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 77 ms on hcdnc317 (9/10)%%0001017/07/18 01:00:41 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 85 ms on hcdnc829 (10/10)%%0001017/07/18 01:00:41 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:00:41 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.499 s%%0001017/07/18 01:00:41 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.706801 s%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:00:41 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:00:42 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:00:42 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:00:42 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:00:42 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:00:42 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:00:42 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:00:42 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38334] &lt;- [akka.tcp://sparkExecutor@hcdnc317:34686]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc317:34686] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc317:34686%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:42 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38334] &lt;- [akka.tcp://sparkExecutor@hcdnc829:40549]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc829:40549] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc829:40549%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:00:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:00:42 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:00:42 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:00:42 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:00:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:00:42 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:00:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:00:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:00:42 INFO Remoting: Remoting shut down%%0001017/07/18 01:00:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:00:42 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:00:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-db4ae7f2-6ef3-4c18-b1f4-d7d9562b2ddb%%00010"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:00:56 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:00:57 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:00:57 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:00:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:00:57 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:00:57 INFO Remoting: Starting remoting%%0001017/07/18 01:00:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38063]%%0001017/07/18 01:00:57 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38063]%%0001017/07/18 01:00:57 INFO Utils: Successfully started service 'sparkDriver' on port 38063.%%0001017/07/18 01:00:57 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:00:57 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:00:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d29de68e-9175-4593-b9da-48a253aeb042%%0001017/07/18 01:00:57 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:00:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-5f98fef7-5c07-4074-a1fb-4fc9d3ed32a5/httpd-6d927e21-f266-4c0a-bee1-197589e4ce0f%%0001017/07/18 01:00:58 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:00:58 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:00:58 INFO AbstractConnector: Started SocketConnector@0.0.0.0:41321%%0001017/07/18 01:00:58 INFO Utils: Successfully started service 'HTTP file server' on port 41321.%%0001017/07/18 01:00:58 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:00:58 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:00:59 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:00:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:00:59 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:00:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:00:59 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:00:59 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:00:59 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:00:59 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:00:59 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:00:59 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:00:59 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:01:05 INFO Client: Uploading resource file:/tmp/spark-5f98fef7-5c07-4074-a1fb-4fc9d3ed32a5/__spark_conf__4023830525756384668.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22125/__spark_conf__4023830525756384668.zip%%0001017/07/18 01:01:05 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:01:05 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:01:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:01:05 INFO Client: Submitting application 22125 to ResourceManager%%0001017/07/18 01:01:05 INFO YarnClientImpl: Submitted application application_1491786134915_22125%%0001017/07/18 01:01:06 INFO Client: Application report for application_1491786134915_22125 (state: ACCEPTED)%%0001017/07/18 01:01:06 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310865461%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22125/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:01:07 INFO Client: Application report for application_1491786134915_22125 (state: ACCEPTED)%%0001017/07/18 01:01:08 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:59844/user/YarnAM#327302571])%%0001017/07/18 01:01:08 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22125,http://hcnnc117:8088/proxy/application_1491786134915_22125), /proxy/application_1491786134915_22125%%0001017/07/18 01:01:08 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:01:08 INFO Client: Application report for application_1491786134915_22125 (state: RUNNING)%%0001017/07/18 01:01:08 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310865461%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22125/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:01:08 INFO YarnClientSchedulerBackend: Application application_1491786134915_22125 has started running.%%0001017/07/18 01:01:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38815.%%0001017/07/18 01:01:08 INFO NettyBlockTransferService: Server created on 38815%%0001017/07/18 01:01:08 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:01:08 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:01:08 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:38815 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 38815)%%0001017/07/18 01:01:08 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:01:09 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22125%%0001017/07/18 01:01:09 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:01:09 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:01:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:01:09 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:01:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:01:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:38815 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:01:09 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:01:09 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:01:09 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:01:09 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:01:09 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:01:09 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:01:09 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:01:09 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:01:09 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:01:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:01:09 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:01:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:01:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:38815 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:01:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:01:09 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:01:10 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:01:11 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:01:13 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38063] &lt;- [akka.tcp://driverPropsFetcher@hcdnc307:50881]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc307:50881] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc307:50881%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:13 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc307:34044/user/Executor#-1553745944]) with ID 1%%0001017/07/18 01:01:13 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:01:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc307, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:01:13 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc307:37015 with 530.0 MB RAM, BlockManagerId(1, hcdnc307, 37015)%%0001017/07/18 01:01:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc307:37015 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:14 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38063] &lt;- [akka.tcp://driverPropsFetcher@hcdnc302:51351]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc302:51351] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc302:51351%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:14 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc302:53448/user/Executor#-730180379]) with ID 2%%0001017/07/18 01:01:14 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:01:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc302, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:01:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc307:37015 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:14 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc302:35937 with 530.0 MB RAM, BlockManagerId(2, hcdnc302, 35937)%%0001017/07/18 01:01:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc302:35937 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc302:35937 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2502 ms on hcdnc307 (1/2)%%0001017/07/18 01:01:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2716 ms on hcdnc302 (2/2)%%0001017/07/18 01:01:17 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.290 s%%0001017/07/18 01:01:17 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:17 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.417031 s%%0001017/07/18 01:01:17 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:01:17 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:01:17 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:01:17 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:01:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:01:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:01:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:01:17 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:01:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:01:17 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:01:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:01:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:38815 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:01:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:01:17 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:01:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc302, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:01:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc307, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:01:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc302:35937 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:01:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc307:37015 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:01:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1391 ms on hcdnc307 (1/2)%%0001017/07/18 01:01:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1461 ms on hcdnc302 (2/2)%%0001017/07/18 01:01:18 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:18 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.462 s%%0001017/07/18 01:01:18 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:18 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:18 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:01:18 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:18 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:01:18 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:01:18 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:01:18 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:01:18 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:01:18 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:38815 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:01:18 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:01:18 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:01:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc302, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc302:35937 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc307:37015 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc302:53448%%0001017/07/18 01:01:18 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:01:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc307:34044%%0001017/07/18 01:01:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 166 ms on hcdnc302 (1/2)%%0001017/07/18 01:01:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 167 ms on hcdnc307 (2/2)%%0001017/07/18 01:01:18 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:18 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.169 s%%0001017/07/18 01:01:18 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.662871 s%%0001017/07/18 01:01:18 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:01:18 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:01:18 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:01:18 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:01:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:01:18 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:01:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:01:18 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:01:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:01:18 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:01:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:38815 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:01:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:01:18 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:01:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc307, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:18 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc302, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc307:37015 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:01:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc302:35937 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 210 ms on hcdnc307 (1/2)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 214 ms on hcdnc302 (2/2)%%0001017/07/18 01:01:19 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.215 s%%0001017/07/18 01:01:19 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:19 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.227653 s%%0001017/07/18 01:01:19 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:01:19 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:01:19 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:01:19 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:01:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:01:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:38815 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:01:19 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:01:19 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc307, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc302, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc302:35937 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc307:37015 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 289 ms on hcdnc302 (1/2)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 301 ms on hcdnc307 (2/2)%%0001017/07/18 01:01:19 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:19 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.301 s%%0001017/07/18 01:01:19 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:19 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:19 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:01:19 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:19 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:38815 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:01:19 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:01:19 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc302, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc302:35937 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc307:37015 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc302:53448%%0001017/07/18 01:01:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:01:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc307:34044%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc302, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc302 (1/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc307, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc307 (2/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc302, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc302 (3/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc307, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc307 (4/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc302, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc302 (5/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc307, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc307 (6/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc302, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc302 (7/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc307, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc307 (8/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc302 (9/10)%%0001017/07/18 01:01:19 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc307 (10/10)%%0001017/07/18 01:01:19 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 01:01:19 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:19 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.425487 s%%0001017/07/18 01:01:19 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:01:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:01:19 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:01:19 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:01:19 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:01:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:01:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(12960) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO MemoryStore: ensureFreeSpace(7122) called with curMem=301428, maxMem=556038881%%0001017/07/18 01:01:19 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:38815 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:01:19 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:01:19 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc302, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:19 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc307, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc302:35937 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc307:37015 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:01:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc307:34044%%0001017/07/18 01:01:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc302:53448%%0001017/07/18 01:01:20 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1133 ms on hcdnc307 (1/2)%%0001017/07/18 01:01:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1169 ms on hcdnc302 (2/2)%%0001017/07/18 01:01:20 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:20 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.170 s%%0001017/07/18 01:01:20 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:20 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:20 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:01:20 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:20 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:01:20 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:01:20 INFO MemoryStore: ensureFreeSpace(16040) called with curMem=308550, maxMem=556038881%%0001017/07/18 01:01:20 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:01:20 INFO MemoryStore: ensureFreeSpace(8479) called with curMem=324590, maxMem=556038881%%0001017/07/18 01:01:20 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:01:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:38815 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:01:20 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:20 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:01:20 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:01:20 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc307, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:20 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc302, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc307:37015 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc302:35937 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc307:34044%%0001017/07/18 01:01:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 156 bytes%%0001017/07/18 01:01:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc302:53448%%0001017/07/18 01:01:20 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc302, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:20 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 147 ms on hcdnc302 (1/10)%%0001017/07/18 01:01:20 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc307, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:20 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 177 ms on hcdnc307 (2/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc302, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 92 ms on hcdnc302 (3/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc307, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 90 ms on hcdnc307 (4/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc302, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 83 ms on hcdnc302 (5/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc307, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 82 ms on hcdnc307 (6/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc302, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 68 ms on hcdnc302 (7/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc307, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 81 ms on hcdnc307 (8/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 70 ms on hcdnc302 (9/10)%%0001017/07/18 01:01:21 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 82 ms on hcdnc307 (10/10)%%0001017/07/18 01:01:21 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:21 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.510 s%%0001017/07/18 01:01:21 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.706753 s%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:01:21 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:01:21 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:01:21 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:01:21 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:01:21 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:01:21 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:01:21 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:01:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38063] &lt;- [akka.tcp://sparkExecutor@hcdnc302:53448]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc302:53448] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc302:53448%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38063] &lt;- [akka.tcp://sparkExecutor@hcdnc307:34044]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc307:34044] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc307:34044%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:01:21 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:01:21 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:01:21 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:01:21 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:01:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:01:21 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:01:21 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:01:21 INFO Remoting: Remoting shut down%%0001017/07/18 01:01:21 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:01:22 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:01:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-5f98fef7-5c07-4074-a1fb-4fc9d3ed32a5/pyspark-bc39a5e1-6e1f-41ae-b196-3d60b85a0e9c%%0001017/07/18 01:01:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-5f98fef7-5c07-4074-a1fb-4fc9d3ed32a5%%00010"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:01:36 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:01:36 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:01:36 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:01:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:01:37 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:01:37 INFO Remoting: Starting remoting%%0001017/07/18 01:01:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38398]%%0001017/07/18 01:01:37 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38398]%%0001017/07/18 01:01:37 INFO Utils: Successfully started service 'sparkDriver' on port 38398.%%0001017/07/18 01:01:37 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:01:37 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:01:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e6d2321a-0f4a-49de-bf29-48e2623acdc4%%0001017/07/18 01:01:37 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:01:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3ac9960f-6317-48e8-bcc6-c426506c2750/httpd-c1625aa5-f9d5-4089-a635-2868dea4831f%%0001017/07/18 01:01:37 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:01:37 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:01:37 INFO AbstractConnector: Started SocketConnector@0.0.0.0:38083%%0001017/07/18 01:01:37 INFO Utils: Successfully started service 'HTTP file server' on port 38083.%%0001017/07/18 01:01:37 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:01:37 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:01:38 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:01:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:01:38 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:01:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:01:39 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:01:39 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:01:39 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:01:39 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:01:39 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:01:39 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:01:39 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:01:39 INFO Client: Uploading resource file:/tmp/spark-3ac9960f-6317-48e8-bcc6-c426506c2750/__spark_conf__4234702571674566785.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22126/__spark_conf__4234702571674566785.zip%%0001017/07/18 01:01:40 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:01:40 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:01:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:01:40 INFO Client: Submitting application 22126 to ResourceManager%%0001017/07/18 01:01:40 INFO YarnClientImpl: Submitted application application_1491786134915_22126%%0001017/07/18 01:01:41 INFO Client: Application report for application_1491786134915_22126 (state: ACCEPTED)%%0001017/07/18 01:01:41 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310900025%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22126/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:01:42 INFO Client: Application report for application_1491786134915_22126 (state: ACCEPTED)%%0001017/07/18 01:01:42 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:53623/user/YarnAM#2101407535])%%0001017/07/18 01:01:42 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22126,http://hcnnc117:8088/proxy/application_1491786134915_22126), /proxy/application_1491786134915_22126%%0001017/07/18 01:01:42 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:01:43 INFO Client: Application report for application_1491786134915_22126 (state: RUNNING)%%0001017/07/18 01:01:43 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310900025%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22126/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:01:43 INFO YarnClientSchedulerBackend: Application application_1491786134915_22126 has started running.%%0001017/07/18 01:01:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46768.%%0001017/07/18 01:01:43 INFO NettyBlockTransferService: Server created on 46768%%0001017/07/18 01:01:43 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:01:43 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:01:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:46768 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 46768)%%0001017/07/18 01:01:43 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:01:43 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22126%%0001017/07/18 01:01:43 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:01:44 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:01:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:01:44 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:01:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:01:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:46768 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:01:44 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:01:44 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:01:44 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:01:44 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:01:44 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:01:44 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:01:44 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:01:44 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:01:44 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:01:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:01:44 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:01:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:01:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:46768 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:01:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:01:44 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:01:45 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:01:46 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:01:47 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38398] &lt;- [akka.tcp://driverPropsFetcher@hcdnc235:45113]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc235:45113] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc235:45113%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:48 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc235:33898/user/Executor#-96060902]) with ID 1%%0001017/07/18 01:01:48 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:01:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc235, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:01:48 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc235:48007 with 530.0 MB RAM, BlockManagerId(1, hcdnc235, 48007)%%0001017/07/18 01:01:48 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38398] &lt;- [akka.tcp://driverPropsFetcher@hcdnc230:53638]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:53638] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:53638%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc235:48007 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:48 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc230:35554/user/Executor#-617472644]) with ID 2%%0001017/07/18 01:01:48 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:01:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc230, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:01:48 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc230:50101 with 530.0 MB RAM, BlockManagerId(2, hcdnc230, 50101)%%0001017/07/18 01:01:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc235:48007 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc230:50101 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc230:50101 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2612 ms on hcdnc235 (1/2)%%0001017/07/18 01:01:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2587 ms on hcdnc230 (2/2)%%0001017/07/18 01:01:51 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:51 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.102 s%%0001017/07/18 01:01:51 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.224415 s%%0001017/07/18 01:01:51 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:01:51 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:01:51 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:01:51 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:01:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:01:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:01:51 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:01:51 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:01:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:01:51 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:01:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:01:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:46768 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:01:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:01:51 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:01:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc235, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:01:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc230, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:01:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc235:48007 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:01:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc230:50101 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:01:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1377 ms on hcdnc230 (1/2)%%0001017/07/18 01:01:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1412 ms on hcdnc235 (2/2)%%0001017/07/18 01:01:52 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:52 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.413 s%%0001017/07/18 01:01:52 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:52 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:52 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:01:52 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:52 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:01:52 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:01:52 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:01:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:01:52 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:01:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:01:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:46768 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:01:52 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:01:52 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:01:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc230, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc235, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc230:50101 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc235:48007 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:01:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:35554%%0001017/07/18 01:01:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:01:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc235:33898%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 149 ms on hcdnc230 (1/2)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 156 ms on hcdnc235 (2/2)%%0001017/07/18 01:01:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.157 s%%0001017/07/18 01:01:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.600734 s%%0001017/07/18 01:01:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:01:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:01:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:01:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:01:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:01:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:46768 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:01:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:01:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc235, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc235:48007 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc230:50101 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 213 ms on hcdnc235 (1/2)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 216 ms on hcdnc230 (2/2)%%0001017/07/18 01:01:53 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:53 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.217 s%%0001017/07/18 01:01:53 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.230347 s%%0001017/07/18 01:01:53 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:01:53 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:01:53 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:01:53 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:01:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:01:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:46768 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:01:53 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:01:53 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc235, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc230, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc230:50101 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc235:48007 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 282 ms on hcdnc230 (1/2)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 295 ms on hcdnc235 (2/2)%%0001017/07/18 01:01:53 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:53 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.296 s%%0001017/07/18 01:01:53 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:53 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:53 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:01:53 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:53 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:46768 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:01:53 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:01:53 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc235, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc230:50101 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc235:48007 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc230:35554%%0001017/07/18 01:01:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:01:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc235:33898%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc235, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc230, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 45 ms on hcdnc235 (1/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc230 (2/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc230, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc230 (3/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc235, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 17 ms on hcdnc235 (4/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc230, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc230 (5/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc235, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc235 (6/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc230, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc230 (7/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc235, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc235 (8/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 12 ms on hcdnc230 (9/10)%%0001017/07/18 01:01:53 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc235 (10/10)%%0001017/07/18 01:01:53 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.102 s%%0001017/07/18 01:01:53 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:53 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.419592 s%%0001017/07/18 01:01:53 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:01:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:01:53 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:01:53 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:01:53 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:01:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:01:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(12960) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO MemoryStore: ensureFreeSpace(7122) called with curMem=301428, maxMem=556038881%%0001017/07/18 01:01:53 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:46768 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:01:53 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:01:53 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc230, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:53 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc235, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc230:50101 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc235:48007 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:01:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:35554%%0001017/07/18 01:01:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc235:33898%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1171 ms on hcdnc230 (1/2)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1185 ms on hcdnc235 (2/2)%%0001017/07/18 01:01:55 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:55 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.187 s%%0001017/07/18 01:01:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:01:55 INFO DAGScheduler: running: Set()%%0001017/07/18 01:01:55 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:01:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:01:55 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:01:55 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:01:55 INFO MemoryStore: ensureFreeSpace(16040) called with curMem=308550, maxMem=556038881%%0001017/07/18 01:01:55 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:01:55 INFO MemoryStore: ensureFreeSpace(8479) called with curMem=324590, maxMem=556038881%%0001017/07/18 01:01:55 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:01:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:46768 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:01:55 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:01:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:01:55 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc230, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc235, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc235:48007 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc230:50101 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:01:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc235:33898%%0001017/07/18 01:01:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 156 bytes%%0001017/07/18 01:01:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc230:35554%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc230, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 153 ms on hcdnc230 (1/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc235, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 212 ms on hcdnc235 (2/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc230, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 95 ms on hcdnc230 (3/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc235, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 99 ms on hcdnc235 (4/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc230, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 84 ms on hcdnc230 (5/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc235, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 78 ms on hcdnc235 (6/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc230, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 84 ms on hcdnc230 (7/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc235, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 72 ms on hcdnc235 (8/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 80 ms on hcdnc230 (9/10)%%0001017/07/18 01:01:55 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 84 ms on hcdnc235 (10/10)%%0001017/07/18 01:01:55 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:01:55 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.543 s%%0001017/07/18 01:01:55 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.755613 s%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:01:55 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:01:55 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:01:55 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:01:55 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:01:55 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:01:55 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:01:55 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:01:55 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38398] &lt;- [akka.tcp://sparkExecutor@hcdnc230:35554]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc230:35554] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc230:35554%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:55 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38398] &lt;- [akka.tcp://sparkExecutor@hcdnc235:33898]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc235:33898] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc235:33898%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:01:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:01:55 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:01:55 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:01:55 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:01:55 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:01:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:01:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:01:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:01:56 INFO Remoting: Remoting shut down%%0001017/07/18 01:01:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:01:56 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:01:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-3ac9960f-6317-48e8-bcc6-c426506c2750%%00010"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:02:09 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:02:11 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:02:11 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:02:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:02:11 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:02:11 INFO Remoting: Starting remoting%%0001017/07/18 01:02:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:40981]%%0001017/07/18 01:02:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:40981]%%0001017/07/18 01:02:11 INFO Utils: Successfully started service 'sparkDriver' on port 40981.%%0001017/07/18 01:02:11 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:02:11 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:02:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-45afc13b-79d5-4d0e-b102-fd55ca7e4608%%0001017/07/18 01:02:11 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:02:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-55121f53-3784-459f-bb8e-8da5de24aa6c/httpd-e42eebbd-9843-45ca-9536-925f9968bd04%%0001017/07/18 01:02:12 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:02:12 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:02:12 INFO AbstractConnector: Started SocketConnector@0.0.0.0:46331%%0001017/07/18 01:02:12 INFO Utils: Successfully started service 'HTTP file server' on port 46331.%%0001017/07/18 01:02:12 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:02:12 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:02:12 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:02:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:02:12 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:02:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:02:12 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:02:12 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:02:12 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:02:12 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:02:12 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:02:12 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:02:12 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:02:13 INFO Client: Uploading resource file:/tmp/spark-55121f53-3784-459f-bb8e-8da5de24aa6c/__spark_conf__711084175241420902.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22127/__spark_conf__711084175241420902.zip%%0001017/07/18 01:02:13 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:02:13 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:02:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:02:13 INFO Client: Submitting application 22127 to ResourceManager%%0001017/07/18 01:02:14 INFO YarnClientImpl: Submitted application application_1491786134915_22127%%0001017/07/18 01:02:15 INFO Client: Application report for application_1491786134915_22127 (state: ACCEPTED)%%0001017/07/18 01:02:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310933958%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22127/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:02:16 INFO Client: Application report for application_1491786134915_22127 (state: ACCEPTED)%%0001017/07/18 01:02:17 INFO Client: Application report for application_1491786134915_22127 (state: ACCEPTED)%%0001017/07/18 01:02:17 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:50161/user/YarnAM#-573720868])%%0001017/07/18 01:02:17 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22127,http://hcnnc117:8088/proxy/application_1491786134915_22127), /proxy/application_1491786134915_22127%%0001017/07/18 01:02:17 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:02:18 INFO Client: Application report for application_1491786134915_22127 (state: RUNNING)%%0001017/07/18 01:02:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310933958%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22127/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:02:18 INFO YarnClientSchedulerBackend: Application application_1491786134915_22127 has started running.%%0001017/07/18 01:02:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40663.%%0001017/07/18 01:02:18 INFO NettyBlockTransferService: Server created on 40663%%0001017/07/18 01:02:18 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:02:18 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:02:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:40663 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 40663)%%0001017/07/18 01:02:18 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:02:18 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22127%%0001017/07/18 01:02:18 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:02:19 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:02:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:02:19 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:02:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:02:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:40663 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:02:19 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:02:19 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:02:19 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:02:19 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:02:19 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:02:19 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:02:19 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:02:19 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:02:19 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:02:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:02:19 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:02:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:02:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:40663 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:02:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:02:19 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:02:20 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:02:21 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:02:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40981] &lt;- [akka.tcp://driverPropsFetcher@hcdnc305:43081]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc305:43081] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc305:43081%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:23 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc305:50901/user/Executor#2121170639]) with ID 1%%0001017/07/18 01:02:23 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:02:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc305, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:02:23 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc305:35239 with 530.0 MB RAM, BlockManagerId(1, hcdnc305, 35239)%%0001017/07/18 01:02:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40981] &lt;- [akka.tcp://driverPropsFetcher@hcdnc230:53226]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:53226] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:53226%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc305:35239 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:24 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc230:39137/user/Executor#149559000]) with ID 2%%0001017/07/18 01:02:24 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:02:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc230, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:02:24 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc230:41986 with 530.0 MB RAM, BlockManagerId(2, hcdnc230, 41986)%%0001017/07/18 01:02:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc305:35239 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:02:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc230:41986 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc230:41986 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:02:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2639 ms on hcdnc305 (1/2)%%0001017/07/18 01:02:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2543 ms on hcdnc230 (2/2)%%0001017/07/18 01:02:26 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.076 s%%0001017/07/18 01:02:26 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:26 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.204321 s%%0001017/07/18 01:02:26 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:02:26 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:02:26 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:02:26 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:02:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:02:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:02:26 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:02:26 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:02:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:02:26 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:02:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:02:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:40663 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:02:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:02:26 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:02:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc230, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:02:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc305, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:02:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc230:41986 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:02:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc305:35239 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1394 ms on hcdnc230 (1/2)%%0001017/07/18 01:02:28 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.446 s%%0001017/07/18 01:02:28 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:02:28 INFO DAGScheduler: running: Set()%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1444 ms on hcdnc305 (2/2)%%0001017/07/18 01:02:28 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:02:28 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:28 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:02:28 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:40663 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:02:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:02:28 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc230:41986 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc305:35239 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:39137%%0001017/07/18 01:02:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:02:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc305:50901%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 160 ms on hcdnc230 (1/2)%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 173 ms on hcdnc305 (2/2)%%0001017/07/18 01:02:28 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:28 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.173 s%%0001017/07/18 01:02:28 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.657309 s%%0001017/07/18 01:02:28 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:02:28 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:02:28 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:02:28 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:02:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:02:28 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:40663 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:02:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:02:28 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc230:41986 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc305:35239 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 219 ms on hcdnc305 (1/2)%%0001017/07/18 01:02:28 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 232 ms on hcdnc230 (2/2)%%0001017/07/18 01:02:28 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:28 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.233 s%%0001017/07/18 01:02:28 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.246260 s%%0001017/07/18 01:02:28 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:02:28 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:02:28 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:02:28 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:02:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:02:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:02:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:40663 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:02:28 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:02:28 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc230, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:02:28 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc305, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc305:35239 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:02:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc230:41986 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 289 ms on hcdnc305 (1/2)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 295 ms on hcdnc230 (2/2)%%0001017/07/18 01:02:29 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:29 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.296 s%%0001017/07/18 01:02:29 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:02:29 INFO DAGScheduler: running: Set()%%0001017/07/18 01:02:29 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:02:29 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:02:29 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:02:29 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:02:29 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:02:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:02:29 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:02:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:40663 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:02:29 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:29 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:02:29 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc230, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc305, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc230:41986 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc305:35239 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc230:39137%%0001017/07/18 01:02:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 167 bytes%%0001017/07/18 01:02:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc305:50901%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc305, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc305 (1/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc230, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 50 ms on hcdnc230 (2/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc305, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc305 (3/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc230, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 18 ms on hcdnc230 (4/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc305, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc305 (5/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc230, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc230 (6/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc305, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc305 (7/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc230, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 11 ms on hcdnc230 (8/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc305 (9/10)%%0001017/07/18 01:02:29 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc230 (10/10)%%0001017/07/18 01:02:29 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:02:29 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:29 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.422138 s%%0001017/07/18 01:02:29 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:02:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:02:29 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:02:29 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:02:29 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:02:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:02:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:02:29 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:02:29 INFO MemoryStore: ensureFreeSpace(12160) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:02:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.9 KB, free 530.0 MB)%%0001017/07/18 01:02:29 INFO MemoryStore: ensureFreeSpace(6686) called with curMem=300628, maxMem=556038881%%0001017/07/18 01:02:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 530.0 MB)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:40663 (size: 6.5 KB, free: 530.2 MB)%%0001017/07/18 01:02:29 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:02:29 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc230, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:02:29 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc305, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc230:41986 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc305:35239 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:02:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:39137%%0001017/07/18 01:02:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc305:50901%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1008 ms on hcdnc230 (1/2)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1055 ms on hcdnc305 (2/2)%%0001017/07/18 01:02:30 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:30 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.057 s%%0001017/07/18 01:02:30 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:02:30 INFO DAGScheduler: running: Set()%%0001017/07/18 01:02:30 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:02:30 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:02:30 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:02:30 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:02:30 INFO MemoryStore: ensureFreeSpace(15072) called with curMem=307314, maxMem=556038881%%0001017/07/18 01:02:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.7 KB, free 530.0 MB)%%0001017/07/18 01:02:30 INFO MemoryStore: ensureFreeSpace(7941) called with curMem=322386, maxMem=556038881%%0001017/07/18 01:02:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 01:02:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:40663 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 01:02:30 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:02:30 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc305:35239 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:02:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc230:41986 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:02:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc230:39137%%0001017/07/18 01:02:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 01:02:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc305:50901%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc230, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 129 ms on hcdnc230 (1/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc305, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 153 ms on hcdnc305 (2/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc230, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 70 ms on hcdnc230 (3/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc305, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 75 ms on hcdnc305 (4/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc230, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 70 ms on hcdnc230 (5/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc305, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 73 ms on hcdnc305 (6/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc230, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 71 ms on hcdnc230 (7/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc305, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 70 ms on hcdnc305 (8/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 77 ms on hcdnc230 (9/10)%%0001017/07/18 01:02:30 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 71 ms on hcdnc305 (10/10)%%0001017/07/18 01:02:30 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:02:30 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.440 s%%0001017/07/18 01:02:30 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.522938 s%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:02:30 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:02:30 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:02:30 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:02:30 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:02:30 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:02:30 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:02:30 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:02:30 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40981] &lt;- [akka.tcp://sparkExecutor@hcdnc305:50901]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc305:50901] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc305:50901%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:30 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40981] &lt;- [akka.tcp://sparkExecutor@hcdnc230:39137]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc230:39137] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc230:39137%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:02:31 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:02:31 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:02:31 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:02:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:02:31 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:02:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:02:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:02:31 INFO Remoting: Remoting shut down%%0001017/07/18 01:02:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:02:31 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:02:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-55121f53-3784-459f-bb8e-8da5de24aa6c%%00010"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:02:44 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:02:45 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:02:45 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:02:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:02:46 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:02:46 INFO Remoting: Starting remoting%%0001017/07/18 01:02:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:36859]%%0001017/07/18 01:02:46 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:36859]%%0001017/07/18 01:02:46 INFO Utils: Successfully started service 'sparkDriver' on port 36859.%%0001017/07/18 01:02:46 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:02:46 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:02:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d02d0bb1-923d-4ccc-b831-57ca41b14193%%0001017/07/18 01:02:46 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:02:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-81ff0a2c-3bbc-4d52-b8d8-845a6954872c/httpd-a1ee8b62-d23e-4bdb-857a-d7af9c2b9f44%%0001017/07/18 01:02:46 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:02:46 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:02:46 INFO AbstractConnector: Started SocketConnector@0.0.0.0:41843%%0001017/07/18 01:02:46 INFO Utils: Successfully started service 'HTTP file server' on port 41843.%%0001017/07/18 01:02:46 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:02:47 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:02:47 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:02:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:02:47 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:02:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:02:47 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:02:47 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:02:47 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:02:47 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:02:47 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:02:47 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:02:47 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:02:47 INFO Client: Uploading resource file:/tmp/spark-81ff0a2c-3bbc-4d52-b8d8-845a6954872c/__spark_conf__5809201309927949376.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22128/__spark_conf__5809201309927949376.zip%%0001017/07/18 01:02:48 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:02:48 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:02:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:02:48 INFO Client: Submitting application 22128 to ResourceManager%%0001017/07/18 01:02:48 INFO YarnClientImpl: Submitted application application_1491786134915_22128%%0001017/07/18 01:02:49 INFO Client: Application report for application_1491786134915_22128 (state: ACCEPTED)%%0001017/07/18 01:02:49 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310968356%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22128/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:02:50 INFO Client: Application report for application_1491786134915_22128 (state: ACCEPTED)%%0001017/07/18 01:02:51 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:38053/user/YarnAM#-560803277])%%0001017/07/18 01:02:51 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22128,http://hcnnc117:8088/proxy/application_1491786134915_22128), /proxy/application_1491786134915_22128%%0001017/07/18 01:02:51 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:02:51 INFO Client: Application report for application_1491786134915_22128 (state: RUNNING)%%0001017/07/18 01:02:51 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500310968356%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22128/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:02:51 INFO YarnClientSchedulerBackend: Application application_1491786134915_22128 has started running.%%0001017/07/18 01:02:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35752.%%0001017/07/18 01:02:51 INFO NettyBlockTransferService: Server created on 35752%%0001017/07/18 01:02:51 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:02:51 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:02:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:35752 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 35752)%%0001017/07/18 01:02:51 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:02:51 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22128%%0001017/07/18 01:02:51 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:02:52 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:02:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:02:53 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:02:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:02:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:35752 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:02:53 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:02:53 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:02:53 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:02:53 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:02:53 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:02:53 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:02:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:02:53 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:02:53 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:02:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:02:53 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:02:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:02:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:35752 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:02:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:02:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:02:53 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:02:54 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:02:55 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:02:57 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36859] &lt;- [akka.tcp://driverPropsFetcher@hcdnc226:46401]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc226:46401] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc226:46401%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:57 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc226:43327/user/Executor#1408387231]) with ID 1%%0001017/07/18 01:02:57 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:02:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc226, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:02:57 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc226:42776 with 530.0 MB RAM, BlockManagerId(1, hcdnc226, 42776)%%0001017/07/18 01:02:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc226:42776 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:57 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36859] &lt;- [akka.tcp://driverPropsFetcher@hcdnc230:40258]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:40258] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc230:40258%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:02:58 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc230:49732/user/Executor#447563130]) with ID 2%%0001017/07/18 01:02:58 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:02:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc230, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:02:58 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc230:34529 with 530.0 MB RAM, BlockManagerId(2, hcdnc230, 34529)%%0001017/07/18 01:02:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc226:42776 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:02:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc230:34529 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:02:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc230:34529 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:03:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2602 ms on hcdnc226 (1/2)%%0001017/07/18 01:03:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2646 ms on hcdnc230 (2/2)%%0001017/07/18 01:03:00 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.365 s%%0001017/07/18 01:03:00 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:00 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.487755 s%%0001017/07/18 01:03:00 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:03:00 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:03:00 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:03:00 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:03:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:03:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:03:00 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:03:00 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:03:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:03:00 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:03:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:03:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:35752 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:03:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:03:00 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:03:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc226, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:03:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc230, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:03:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc230:34529 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:03:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc226:42776 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1384 ms on hcdnc226 (1/2)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1397 ms on hcdnc230 (2/2)%%0001017/07/18 01:03:02 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.399 s%%0001017/07/18 01:03:02 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:02 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:02 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:02 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:03:02 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:02 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:35752 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:03:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:03:02 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc230, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc226, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc230:34529 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc226:42776 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:49732%%0001017/07/18 01:03:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:03:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc226:43327%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 158 ms on hcdnc230 (1/2)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 163 ms on hcdnc226 (2/2)%%0001017/07/18 01:03:02 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:02 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.164 s%%0001017/07/18 01:03:02 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.595057 s%%0001017/07/18 01:03:02 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:03:02 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:03:02 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:03:02 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:03:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:03:02 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262324, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268844, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:35752 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:03:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:03:02 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc226, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc226:42776 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc230:34529 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 214 ms on hcdnc226 (1/2)%%0001017/07/18 01:03:02 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 234 ms on hcdnc230 (2/2)%%0001017/07/18 01:03:02 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:02 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.235 s%%0001017/07/18 01:03:02 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.248418 s%%0001017/07/18 01:03:02 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:03:02 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:03:02 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:03:02 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:03:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:03:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272746, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279922, maxMem=556038881%%0001017/07/18 01:03:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:35752 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:03:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:03:02 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc226, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:02 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc230, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc226:42776 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:03:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc230:34529 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 295 ms on hcdnc226 (1/2)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 297 ms on hcdnc230 (2/2)%%0001017/07/18 01:03:03 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:03 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.298 s%%0001017/07/18 01:03:03 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:03 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:03 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:03:03 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:03 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:03:03 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:03:03 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284071, maxMem=556038881%%0001017/07/18 01:03:03 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:03:03 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286855, maxMem=556038881%%0001017/07/18 01:03:03 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:35752 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:03:03 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:03 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:03:03 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc226, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc226:42776 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc230:34529 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc226:43327%%0001017/07/18 01:03:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 01:03:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc230:49732%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc230, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc230 (1/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc226, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc226 (2/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc226, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc230, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc226 (3/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 19 ms on hcdnc230 (4/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc226, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc226 (5/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc230, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc230 (6/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc226, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc230, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 17 ms on hcdnc226 (7/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc230 (8/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc226 (9/10)%%0001017/07/18 01:03:03 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 15 ms on hcdnc230 (10/10)%%0001017/07/18 01:03:03 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:03 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.108 s%%0001017/07/18 01:03:03 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.427805 s%%0001017/07/18 01:03:03 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:03:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:03:03 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:03:03 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:03:03 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:03:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:03:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:03:03 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:03:03 INFO MemoryStore: ensureFreeSpace(12160) called with curMem=288468, maxMem=556038881%%0001017/07/18 01:03:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.9 KB, free 530.0 MB)%%0001017/07/18 01:03:03 INFO MemoryStore: ensureFreeSpace(6686) called with curMem=300628, maxMem=556038881%%0001017/07/18 01:03:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 530.0 MB)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:35752 (size: 6.5 KB, free: 530.2 MB)%%0001017/07/18 01:03:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:03:03 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc230, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:03 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc226, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc230:34529 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc226:42776 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:03:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc226:43327%%0001017/07/18 01:03:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc230:49732%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1025 ms on hcdnc230 (1/2)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1066 ms on hcdnc226 (2/2)%%0001017/07/18 01:03:04 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:04 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.067 s%%0001017/07/18 01:03:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:04 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:04 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:03:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:04 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:03:04 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:03:04 INFO MemoryStore: ensureFreeSpace(15072) called with curMem=307314, maxMem=556038881%%0001017/07/18 01:03:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.7 KB, free 530.0 MB)%%0001017/07/18 01:03:04 INFO MemoryStore: ensureFreeSpace(7941) called with curMem=322386, maxMem=556038881%%0001017/07/18 01:03:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 01:03:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:35752 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 01:03:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:03:04 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc226, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc230, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc230:34529 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc226:42776 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc230:49732%%0001017/07/18 01:03:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 160 bytes%%0001017/07/18 01:03:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc226:43327%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc230, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 135 ms on hcdnc230 (1/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc226, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 153 ms on hcdnc226 (2/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc230, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 75 ms on hcdnc230 (3/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc226, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 75 ms on hcdnc226 (4/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc230, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 79 ms on hcdnc230 (5/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc226, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 77 ms on hcdnc226 (6/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc230, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 76 ms on hcdnc230 (7/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc226, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 62 ms on hcdnc226 (8/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 59 ms on hcdnc226 (9/10)%%0001017/07/18 01:03:04 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 67 ms on hcdnc230 (10/10)%%0001017/07/18 01:03:04 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:04 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.430 s%%0001017/07/18 01:03:04 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.526431 s%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:03:04 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:03:05 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:03:05 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:03:05 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:03:05 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:03:05 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:03:05 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:03:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36859] &lt;- [akka.tcp://sparkExecutor@hcdnc226:43327]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc226:43327] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc226:43327%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36859] &lt;- [akka.tcp://sparkExecutor@hcdnc230:49732]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc230:49732] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc230:49732%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:03:05 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:03:05 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:03:05 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:03:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:03:05 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:03:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:03:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:03:05 INFO Remoting: Remoting shut down%%0001017/07/18 01:03:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:03:06 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:03:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-81ff0a2c-3bbc-4d52-b8d8-845a6954872c%%00010"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:03:19 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:03:19 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:03:19 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:03:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:03:20 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:03:20 INFO Remoting: Starting remoting%%0001017/07/18 01:03:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:34207]%%0001017/07/18 01:03:20 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:34207]%%0001017/07/18 01:03:20 INFO Utils: Successfully started service 'sparkDriver' on port 34207.%%0001017/07/18 01:03:20 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:03:20 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:03:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a15af27d-5dad-4a6a-b83b-3555dd6496c4%%0001017/07/18 01:03:20 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:03:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-c2ecc338-eb9f-459e-a4e2-a9f983ed0422/httpd-dd7c8cc6-256e-49e1-b3ee-f3076f92d56f%%0001017/07/18 01:03:20 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:03:20 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:03:20 INFO AbstractConnector: Started SocketConnector@0.0.0.0:43766%%0001017/07/18 01:03:20 INFO Utils: Successfully started service 'HTTP file server' on port 43766.%%0001017/07/18 01:03:20 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:03:21 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:03:21 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:03:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:03:21 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:03:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:03:22 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:03:22 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:03:22 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:03:22 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:03:22 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:03:22 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:03:22 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:03:22 INFO Client: Uploading resource file:/tmp/spark-c2ecc338-eb9f-459e-a4e2-a9f983ed0422/__spark_conf__1208396064862074825.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22129/__spark_conf__1208396064862074825.zip%%0001017/07/18 01:03:22 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:03:22 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:03:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:03:22 INFO Client: Submitting application 22129 to ResourceManager%%0001017/07/18 01:03:23 INFO YarnClientImpl: Submitted application application_1491786134915_22129%%0001017/07/18 01:03:24 INFO Client: Application report for application_1491786134915_22129 (state: ACCEPTED)%%0001017/07/18 01:03:24 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311002976%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22129/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:03:25 INFO Client: Application report for application_1491786134915_22129 (state: ACCEPTED)%%0001017/07/18 01:03:26 INFO Client: Application report for application_1491786134915_22129 (state: ACCEPTED)%%0001017/07/18 01:03:26 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33276/user/YarnAM#-1593142571])%%0001017/07/18 01:03:26 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22129,http://hcnnc117:8088/proxy/application_1491786134915_22129), /proxy/application_1491786134915_22129%%0001017/07/18 01:03:26 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:03:27 INFO Client: Application report for application_1491786134915_22129 (state: RUNNING)%%0001017/07/18 01:03:27 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311002976%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22129/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:03:27 INFO YarnClientSchedulerBackend: Application application_1491786134915_22129 has started running.%%0001017/07/18 01:03:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41302.%%0001017/07/18 01:03:27 INFO NettyBlockTransferService: Server created on 41302%%0001017/07/18 01:03:27 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:03:27 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:03:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41302 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41302)%%0001017/07/18 01:03:27 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:03:27 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22129%%0001017/07/18 01:03:27 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:03:27 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:03:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:03:28 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:03:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:03:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41302 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:03:28 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:03:28 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:03:28 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:03:28 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:03:28 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:03:28 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:03:28 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:03:28 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:03:28 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:03:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:03:28 INFO MemoryStore: ensureFreeSpace(3969) called with curMem=233428, maxMem=556038881%%0001017/07/18 01:03:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:03:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41302 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:03:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:03:28 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:03:29 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:03:30 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:03:31 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34207] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:53203]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:53203] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:53203%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:32 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:58328/user/Executor#-1160705187]) with ID 1%%0001017/07/18 01:03:32 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:03:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:03:32 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:60294 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 60294)%%0001017/07/18 01:03:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:60294 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:03:32 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34207] &lt;- [akka.tcp://driverPropsFetcher@hcdnc335:46797]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc335:46797] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc335:46797%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:60294 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:03:32 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc335:33257/user/Executor#-1323336664]) with ID 2%%0001017/07/18 01:03:32 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:03:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc335, partition 1,RACK_LOCAL, 2143 bytes)%%0001017/07/18 01:03:33 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc335:57385 with 530.0 MB RAM, BlockManagerId(2, hcdnc335, 57385)%%0001017/07/18 01:03:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc335:57385 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:03:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc335:57385 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:03:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2793 ms on hcdnc310 (1/2)%%0001017/07/18 01:03:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2495 ms on hcdnc335 (2/2)%%0001017/07/18 01:03:35 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 7.208 s%%0001017/07/18 01:03:35 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:35 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 7.334202 s%%0001017/07/18 01:03:35 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:03:35 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:03:35 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:03:35 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:03:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:03:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:03:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:03:35 INFO MemoryStore: ensureFreeSpace(8648) called with curMem=237397, maxMem=556038881%%0001017/07/18 01:03:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 530.0 MB)%%0001017/07/18 01:03:35 INFO MemoryStore: ensureFreeSpace(5300) called with curMem=246045, maxMem=556038881%%0001017/07/18 01:03:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:03:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41302 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:03:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:03:35 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:03:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:03:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc335, partition 1,RACK_LOCAL, 2132 bytes)%%0001017/07/18 01:03:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:60294 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:03:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc335:57385 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:03:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1374 ms on hcdnc335 (1/2)%%0001017/07/18 01:03:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 1396 ms on hcdnc310 (2/2)%%0001017/07/18 01:03:36 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 1.397 s%%0001017/07/18 01:03:36 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:36 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:36 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:36 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:03:36 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:36 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:03:36 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:03:36 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251345, maxMem=556038881%%0001017/07/18 01:03:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:03:36 INFO MemoryStore: ensureFreeSpace(4048) called with curMem=258281, maxMem=556038881%%0001017/07/18 01:03:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 530.0 MB)%%0001017/07/18 01:03:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41302 (size: 4.0 KB, free: 530.2 MB)%%0001017/07/18 01:03:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:03:36 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:03:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc335, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:60294 (size: 4.0 KB, free: 530.0 MB)%%0001017/07/18 01:03:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc335:57385 (size: 4.0 KB, free: 530.0 MB)%%0001017/07/18 01:03:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:58328%%0001017/07/18 01:03:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:03:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc335:33257%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 158 ms on hcdnc335 (1/2)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 157 ms on hcdnc310 (2/2)%%0001017/07/18 01:03:37 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:37 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.159 s%%0001017/07/18 01:03:37 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 1.588102 s%%0001017/07/18 01:03:37 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:03:37 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:03:37 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:03:37 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:03:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:03:37 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262329, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268849, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41302 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:03:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:03:37 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc335, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:60294 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc335:57385 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 194 ms on hcdnc335 (1/2)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 205 ms on hcdnc310 (2/2)%%0001017/07/18 01:03:37 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.206 s%%0001017/07/18 01:03:37 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:37 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.219133 s%%0001017/07/18 01:03:37 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:03:37 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:03:37 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:03:37 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:03:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:03:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272751, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279927, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41302 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:03:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:03:37 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc335, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:60294 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc335:57385 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 297 ms on hcdnc310 (1/2)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 310 ms on hcdnc335 (2/2)%%0001017/07/18 01:03:37 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:37 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.311 s%%0001017/07/18 01:03:37 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:37 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:37 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:03:37 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:37 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284076, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286860, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41302 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:03:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:03:37 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc335, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc335:57385 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:60294 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc335:33257%%0001017/07/18 01:03:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 01:03:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:58328%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc335, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc335 (1/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc310 (2/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc335, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc335 (3/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc310 (4/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc335, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc335 (5/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc310 (6/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc335, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc335 (7/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc310 (8/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc335 (9/10)%%0001017/07/18 01:03:37 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc310 (10/10)%%0001017/07/18 01:03:37 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:03:37 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:37 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.438700 s%%0001017/07/18 01:03:37 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:03:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:03:37 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:03:37 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:03:37 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:03:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:03:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(12160) called with curMem=288473, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.9 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO MemoryStore: ensureFreeSpace(6686) called with curMem=300633, maxMem=556038881%%0001017/07/18 01:03:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41302 (size: 6.5 KB, free: 530.2 MB)%%0001017/07/18 01:03:37 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:03:37 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc335, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:37 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc335:57385 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:60294 (size: 6.5 KB, free: 530.0 MB)%%0001017/07/18 01:03:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc335:33257%%0001017/07/18 01:03:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:58328%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 1096 ms on hcdnc310 (1/2)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 1157 ms on hcdnc335 (2/2)%%0001017/07/18 01:03:39 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:39 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 1.157 s%%0001017/07/18 01:03:39 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:03:39 INFO DAGScheduler: running: Set()%%0001017/07/18 01:03:39 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:03:39 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:03:39 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:03:39 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:03:39 INFO MemoryStore: ensureFreeSpace(15072) called with curMem=307319, maxMem=556038881%%0001017/07/18 01:03:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.7 KB, free 530.0 MB)%%0001017/07/18 01:03:39 INFO MemoryStore: ensureFreeSpace(7941) called with curMem=322391, maxMem=556038881%%0001017/07/18 01:03:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 01:03:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41302 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 01:03:39 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:03:39 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:03:39 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc335, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:60294 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc335:57385 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 01:03:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:58328%%0001017/07/18 01:03:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 160 bytes%%0001017/07/18 01:03:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc335:33257%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc335, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 144 ms on hcdnc335 (1/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 148 ms on hcdnc310 (2/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc335, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 81 ms on hcdnc335 (3/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 80 ms on hcdnc310 (4/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc335, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 72 ms on hcdnc335 (5/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 77 ms on hcdnc310 (6/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc335, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 71 ms on hcdnc335 (7/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 68 ms on hcdnc310 (8/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 74 ms on hcdnc335 (9/10)%%0001017/07/18 01:03:39 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 70 ms on hcdnc310 (10/10)%%0001017/07/18 01:03:39 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:03:39 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.442 s%%0001017/07/18 01:03:39 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 1.626414 s%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:03:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:03:39 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:03:39 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:03:39 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:03:39 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:03:39 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:03:39 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:03:39 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34207] &lt;- [akka.tcp://sparkExecutor@hcdnc335:33257]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc335:33257] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc335:33257%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:39 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34207] &lt;- [akka.tcp://sparkExecutor@hcdnc310:58328]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:58328] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:58328%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:03:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:03:39 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:03:39 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:03:39 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:03:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:03:39 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:03:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:03:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:03:39 INFO Remoting: Remoting shut down%%0001017/07/18 01:03:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:03:40 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:03:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-c2ecc338-eb9f-459e-a4e2-a9f983ed0422%%00010"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_2">
<entry key="column_name" type="xstring" value="FailingNode"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Bash"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_3">
<entry key="column_name" type="xstring" value="currentIteration"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.IntCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="8"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_4">
<entry key="column_name" type="xstring" value="maxIterations"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.IntCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="9"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="9"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_5">
<entry key="column_name" type="xstring" value="index_of_drugColumn"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="4.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="4.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_6">
<entry key="column_name" type="xstring" value="minSupport"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.005"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.009999999999999998"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_7">
<entry key="column_name" type="xstring" value="minConfidence"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.2"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.4000000000000001"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_8">
<entry key="column_name" type="xstring" value="cmd"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.005 0.2"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.005 0.3"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.005 0.4"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.0075 0.2"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.0075 0.3"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.0075 0.4"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.01 0.2"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.01 0.3"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.AD.csv 4 0.01 0.4"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_9">
<entry key="column_name" type="xstring" value="RowID"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="0"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="2"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="3"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="4"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="5"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="6"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="7"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="8"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_10">
<entry key="column_name" type="xstring" value="config_host_ip"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="140.110.30.32"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_11">
<entry key="column_name" type="xstring" value="task_minConfidenceLower"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="20.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="20.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_12">
<entry key="column_name" type="xstring" value="task_local_attr_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.feature.TCM.summary.level123.QiFlavorMeri.20170621.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_13">
<entry key="column_name" type="xstring" value="config_password"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1q2w3e4r"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_14">
<entry key="column_name" type="xstring" value="config_local_NHIcode_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.TCM.HF_SH.20170703.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_15">
<entry key="column_name" type="xstring" value="config_local_metadata_fullpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_16">
<entry key="column_name" type="xstring" value="task_minConfidenceStep"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="10.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="10.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_17">
<entry key="column_name" type="xstring" value="task_local_keyword_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.keyword.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_18">
<entry key="column_name" type="xstring" value="task_drugColumnIndex"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="4.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="4.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_19">
<entry key="column_name" type="xstring" value="task_updateCachedDataFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_20">
<entry key="column_name" type="xstring" value="task_name_Ch"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value=""/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_21">
<entry key="column_name" type="xstring" value="config_local_output_fullpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData/Sample"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_22">
<entry key="column_name" type="xstring" value="task_minSupportUpper"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="1.25"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="1.25"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_23">
<entry key="column_name" type="xstring" value="task_local_cachedData_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.cachedData.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_24">
<entry key="column_name" type="xstring" value="task_updateCachedPubmedFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="N"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_25">
<entry key="column_name" type="xstring" value="task_name"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="atopic dermatitis"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_26">
<entry key="column_name" type="xstring" value="task_minConfidenceUpper"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="50.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="50.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_27">
<entry key="column_name" type="xstring" value="config_local_translation_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.NAME.translation_shortform.20170625.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_28">
<entry key="column_name" type="xstring" value="task_local_translation_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.NAME.translation_shortform.20170625.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_29">
<entry key="column_name" type="xstring" value="config_graphspace_id"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="yuchn.chen@gmail.com"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_30">
<entry key="column_name" type="xstring" value="task_local_NHIcode_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.TCM.HF_SH.20170703.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_31">
<entry key="column_name" type="xstring" value="config_graphspace_pwd"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1q2w3e4r"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_32">
<entry key="column_name" type="xstring" value="task_local_cachedPubmed_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.cachedPubmed.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_33">
<entry key="column_name" type="xstring" value="config_local_cachedData_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.cachedData.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_34">
<entry key="column_name" type="xstring" value="task_remote_srcFilemname"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="/home_i1/y23ycc01/incoming/tid.AD.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_35">
<entry key="column_name" type="xstring" value="config_local_cachedPubmed_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.cachedPubmed.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_36">
<entry key="column_name" type="xstring" value="task_remote_srcFilepath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="/home_i1/y23ycc01/incoming"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_37">
<entry key="column_name" type="xstring" value="config_user_id"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="y23ycc01"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_38">
<entry key="column_name" type="xstring" value="task_forceReanalyze"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_39">
<entry key="column_name" type="xstring" value="config_workpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="incoming"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_40">
<entry key="column_name" type="xstring" value="task_reuploadSrcFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_41">
<entry key="column_name" type="xstring" value="task_minSupportLower"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.5"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.5"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_42">
<entry key="column_name" type="xstring" value="config_local_keyword_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.keyword.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_43">
<entry key="column_name" type="xstring" value="task_minSupportStep"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.25"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.25"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_44">
<entry key="column_name" type="xstring" value="config_local_attr_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.feature.TCM.summary.level123.QiFlavorMeri.20170621.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_45">
<entry key="column_name" type="xstring" value="task_srcFileExt"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value=".csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_46">
<entry key="column_name" type="xstring" value="task_srcFilename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="tid.AD"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_47">
<entry key="column_name" type="xstring" value="task_srcDirectory"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Dropbox\1.Projects\Cytoscape\testData\Sample"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_48">
<entry key="column_name" type="xstring" value="task_local_srcfilename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Dropbox\1.Projects\Cytoscape\testData\Sample\tid.AD.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_49">
<entry key="column_name" type="xstring" value="knime.workspace"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Users\yuchn\knime-workspace"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
</config>
