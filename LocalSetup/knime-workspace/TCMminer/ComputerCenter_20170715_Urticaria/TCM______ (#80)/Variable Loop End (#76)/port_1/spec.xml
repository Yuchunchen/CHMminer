<?xml version="1.0" encoding="UTF-8"?>
<config xmlns="http://www.knime.org/2008/09/XMLConfig" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.knime.org/2008/09/XMLConfig http://www.knime.org/XMLConfig_2008_09.xsd" key="spec.xml">
<entry key="spec_name" type="xstring" value="default"/>
<entry key="number_columns" type="xint" value="50"/>
<config key="column_spec_0">
<entry key="column_name" type="xstring" value="FailingNodeStackTrace"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:18:21 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:18:22 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:18:22 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:18:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:18:22 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:18:22 INFO Remoting: Starting remoting%%0001017/07/18 01:18:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37367]%%0001017/07/18 01:18:23 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37367]%%0001017/07/18 01:18:23 INFO Utils: Successfully started service 'sparkDriver' on port 37367.%%0001017/07/18 01:18:23 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:18:23 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:18:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d157f2a4-5bb6-492a-b4a4-c70e2b5d9cf8%%0001017/07/18 01:18:23 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:18:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-166b01c8-01ef-45b5-9828-2937e401ffce/httpd-9d4180f6-2627-4e39-97a5-0230e99549e5%%0001017/07/18 01:18:23 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:18:23 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:18:23 INFO AbstractConnector: Started SocketConnector@0.0.0.0:42112%%0001017/07/18 01:18:23 INFO Utils: Successfully started service 'HTTP file server' on port 42112.%%0001017/07/18 01:18:23 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:18:23 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:18:23 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:18:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:18:23 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:18:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:18:24 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:18:24 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:18:24 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:18:24 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:18:24 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:18:24 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:18:24 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:18:25 INFO Client: Uploading resource file:/tmp/spark-166b01c8-01ef-45b5-9828-2937e401ffce/__spark_conf__2349566215010369748.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22130/__spark_conf__2349566215010369748.zip%%0001017/07/18 01:18:25 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:18:25 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:18:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:18:25 INFO Client: Submitting application 22130 to ResourceManager%%0001017/07/18 01:18:26 INFO YarnClientImpl: Submitted application application_1491786134915_22130%%0001017/07/18 01:18:27 INFO Client: Application report for application_1491786134915_22130 (state: ACCEPTED)%%0001017/07/18 01:18:27 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311905783%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22130/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:18:28 INFO Client: Application report for application_1491786134915_22130 (state: ACCEPTED)%%0001017/07/18 01:18:28 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:53822/user/YarnAM#-817914922])%%0001017/07/18 01:18:28 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22130,http://hcnnc117:8088/proxy/application_1491786134915_22130), /proxy/application_1491786134915_22130%%0001017/07/18 01:18:28 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:18:29 INFO Client: Application report for application_1491786134915_22130 (state: ACCEPTED)%%0001017/07/18 01:18:30 INFO Client: Application report for application_1491786134915_22130 (state: RUNNING)%%0001017/07/18 01:18:30 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311905783%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22130/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:18:30 INFO YarnClientSchedulerBackend: Application application_1491786134915_22130 has started running.%%0001017/07/18 01:18:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39488.%%0001017/07/18 01:18:30 INFO NettyBlockTransferService: Server created on 39488%%0001017/07/18 01:18:30 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:18:30 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:18:30 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:39488 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 39488)%%0001017/07/18 01:18:30 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:18:30 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22130%%0001017/07/18 01:18:30 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:18:30 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:18:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:18:30 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:18:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:18:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:39488 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:18:30 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:18:30 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:18:30 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:18:30 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:18:30 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:18:30 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:18:30 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:18:30 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:18:30 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:18:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:18:30 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:18:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:18:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:39488 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:18:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:18:31 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:18:32 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:18:33 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:18:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37367] &lt;- [akka.tcp://driverPropsFetcher@hcdnc226:33767]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc226:33767] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc226:33767%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:18:34 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc226:33845/user/Executor#-63220186]) with ID 1%%0001017/07/18 01:18:34 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:18:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc226, partition 0,NODE_LOCAL, 2150 bytes)%%0001017/07/18 01:18:35 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc226:59868 with 530.0 MB RAM, BlockManagerId(1, hcdnc226, 59868)%%0001017/07/18 01:18:35 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37367] &lt;- [akka.tcp://driverPropsFetcher@hcdnc240:41342]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc240:41342] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc240:41342%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:18:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc226:59868 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:18:35 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc240:38058/user/Executor#-1496461239]) with ID 2%%0001017/07/18 01:18:35 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:18:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc240, partition 1,NODE_LOCAL, 2150 bytes)%%0001017/07/18 01:18:35 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc240:45519 with 530.0 MB RAM, BlockManagerId(2, hcdnc240, 45519)%%0001017/07/18 01:18:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc226:59868 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:18:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc240:45519 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:18:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc240:45519 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:18:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5899 ms on hcdnc226 (1/2)%%0001017/07/18 01:18:40 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5317 ms on hcdnc240 (2/2)%%0001017/07/18 01:18:40 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 9.819 s%%0001017/07/18 01:18:40 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:40 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 9.942036 s%%0001017/07/18 01:18:40 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:18:40 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:18:40 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:18:40 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:18:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:18:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:18:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:18:40 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:18:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:18:40 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:18:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:18:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:39488 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:18:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:18:40 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:18:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc226, partition 0,NODE_LOCAL, 2139 bytes)%%0001017/07/18 01:18:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc240, partition 1,NODE_LOCAL, 2139 bytes)%%0001017/07/18 01:18:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc226:59868 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:18:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc240:45519 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:18:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5260 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5442 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:46 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:46 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.443 s%%0001017/07/18 01:18:46 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:18:46 INFO DAGScheduler: running: Set()%%0001017/07/18 01:18:46 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:18:46 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:18:46 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:18:46 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:18:46 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:18:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:18:46 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:18:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:39488 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:18:46 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:18:46 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:18:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc240, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc226, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc226:59868 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc240:45519 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:18:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc226:33845%%0001017/07/18 01:18:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:18:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc240:38058%%0001017/07/18 01:18:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 472 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 453 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:46 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:46 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.474 s%%0001017/07/18 01:18:46 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.947371 s%%0001017/07/18 01:18:46 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:18:46 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:18:46 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:18:46 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:18:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:18:46 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:18:46 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:18:46 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:18:46 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:18:46 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:18:46 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:39488 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:18:46 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:18:46 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:18:46 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc240, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:46 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc226, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc240:45519 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc226:59868 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:18:47 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 665 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:47 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 704 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:47 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:47 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.705 s%%0001017/07/18 01:18:47 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.718407 s%%0001017/07/18 01:18:47 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:18:47 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:18:47 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:18:47 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:18:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:18:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:18:47 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:18:47 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:18:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:18:47 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:18:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:18:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:39488 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:18:47 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:18:47 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:18:47 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc240, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:18:47 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc226, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:18:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc226:59868 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:18:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc240:45519 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 709 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 709 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:48 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:48 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.710 s%%0001017/07/18 01:18:48 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:18:48 INFO DAGScheduler: running: Set()%%0001017/07/18 01:18:48 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:18:48 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:18:48 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:18:48 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:18:48 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:18:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:18:48 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:18:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:39488 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:18:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:48 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:18:48 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc240, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc226, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc240:45519 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc226:59868 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc226:33845%%0001017/07/18 01:18:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:18:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc240:38058%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc240, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc240 (1/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc226, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc226 (2/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc240, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 12 ms on hcdnc240 (3/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc226, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc226 (4/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc240, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 16 ms on hcdnc240 (5/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc226, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 16 ms on hcdnc226 (6/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc226, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc240, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 13 ms on hcdnc226 (7/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 18 ms on hcdnc240 (8/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 10 ms on hcdnc226 (9/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc240 (10/10)%%0001017/07/18 01:18:48 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:48 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.099 s%%0001017/07/18 01:18:48 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.829421 s%%0001017/07/18 01:18:48 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:18:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:18:48 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:18:48 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:18:48 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:18:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:18:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:18:48 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:18:48 INFO MemoryStore: ensureFreeSpace(14160) called with curMem=288498, maxMem=556038881%%0001017/07/18 01:18:48 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.8 KB, free 530.0 MB)%%0001017/07/18 01:18:48 INFO MemoryStore: ensureFreeSpace(7802) called with curMem=302658, maxMem=556038881%%0001017/07/18 01:18:48 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:39488 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:18:48 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:18:48 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc226, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc240, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc240:45519 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc226:59868 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc240:38058%%0001017/07/18 01:18:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc226:33845%%0001017/07/18 01:18:52 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 4024 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:52 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 4176 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:52 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:52 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 4.177 s%%0001017/07/18 01:18:52 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:18:52 INFO DAGScheduler: running: Set()%%0001017/07/18 01:18:52 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:18:52 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:18:52 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:18:52 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:18:52 INFO MemoryStore: ensureFreeSpace(17512) called with curMem=310460, maxMem=556038881%%0001017/07/18 01:18:52 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.1 KB, free 530.0 MB)%%0001017/07/18 01:18:52 INFO MemoryStore: ensureFreeSpace(9322) called with curMem=327972, maxMem=556038881%%0001017/07/18 01:18:52 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 530.0 MB)%%0001017/07/18 01:18:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:39488 (size: 9.1 KB, free: 530.2 MB)%%0001017/07/18 01:18:52 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:52 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:18:52 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:18:52 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc226, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:52 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc240, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc226:59868 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:18:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc240:45519 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:18:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc226:33845%%0001017/07/18 01:18:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 01:18:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc240:38058%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc226, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 348 ms on hcdnc226 (1/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc240, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 354 ms on hcdnc240 (2/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc240, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 182 ms on hcdnc240 (3/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc226, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 225 ms on hcdnc226 (4/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc226, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 158 ms on hcdnc226 (5/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc240, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 201 ms on hcdnc240 (6/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc226, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 160 ms on hcdnc226 (7/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc240, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 200 ms on hcdnc240 (8/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 178 ms on hcdnc226 (9/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 183 ms on hcdnc240 (10/10)%%0001017/07/18 01:18:53 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:53 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.118 s%%0001017/07/18 01:18:53 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 5.322727 s%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:18:54 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:18:54 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:18:54 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:18:54 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:18:54 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:18:54 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:18:54 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37367] &lt;- [akka.tcp://sparkExecutor@hcdnc240:38058]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc240:38058] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc240:38058%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:18:54 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37367] &lt;- [akka.tcp://sparkExecutor@hcdnc226:33845]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc226:33845] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc226:33845%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:18:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:18:54 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:18:54 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:18:54 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:18:54 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:18:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:18:54 INFO Remoting: Remoting shut down%%0001017/07/18 01:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:18:55 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:18:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-166b01c8-01ef-45b5-9828-2937e401ffce%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:19:10 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:19:11 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:19:11 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:19:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:19:11 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:19:11 INFO Remoting: Starting remoting%%0001017/07/18 01:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37078]%%0001017/07/18 01:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37078]%%0001017/07/18 01:19:11 INFO Utils: Successfully started service 'sparkDriver' on port 37078.%%0001017/07/18 01:19:11 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:19:11 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:19:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a40a5255-9b97-4c72-b3ee-d69aead542b0%%0001017/07/18 01:19:12 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:19:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-a4d0f18e-8df6-477d-9179-0ce338032683/httpd-744d3d90-5a5d-4ba0-900a-11b0518e21a1%%0001017/07/18 01:19:12 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:19:12 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:19:12 INFO AbstractConnector: Started SocketConnector@0.0.0.0:42535%%0001017/07/18 01:19:12 INFO Utils: Successfully started service 'HTTP file server' on port 42535.%%0001017/07/18 01:19:12 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:19:12 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:19:13 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:19:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:19:13 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:19:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:19:13 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:19:13 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:19:13 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:19:13 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:19:13 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:19:13 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:19:13 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:19:14 INFO Client: Uploading resource file:/tmp/spark-a4d0f18e-8df6-477d-9179-0ce338032683/__spark_conf__7136701991496476249.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22131/__spark_conf__7136701991496476249.zip%%0001017/07/18 01:19:14 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:19:14 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:19:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:19:14 INFO Client: Submitting application 22131 to ResourceManager%%0001017/07/18 01:19:14 INFO YarnClientImpl: Submitted application application_1491786134915_22131%%0001017/07/18 01:19:15 INFO Client: Application report for application_1491786134915_22131 (state: ACCEPTED)%%0001017/07/18 01:19:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311954442%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22131/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:19:16 INFO Client: Application report for application_1491786134915_22131 (state: ACCEPTED)%%0001017/07/18 01:19:17 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:34576/user/YarnAM#663296323])%%0001017/07/18 01:19:17 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22131,http://hcnnc117:8088/proxy/application_1491786134915_22131), /proxy/application_1491786134915_22131%%0001017/07/18 01:19:17 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:19:17 INFO Client: Application report for application_1491786134915_22131 (state: RUNNING)%%0001017/07/18 01:19:17 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311954442%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22131/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:19:17 INFO YarnClientSchedulerBackend: Application application_1491786134915_22131 has started running.%%0001017/07/18 01:19:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38669.%%0001017/07/18 01:19:17 INFO NettyBlockTransferService: Server created on 38669%%0001017/07/18 01:19:17 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:19:17 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:19:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:38669 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 38669)%%0001017/07/18 01:19:17 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:19:18 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22131%%0001017/07/18 01:19:18 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:19:18 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:19:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:19:18 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:19:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:19:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:38669 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:19:18 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:19:18 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:19:18 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:19:18 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:19:18 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:19:18 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:19:18 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:19:18 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:19:18 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:19:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:19:18 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:19:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:19:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:38669 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:19:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:19:18 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:19:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:19:20 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:19:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37078] &lt;- [akka.tcp://driverPropsFetcher@hcdnc333:42341]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc333:42341] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc333:42341%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:19:22 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc333:46754/user/Executor#-2033028249]) with ID 1%%0001017/07/18 01:19:22 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:19:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc333, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:19:22 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc333:52903 with 530.0 MB RAM, BlockManagerId(1, hcdnc333, 52903)%%0001017/07/18 01:19:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc333:52903 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:19:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37078] &lt;- [akka.tcp://driverPropsFetcher@hcdnc307:35330]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc307:35330] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc307:35330%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:19:23 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc307:44459/user/Executor#714642931]) with ID 2%%0001017/07/18 01:19:23 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:19:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc307, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:19:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc333:52903 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:19:23 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc307:53568 with 530.0 MB RAM, BlockManagerId(2, hcdnc307, 53568)%%0001017/07/18 01:19:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc307:53568 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:19:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc307:53568 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:19:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5704 ms on hcdnc333 (1/2)%%0001017/07/18 01:19:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5350 ms on hcdnc307 (2/2)%%0001017/07/18 01:19:28 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 9.979 s%%0001017/07/18 01:19:28 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:28 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.105776 s%%0001017/07/18 01:19:28 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:19:28 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:19:28 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:19:28 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:19:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:19:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:19:28 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:19:28 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:19:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:19:28 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:19:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:19:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:38669 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:19:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:19:28 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:19:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc307, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:19:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc333, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:19:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc333:52903 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:19:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc307:53568 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:19:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5322 ms on hcdnc307 (1/2)%%0001017/07/18 01:19:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5511 ms on hcdnc333 (2/2)%%0001017/07/18 01:19:34 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:34 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.514 s%%0001017/07/18 01:19:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:19:34 INFO DAGScheduler: running: Set()%%0001017/07/18 01:19:34 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:19:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:19:34 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:19:34 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:19:34 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:19:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:19:34 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:19:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:38669 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:19:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:19:34 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:19:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc307, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc333, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc333:52903 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc307:53568 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:19:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc307:44459%%0001017/07/18 01:19:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:19:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc333:46754%%0001017/07/18 01:19:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 449 ms on hcdnc307 (1/2)%%0001017/07/18 01:19:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 451 ms on hcdnc333 (2/2)%%0001017/07/18 01:19:34 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:34 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.452 s%%0001017/07/18 01:19:34 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 6.000259 s%%0001017/07/18 01:19:34 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:19:34 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:19:34 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:19:34 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:19:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:19:34 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:19:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:19:34 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:19:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:19:34 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:19:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:38669 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:19:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:19:34 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:19:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc333, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:34 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc333:52903 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc307:53568 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:19:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 711 ms on hcdnc333 (1/2)%%0001017/07/18 01:19:35 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 752 ms on hcdnc307 (2/2)%%0001017/07/18 01:19:35 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:35 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.753 s%%0001017/07/18 01:19:35 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.767834 s%%0001017/07/18 01:19:35 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:19:35 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:19:35 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:19:35 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:19:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:19:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:19:35 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:19:35 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:19:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:19:35 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:19:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:19:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:38669 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:19:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:19:35 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:19:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc307, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:19:35 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc333, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:19:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc307:53568 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:19:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc333:52903 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 734 ms on hcdnc307 (1/2)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 752 ms on hcdnc333 (2/2)%%0001017/07/18 01:19:36 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:36 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.753 s%%0001017/07/18 01:19:36 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:19:36 INFO DAGScheduler: running: Set()%%0001017/07/18 01:19:36 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:19:36 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:19:36 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:19:36 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:19:36 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:19:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:19:36 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:19:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:38669 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:19:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:36 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:19:36 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc333, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc333:52903 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc307:53568 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc333:46754%%0001017/07/18 01:19:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:19:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc307:44459%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc333, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc333 (1/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc307, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc307 (2/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc333, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc333 (3/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc307, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc307 (4/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc333, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 16 ms on hcdnc333 (5/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc307, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 21 ms on hcdnc307 (6/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc333, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc333 (7/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc307, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc307 (8/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc333 (9/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc307 (10/10)%%0001017/07/18 01:19:36 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:36 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.107 s%%0001017/07/18 01:19:36 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.883410 s%%0001017/07/18 01:19:36 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:19:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:19:36 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:19:36 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:19:36 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:19:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:19:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:19:36 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:19:36 INFO MemoryStore: ensureFreeSpace(14160) called with curMem=288498, maxMem=556038881%%0001017/07/18 01:19:36 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.8 KB, free 530.0 MB)%%0001017/07/18 01:19:36 INFO MemoryStore: ensureFreeSpace(7802) called with curMem=302658, maxMem=556038881%%0001017/07/18 01:19:36 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:38669 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:19:36 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:19:36 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc333, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc307, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc307:53568 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc333:52903 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc307:44459%%0001017/07/18 01:19:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc333:46754%%0001017/07/18 01:19:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 4244 ms on hcdnc333 (1/2)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 4350 ms on hcdnc307 (2/2)%%0001017/07/18 01:19:41 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:41 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 4.351 s%%0001017/07/18 01:19:41 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:19:41 INFO DAGScheduler: running: Set()%%0001017/07/18 01:19:41 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:19:41 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:19:41 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:19:41 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:19:41 INFO MemoryStore: ensureFreeSpace(17512) called with curMem=310460, maxMem=556038881%%0001017/07/18 01:19:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.1 KB, free 530.0 MB)%%0001017/07/18 01:19:41 INFO MemoryStore: ensureFreeSpace(9322) called with curMem=327972, maxMem=556038881%%0001017/07/18 01:19:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 530.0 MB)%%0001017/07/18 01:19:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:38669 (size: 9.1 KB, free: 530.2 MB)%%0001017/07/18 01:19:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:19:41 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc333, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc307:53568 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:19:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc333:52903 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:19:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc307:44459%%0001017/07/18 01:19:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 01:19:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc333:46754%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc307, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 332 ms on hcdnc307 (1/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc333, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 336 ms on hcdnc333 (2/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc333, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 171 ms on hcdnc333 (3/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc307, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 222 ms on hcdnc307 (4/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc333, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 155 ms on hcdnc333 (5/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc307, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 194 ms on hcdnc307 (6/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc333, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 160 ms on hcdnc333 (7/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc307, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 181 ms on hcdnc307 (8/10)%%0001017/07/18 01:19:42 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 181 ms on hcdnc333 (9/10)%%0001017/07/18 01:19:42 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 189 ms on hcdnc307 (10/10)%%0001017/07/18 01:19:42 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:42 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.118 s%%0001017/07/18 01:19:42 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 5.499536 s%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:19:42 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:19:42 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:19:42 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:19:42 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:19:42 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:19:42 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:19:42 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37078] &lt;- [akka.tcp://sparkExecutor@hcdnc333:46754]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc333:46754] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc333:46754%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:19:42 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37078] &lt;- [akka.tcp://sparkExecutor@hcdnc307:44459]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc307:44459] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc307:44459%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:19:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:19:42 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:19:42 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:19:42 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:19:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:19:42 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:19:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:19:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:19:43 INFO Remoting: Remoting shut down%%0001017/07/18 01:19:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:19:43 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:19:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-a4d0f18e-8df6-477d-9179-0ce338032683%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:19:59 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:19:59 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:19:59 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:19:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:20:00 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:20:00 INFO Remoting: Starting remoting%%0001017/07/18 01:20:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:41779]%%0001017/07/18 01:20:00 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:41779]%%0001017/07/18 01:20:00 INFO Utils: Successfully started service 'sparkDriver' on port 41779.%%0001017/07/18 01:20:00 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:20:00 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:20:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b3a5064-a0d7-40d0-b0af-01ae6af706c2%%0001017/07/18 01:20:00 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:20:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3eda37af-a4e4-484e-b4c2-56c53115b140/httpd-c5bbefb0-7bdc-45d8-8c99-fb8fc9320720%%0001017/07/18 01:20:01 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:20:01 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:20:01 INFO AbstractConnector: Started SocketConnector@0.0.0.0:44915%%0001017/07/18 01:20:01 INFO Utils: Successfully started service 'HTTP file server' on port 44915.%%0001017/07/18 01:20:01 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:20:01 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:20:01 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:20:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:20:01 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:20:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:20:01 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:20:01 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:20:01 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:20:01 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:20:01 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:20:01 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:20:01 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:20:02 INFO Client: Uploading resource file:/tmp/spark-3eda37af-a4e4-484e-b4c2-56c53115b140/__spark_conf__3325903943632158223.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22132/__spark_conf__3325903943632158223.zip%%0001017/07/18 01:20:02 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:20:02 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:20:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:20:02 INFO Client: Submitting application 22132 to ResourceManager%%0001017/07/18 01:20:03 INFO YarnClientImpl: Submitted application application_1491786134915_22132%%0001017/07/18 01:20:04 INFO Client: Application report for application_1491786134915_22132 (state: ACCEPTED)%%0001017/07/18 01:20:04 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312003009%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22132/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:20:05 INFO Client: Application report for application_1491786134915_22132 (state: ACCEPTED)%%0001017/07/18 01:20:06 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:57905/user/YarnAM#1241885629])%%0001017/07/18 01:20:06 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22132,http://hcnnc117:8088/proxy/application_1491786134915_22132), /proxy/application_1491786134915_22132%%0001017/07/18 01:20:06 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:20:06 INFO Client: Application report for application_1491786134915_22132 (state: RUNNING)%%0001017/07/18 01:20:06 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312003009%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22132/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:20:06 INFO YarnClientSchedulerBackend: Application application_1491786134915_22132 has started running.%%0001017/07/18 01:20:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33620.%%0001017/07/18 01:20:06 INFO NettyBlockTransferService: Server created on 33620%%0001017/07/18 01:20:06 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:20:06 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:20:06 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:33620 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 33620)%%0001017/07/18 01:20:06 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:20:06 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22132%%0001017/07/18 01:20:06 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:20:06 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:20:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:20:07 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:20:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:20:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:33620 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:20:07 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:20:07 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:20:07 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:20:07 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:20:07 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:20:07 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:20:07 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:20:07 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:20:07 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:20:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:20:07 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:20:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:20:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:33620 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:20:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:20:07 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:20:08 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:20:09 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:20:10 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41779] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:44913]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:44913] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:44913%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:20:11 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:37069/user/Executor#664190157]) with ID 1%%0001017/07/18 01:20:11 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:20:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc304, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:20:11 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:41229 with 530.0 MB RAM, BlockManagerId(1, hcdnc304, 41229)%%0001017/07/18 01:20:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:41229 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:20:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41779] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:46389]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:46389] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:46389%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:20:11 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:35377/user/Executor#-1947656875]) with ID 2%%0001017/07/18 01:20:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,NODE_LOCAL, 2150 bytes)%%0001017/07/18 01:20:11 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:20:11 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:40782 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 40782)%%0001017/07/18 01:20:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:41229 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:20:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:40782 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:20:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:40782 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:20:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5619 ms on hcdnc304 (1/2)%%0001017/07/18 01:20:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5782 ms on hcdnc310 (2/2)%%0001017/07/18 01:20:17 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.360 s%%0001017/07/18 01:20:17 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:17 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.484887 s%%0001017/07/18 01:20:17 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:20:17 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:20:17 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:20:17 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:20:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:20:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:20:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:20:17 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:20:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:20:17 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:20:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:20:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:33620 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:20:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:20:17 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:20:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,NODE_LOCAL, 2139 bytes)%%0001017/07/18 01:20:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:40782 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:20:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:20:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc304, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:20:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:41229 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:20:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5581 ms on hcdnc310 (1/2)%%0001017/07/18 01:20:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5251 ms on hcdnc304 (2/2)%%0001017/07/18 01:20:26 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:26 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 8.758 s%%0001017/07/18 01:20:26 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:20:26 INFO DAGScheduler: running: Set()%%0001017/07/18 01:20:26 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:20:26 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:20:26 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:20:26 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:20:26 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:20:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:20:26 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:20:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:20:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:33620 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:20:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:20:26 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:20:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:41229 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:20:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:40782 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:20:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:37069%%0001017/07/18 01:20:26 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:20:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:35377%%0001017/07/18 01:20:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 435 ms on hcdnc304 (1/2)%%0001017/07/18 01:20:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 491 ms on hcdnc310 (2/2)%%0001017/07/18 01:20:26 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:26 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.493 s%%0001017/07/18 01:20:26 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 9.282114 s%%0001017/07/18 01:20:27 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:20:27 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:20:27 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:20:27 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:20:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:20:27 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:20:27 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:20:27 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:20:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:20:27 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:20:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:33620 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:20:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:20:27 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:20:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:27 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:41229 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:40782 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:20:27 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 714 ms on hcdnc310 (1/2)%%0001017/07/18 01:20:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 747 ms on hcdnc304 (2/2)%%0001017/07/18 01:20:27 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:27 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.749 s%%0001017/07/18 01:20:27 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.760965 s%%0001017/07/18 01:20:27 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:20:27 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:20:27 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:20:27 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:20:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:20:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:20:27 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:20:27 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:20:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:20:27 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:20:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:33620 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:20:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:20:27 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:20:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc304, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:20:27 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:41229 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:40782 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 705 ms on hcdnc304 (1/2)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 779 ms on hcdnc310 (2/2)%%0001017/07/18 01:20:28 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:28 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.780 s%%0001017/07/18 01:20:28 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:20:28 INFO DAGScheduler: running: Set()%%0001017/07/18 01:20:28 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:20:28 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:20:28 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:20:28 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:20:28 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:20:28 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:20:28 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:20:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:33620 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:20:28 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:28 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:20:28 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:40782 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:41229 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:35377%%0001017/07/18 01:20:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:20:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:37069%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 41 ms on hcdnc310 (1/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 51 ms on hcdnc304 (2/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc310 (3/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc304, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 13 ms on hcdnc304 (4/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc310 (5/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 16 ms on hcdnc304 (6/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc310 (7/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc304 (8/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc310 (9/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc304 (10/10)%%0001017/07/18 01:20:28 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:28 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 01:20:28 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.902961 s%%0001017/07/18 01:20:28 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:20:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:20:28 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:20:28 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:20:28 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:20:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:20:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:20:28 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:20:28 INFO MemoryStore: ensureFreeSpace(14160) called with curMem=288498, maxMem=556038881%%0001017/07/18 01:20:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.8 KB, free 530.0 MB)%%0001017/07/18 01:20:28 INFO MemoryStore: ensureFreeSpace(7802) called with curMem=302658, maxMem=556038881%%0001017/07/18 01:20:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:33620 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:20:28 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:20:28 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:40782 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:41229 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:35377%%0001017/07/18 01:20:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:37069%%0001017/07/18 01:20:32 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 3999 ms on hcdnc304 (1/2)%%0001017/07/18 01:20:32 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 4091 ms on hcdnc310 (2/2)%%0001017/07/18 01:20:32 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 4.091 s%%0001017/07/18 01:20:32 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:32 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:20:32 INFO DAGScheduler: running: Set()%%0001017/07/18 01:20:32 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:20:32 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:20:32 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:20:32 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:20:32 INFO MemoryStore: ensureFreeSpace(17512) called with curMem=310460, maxMem=556038881%%0001017/07/18 01:20:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.1 KB, free 530.0 MB)%%0001017/07/18 01:20:32 INFO MemoryStore: ensureFreeSpace(9322) called with curMem=327972, maxMem=556038881%%0001017/07/18 01:20:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 530.0 MB)%%0001017/07/18 01:20:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:33620 (size: 9.1 KB, free: 530.2 MB)%%0001017/07/18 01:20:32 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:32 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:20:32 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:20:32 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:32 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:40782 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:20:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:41229 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:20:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:35377%%0001017/07/18 01:20:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 01:20:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:37069%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 309 ms on hcdnc304 (1/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 329 ms on hcdnc310 (2/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 181 ms on hcdnc304 (3/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 218 ms on hcdnc310 (4/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 163 ms on hcdnc304 (5/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 167 ms on hcdnc310 (6/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 189 ms on hcdnc304 (7/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 177 ms on hcdnc310 (8/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 187 ms on hcdnc304 (9/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 162 ms on hcdnc310 (10/10)%%0001017/07/18 01:20:33 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:33 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.049 s%%0001017/07/18 01:20:33 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 5.165355 s%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:20:34 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:20:34 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:20:34 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:20:34 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:20:34 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:20:34 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:20:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41779] &lt;- [akka.tcp://sparkExecutor@hcdnc310:35377]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:35377] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:35377%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:20:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41779] &lt;- [akka.tcp://sparkExecutor@hcdnc304:37069]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:37069] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:37069%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:20:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:20:34 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:20:34 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:20:34 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:20:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:20:34 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:20:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:20:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:20:34 INFO Remoting: Remoting shut down%%0001017/07/18 01:20:34 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:20:35 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:20:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-3eda37af-a4e4-484e-b4c2-56c53115b140/pyspark-90913d2c-e2a8-45a7-80f5-de2424b90e9e%%0001017/07/18 01:20:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-3eda37af-a4e4-484e-b4c2-56c53115b140%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:20:49 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:20:50 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:20:50 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:20:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:20:51 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:20:51 INFO Remoting: Starting remoting%%0001017/07/18 01:20:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38439]%%0001017/07/18 01:20:51 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38439]%%0001017/07/18 01:20:51 INFO Utils: Successfully started service 'sparkDriver' on port 38439.%%0001017/07/18 01:20:51 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:20:51 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:20:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a2b1b3dc-72b9-4d4c-8d66-7bb0c8f6ba50%%0001017/07/18 01:20:51 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:20:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-14ed47ee-6376-4583-ad1b-9b22839d8a0c/httpd-22a2206e-12fb-49ae-b7e1-0ea3480529dc%%0001017/07/18 01:20:51 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:20:51 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:20:51 INFO AbstractConnector: Started SocketConnector@0.0.0.0:35314%%0001017/07/18 01:20:51 INFO Utils: Successfully started service 'HTTP file server' on port 35314.%%0001017/07/18 01:20:51 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:20:52 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:20:52 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:20:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:20:52 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:20:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:20:52 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:20:52 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:20:52 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:20:52 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:20:52 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:20:52 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:20:52 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:20:52 INFO Client: Uploading resource file:/tmp/spark-14ed47ee-6376-4583-ad1b-9b22839d8a0c/__spark_conf__1113759508732526743.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22133/__spark_conf__1113759508732526743.zip%%0001017/07/18 01:20:53 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:20:53 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:20:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:20:53 INFO Client: Submitting application 22133 to ResourceManager%%0001017/07/18 01:20:53 INFO YarnClientImpl: Submitted application application_1491786134915_22133%%0001017/07/18 01:20:54 INFO Client: Application report for application_1491786134915_22133 (state: ACCEPTED)%%0001017/07/18 01:20:54 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312053389%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22133/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:20:55 INFO Client: Application report for application_1491786134915_22133 (state: ACCEPTED)%%0001017/07/18 01:20:56 INFO Client: Application report for application_1491786134915_22133 (state: ACCEPTED)%%0001017/07/18 01:20:56 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:53212/user/YarnAM#1392167049])%%0001017/07/18 01:20:56 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22133,http://hcnnc117:8088/proxy/application_1491786134915_22133), /proxy/application_1491786134915_22133%%0001017/07/18 01:20:56 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:20:57 INFO Client: Application report for application_1491786134915_22133 (state: RUNNING)%%0001017/07/18 01:20:57 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312053389%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22133/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:20:57 INFO YarnClientSchedulerBackend: Application application_1491786134915_22133 has started running.%%0001017/07/18 01:20:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38762.%%0001017/07/18 01:20:57 INFO NettyBlockTransferService: Server created on 38762%%0001017/07/18 01:20:57 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:20:57 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:20:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:38762 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 38762)%%0001017/07/18 01:20:57 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:20:58 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22133%%0001017/07/18 01:20:58 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:20:59 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:20:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:20:59 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:20:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:20:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:38762 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:20:59 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:20:59 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:20:59 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:20:59 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:20:59 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:20:59 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:20:59 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:20:59 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:20:59 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:20:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:20:59 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:20:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:20:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:38762 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:20:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:20:59 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:21:00 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:21:01 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:21:03 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38439] &lt;- [akka.tcp://driverPropsFetcher@hcdnc823:56136]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:56136] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:56136%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:03 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc823:36870/user/Executor#73418100]) with ID 1%%0001017/07/18 01:21:03 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:21:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc823, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:21:03 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc823:35364 with 530.0 MB RAM, BlockManagerId(1, hcdnc823, 35364)%%0001017/07/18 01:21:03 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38439] &lt;- [akka.tcp://driverPropsFetcher@hcdnc822:38629]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc822:38629] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc822:38629%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc823:35364 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:04 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc822:50981/user/Executor#1866875818]) with ID 2%%0001017/07/18 01:21:04 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:21:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc822, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:21:04 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc822:54085 with 530.0 MB RAM, BlockManagerId(2, hcdnc822, 54085)%%0001017/07/18 01:21:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc823:35364 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc822:54085 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc822:54085 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5600 ms on hcdnc823 (1/2)%%0001017/07/18 01:21:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5322 ms on hcdnc822 (2/2)%%0001017/07/18 01:21:09 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 9.912 s%%0001017/07/18 01:21:09 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:09 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.035407 s%%0001017/07/18 01:21:09 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:21:09 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:21:09 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:21:09 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:21:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:21:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:21:09 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:21:09 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:21:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:21:09 INFO MemoryStore: ensureFreeSpace(5306) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:21:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:21:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:38762 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:21:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:21:09 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:21:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc822, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:21:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc823, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:21:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc822:54085 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:21:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc823:35364 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:21:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5340 ms on hcdnc822 (1/2)%%0001017/07/18 01:21:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5446 ms on hcdnc823 (2/2)%%0001017/07/18 01:21:15 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.448 s%%0001017/07/18 01:21:15 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:15 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:21:15 INFO DAGScheduler: running: Set()%%0001017/07/18 01:21:15 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:21:15 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:21:15 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:21:15 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:21:15 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251374, maxMem=556038881%%0001017/07/18 01:21:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:21:15 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258310, maxMem=556038881%%0001017/07/18 01:21:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:38762 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:21:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:21:15 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:21:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc822, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc822:54085 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc823:35364 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc822:50981%%0001017/07/18 01:21:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:21:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:36870%%0001017/07/18 01:21:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 436 ms on hcdnc822 (1/2)%%0001017/07/18 01:21:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 494 ms on hcdnc823 (2/2)%%0001017/07/18 01:21:15 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.495 s%%0001017/07/18 01:21:15 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:15 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.974024 s%%0001017/07/18 01:21:15 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:21:15 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:21:15 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:21:15 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:21:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:21:15 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:21:15 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:21:15 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262353, maxMem=556038881%%0001017/07/18 01:21:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:21:15 INFO MemoryStore: ensureFreeSpace(3901) called with curMem=268873, maxMem=556038881%%0001017/07/18 01:21:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:38762 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:21:15 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:21:15 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:21:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:15 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc822, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc823:35364 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc822:54085 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:21:16 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 654 ms on hcdnc822 (1/2)%%0001017/07/18 01:21:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 707 ms on hcdnc823 (2/2)%%0001017/07/18 01:21:16 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.708 s%%0001017/07/18 01:21:16 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:16 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.721044 s%%0001017/07/18 01:21:16 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:21:16 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:21:16 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:21:16 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:21:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:21:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:21:16 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:21:16 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272774, maxMem=556038881%%0001017/07/18 01:21:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:21:16 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279950, maxMem=556038881%%0001017/07/18 01:21:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:21:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:38762 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:21:16 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:21:16 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:21:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc823, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:21:16 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc822, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:21:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc822:54085 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:21:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc823:35364 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 695 ms on hcdnc822 (1/2)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 769 ms on hcdnc823 (2/2)%%0001017/07/18 01:21:17 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:17 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.770 s%%0001017/07/18 01:21:17 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:21:17 INFO DAGScheduler: running: Set()%%0001017/07/18 01:21:17 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:21:17 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:21:17 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:21:17 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:21:17 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284099, maxMem=556038881%%0001017/07/18 01:21:17 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:21:17 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286883, maxMem=556038881%%0001017/07/18 01:21:17 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:38762 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:21:17 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:17 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:21:17 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc822, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc823, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc822:54085 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc823:35364 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc822:50981%%0001017/07/18 01:21:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 164 bytes%%0001017/07/18 01:21:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc823:36870%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc822, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 42 ms on hcdnc822 (1/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc823, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 48 ms on hcdnc823 (2/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc822, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc822 (3/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc823 (4/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc822, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc822 (5/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc823 (6/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc822, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc822 (7/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 13 ms on hcdnc823 (8/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc822 (9/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc823 (10/10)%%0001017/07/18 01:21:17 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 01:21:17 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:17 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.894061 s%%0001017/07/18 01:21:17 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:21:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:21:17 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:21:17 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:21:17 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:21:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:21:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:21:17 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:21:17 INFO MemoryStore: ensureFreeSpace(12992) called with curMem=288498, maxMem=556038881%%0001017/07/18 01:21:17 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:21:17 INFO MemoryStore: ensureFreeSpace(7138) called with curMem=301490, maxMem=556038881%%0001017/07/18 01:21:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:38762 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:21:17 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:21:17 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc822, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc823, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc822:54085 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc823:35364 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:36870%%0001017/07/18 01:21:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc822:50981%%0001017/07/18 01:21:20 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 3533 ms on hcdnc823 (1/2)%%0001017/07/18 01:21:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 3717 ms on hcdnc822 (2/2)%%0001017/07/18 01:21:20 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:20 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 3.718 s%%0001017/07/18 01:21:20 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:21:20 INFO DAGScheduler: running: Set()%%0001017/07/18 01:21:20 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:21:20 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:21:20 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:21:20 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:21:21 INFO MemoryStore: ensureFreeSpace(16080) called with curMem=308628, maxMem=556038881%%0001017/07/18 01:21:21 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:21:21 INFO MemoryStore: ensureFreeSpace(8494) called with curMem=324708, maxMem=556038881%%0001017/07/18 01:21:21 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:21:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:38762 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:21:21 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:21 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:21:21 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc822, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc822:54085 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc823:35364 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc822:50981%%0001017/07/18 01:21:21 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 162 bytes%%0001017/07/18 01:21:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc823:36870%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc823, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 312 ms on hcdnc823 (1/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc822, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 315 ms on hcdnc822 (2/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc822, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 173 ms on hcdnc822 (3/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 204 ms on hcdnc823 (4/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc822, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 160 ms on hcdnc822 (5/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 163 ms on hcdnc823 (6/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc822, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 169 ms on hcdnc822 (7/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 176 ms on hcdnc823 (8/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 163 ms on hcdnc822 (9/10)%%0001017/07/18 01:21:22 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 174 ms on hcdnc823 (10/10)%%0001017/07/18 01:21:22 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:22 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.027 s%%0001017/07/18 01:21:22 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 4.771325 s%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:21:22 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:21:22 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:21:22 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:21:22 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:21:22 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:21:22 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:21:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38439] &lt;- [akka.tcp://sparkExecutor@hcdnc822:50981]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc822:50981] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc822:50981%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38439] &lt;- [akka.tcp://sparkExecutor@hcdnc823:36870]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc823:36870] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc823:36870%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:21:22 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:21:22 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:21:22 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:21:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:21:22 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:21:22 INFO Remoting: Remoting shut down%%0001017/07/18 01:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:21:23 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:21:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-14ed47ee-6376-4583-ad1b-9b22839d8a0c/pyspark-9fa4a827-cea3-4e50-bfa8-1838978f3b8b%%0001017/07/18 01:21:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-14ed47ee-6376-4583-ad1b-9b22839d8a0c%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:21:37 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:21:38 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:21:38 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:21:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:21:38 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:21:38 INFO Remoting: Starting remoting%%0001017/07/18 01:21:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:36018]%%0001017/07/18 01:21:39 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:36018]%%0001017/07/18 01:21:39 INFO Utils: Successfully started service 'sparkDriver' on port 36018.%%0001017/07/18 01:21:40 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:21:40 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:21:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-906a5a97-e098-476d-a456-a353a6655433%%0001017/07/18 01:21:40 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:21:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-066e657a-3fcb-4f41-b470-47f295f12ba8/httpd-39796388-9652-4876-8d3f-66474db1c1ee%%0001017/07/18 01:21:40 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:21:40 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:21:40 INFO AbstractConnector: Started SocketConnector@0.0.0.0:34506%%0001017/07/18 01:21:40 INFO Utils: Successfully started service 'HTTP file server' on port 34506.%%0001017/07/18 01:21:40 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:21:40 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:21:40 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:21:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:21:40 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:21:40 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:21:40 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:21:40 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:21:40 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:21:40 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:21:40 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:21:40 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:21:40 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:21:41 INFO Client: Uploading resource file:/tmp/spark-066e657a-3fcb-4f41-b470-47f295f12ba8/__spark_conf__7263393439660899890.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22134/__spark_conf__7263393439660899890.zip%%0001017/07/18 01:21:41 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:21:41 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:21:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:21:41 INFO Client: Submitting application 22134 to ResourceManager%%0001017/07/18 01:21:42 INFO YarnClientImpl: Submitted application application_1491786134915_22134%%0001017/07/18 01:21:43 INFO Client: Application report for application_1491786134915_22134 (state: ACCEPTED)%%0001017/07/18 01:21:43 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312101839%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22134/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:21:44 INFO Client: Application report for application_1491786134915_22134 (state: ACCEPTED)%%0001017/07/18 01:21:45 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.39:47283/user/YarnAM#-212673071])%%0001017/07/18 01:21:45 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22134,http://hcnnc117:8088/proxy/application_1491786134915_22134), /proxy/application_1491786134915_22134%%0001017/07/18 01:21:45 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:21:45 INFO Client: Application report for application_1491786134915_22134 (state: ACCEPTED)%%0001017/07/18 01:21:46 INFO Client: Application report for application_1491786134915_22134 (state: RUNNING)%%0001017/07/18 01:21:46 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.39%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312101839%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22134/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:21:46 INFO YarnClientSchedulerBackend: Application application_1491786134915_22134 has started running.%%0001017/07/18 01:21:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43067.%%0001017/07/18 01:21:46 INFO NettyBlockTransferService: Server created on 43067%%0001017/07/18 01:21:46 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:21:46 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:21:46 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:43067 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 43067)%%0001017/07/18 01:21:46 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:21:46 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22134%%0001017/07/18 01:21:46 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:21:46 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:21:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:21:46 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:21:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:21:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:43067 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:21:46 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:21:47 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:21:47 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:21:47 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:21:47 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:21:47 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:21:47 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:21:47 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:21:47 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:21:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:21:47 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:21:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:21:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:43067 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:21:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:21:47 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:21:48 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:21:49 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:21:50 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36018] &lt;- [akka.tcp://driverPropsFetcher@hcdnc340:37771]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc340:37771] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc340:37771%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:51 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc340:39290/user/Executor#-1098327346]) with ID 1%%0001017/07/18 01:21:51 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:21:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc340, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:21:51 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc340:38811 with 530.0 MB RAM, BlockManagerId(1, hcdnc340, 38811)%%0001017/07/18 01:21:51 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36018] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:56776]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:56776] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:56776%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc340:38811 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:51 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:50944/user/Executor#648366636]) with ID 2%%0001017/07/18 01:21:51 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:21:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:21:51 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:54641 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 54641)%%0001017/07/18 01:21:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc340:38811 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:54641 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:54641 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5577 ms on hcdnc340 (1/2)%%0001017/07/18 01:21:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5482 ms on hcdnc310 (2/2)%%0001017/07/18 01:21:57 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.016 s%%0001017/07/18 01:21:57 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:57 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.139969 s%%0001017/07/18 01:21:57 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:21:57 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:21:57 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:21:57 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:21:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:21:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:21:57 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:21:57 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:21:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:21:57 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:21:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:21:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:43067 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:21:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:21:57 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:21:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc340, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:21:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:21:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:54641 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:21:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc340:38811 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:22:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5234 ms on hcdnc310 (1/2)%%0001017/07/18 01:22:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5629 ms on hcdnc340 (2/2)%%0001017/07/18 01:22:02 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.631 s%%0001017/07/18 01:22:02 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:02 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:02 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:02 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:22:02 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:02 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:22:02 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:22:02 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:22:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:22:02 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:22:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:22:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:43067 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:22:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:22:02 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:22:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc340:38811 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:54641 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc340:39290%%0001017/07/18 01:22:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:22:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:50944%%0001017/07/18 01:22:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 439 ms on hcdnc340 (1/2)%%0001017/07/18 01:22:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 443 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:03 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:03 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.443 s%%0001017/07/18 01:22:03 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 6.105119 s%%0001017/07/18 01:22:03 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:22:03 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:22:03 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:22:03 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:22:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:22:03 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:22:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:22:03 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:22:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:22:03 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:22:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:22:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:43067 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:22:03 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:22:03 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:22:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:03 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:54641 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:22:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc340:38811 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 680 ms on hcdnc340 (1/2)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 694 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:04 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.694 s%%0001017/07/18 01:22:04 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:04 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.707512 s%%0001017/07/18 01:22:04 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:22:04 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:22:04 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:22:04 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:22:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:22:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:22:04 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:22:04 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:22:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:22:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:22:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:43067 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:22:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:22:04 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc340, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc340:38811 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:54641 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 726 ms on hcdnc310 (1/2)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 750 ms on hcdnc340 (2/2)%%0001017/07/18 01:22:04 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:04 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.751 s%%0001017/07/18 01:22:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:04 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:04 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:22:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:04 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:22:04 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:22:04 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:22:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:22:04 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:22:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:43067 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:22:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:22:04 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc340:38811 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:54641 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc340:39290%%0001017/07/18 01:22:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 164 bytes%%0001017/07/18 01:22:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:50944%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc340, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 48 ms on hcdnc340 (1/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 54 ms on hcdnc310 (2/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc340, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 18 ms on hcdnc340 (3/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 19 ms on hcdnc310 (4/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc340, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc340 (5/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc310 (6/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc340, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc340 (7/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc310 (8/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc340 (9/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc310 (10/10)%%0001017/07/18 01:22:04 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.115 s%%0001017/07/18 01:22:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:04 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.885969 s%%0001017/07/18 01:22:05 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:22:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:22:05 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:22:05 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:22:05 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:22:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:22:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:22:05 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:22:05 INFO MemoryStore: ensureFreeSpace(12992) called with curMem=288500, maxMem=556038881%%0001017/07/18 01:22:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:22:05 INFO MemoryStore: ensureFreeSpace(7138) called with curMem=301492, maxMem=556038881%%0001017/07/18 01:22:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:22:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:43067 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:22:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:22:05 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:22:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc340, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:05 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc340:38811 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:22:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:54641 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:22:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc340:39290%%0001017/07/18 01:22:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:50944%%0001017/07/18 01:22:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 3582 ms on hcdnc340 (1/2)%%0001017/07/18 01:22:08 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 3583 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:08 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:08 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 3.584 s%%0001017/07/18 01:22:08 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:08 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:08 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:22:08 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:08 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:22:08 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:22:08 INFO MemoryStore: ensureFreeSpace(16080) called with curMem=308630, maxMem=556038881%%0001017/07/18 01:22:08 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:22:08 INFO MemoryStore: ensureFreeSpace(8494) called with curMem=324710, maxMem=556038881%%0001017/07/18 01:22:08 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:22:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:43067 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:22:08 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:08 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:22:08 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:22:08 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:08 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:54641 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc340:38811 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:50944%%0001017/07/18 01:22:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 162 bytes%%0001017/07/18 01:22:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc340:39290%%0001017/07/18 01:22:08 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:08 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 278 ms on hcdnc310 (1/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc340, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 328 ms on hcdnc340 (2/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 198 ms on hcdnc310 (3/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc340, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 185 ms on hcdnc340 (4/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 155 ms on hcdnc310 (5/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc340, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 162 ms on hcdnc340 (6/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 163 ms on hcdnc310 (7/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc340, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 170 ms on hcdnc340 (8/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 161 ms on hcdnc310 (9/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 133 ms on hcdnc340 (10/10)%%0001017/07/18 01:22:09 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:09 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.976 s%%0001017/07/18 01:22:09 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 4.587364 s%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:22:09 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:22:09 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:22:09 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:22:09 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:22:09 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:22:09 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:22:09 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36018] &lt;- [akka.tcp://sparkExecutor@hcdnc340:39290]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc340:39290] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc340:39290%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:22:09 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36018] &lt;- [akka.tcp://sparkExecutor@hcdnc310:50944]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:50944] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:50944%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:22:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:22:09 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:22:09 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:22:09 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:22:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:22:09 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:22:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:22:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:22:10 INFO Remoting: Remoting shut down%%0001017/07/18 01:22:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:22:10 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:22:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-066e657a-3fcb-4f41-b470-47f295f12ba8/pyspark-b9293a9d-469c-462f-ab11-21b48630a8ac%%0001017/07/18 01:22:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-066e657a-3fcb-4f41-b470-47f295f12ba8%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:22:27 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:22:28 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:22:28 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:22:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:22:28 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:22:28 INFO Remoting: Starting remoting%%0001017/07/18 01:22:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46448]%%0001017/07/18 01:22:28 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46448]%%0001017/07/18 01:22:28 INFO Utils: Successfully started service 'sparkDriver' on port 46448.%%0001017/07/18 01:22:28 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:22:28 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:22:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-33c864bc-e9e8-4175-bbdb-2e57a3266940%%0001017/07/18 01:22:28 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:22:29 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33444e31-83ef-42bf-b8dd-6b67f8cd547f/httpd-1983c499-1031-4103-85e9-87d84b26dc45%%0001017/07/18 01:22:29 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:22:29 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:22:29 INFO AbstractConnector: Started SocketConnector@0.0.0.0:38550%%0001017/07/18 01:22:29 INFO Utils: Successfully started service 'HTTP file server' on port 38550.%%0001017/07/18 01:22:29 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:22:29 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:22:29 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:22:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:22:29 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:22:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:22:30 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:22:30 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:22:30 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:22:30 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:22:30 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:22:30 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:22:30 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:22:30 INFO Client: Uploading resource file:/tmp/spark-33444e31-83ef-42bf-b8dd-6b67f8cd547f/__spark_conf__6393886764586091181.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22135/__spark_conf__6393886764586091181.zip%%0001017/07/18 01:22:31 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:22:31 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:22:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:22:31 INFO Client: Submitting application 22135 to ResourceManager%%0001017/07/18 01:22:31 INFO YarnClientImpl: Submitted application application_1491786134915_22135%%0001017/07/18 01:22:32 INFO Client: Application report for application_1491786134915_22135 (state: ACCEPTED)%%0001017/07/18 01:22:32 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312151211%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22135/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:22:33 INFO Client: Application report for application_1491786134915_22135 (state: ACCEPTED)%%0001017/07/18 01:22:35 INFO Client: Application report for application_1491786134915_22135 (state: ACCEPTED)%%0001017/07/18 01:22:35 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:49712/user/YarnAM#2056305724])%%0001017/07/18 01:22:35 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22135,http://hcnnc117:8088/proxy/application_1491786134915_22135), /proxy/application_1491786134915_22135%%0001017/07/18 01:22:35 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:22:36 INFO Client: Application report for application_1491786134915_22135 (state: RUNNING)%%0001017/07/18 01:22:36 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312151211%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22135/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:22:36 INFO YarnClientSchedulerBackend: Application application_1491786134915_22135 has started running.%%0001017/07/18 01:22:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34352.%%0001017/07/18 01:22:36 INFO NettyBlockTransferService: Server created on 34352%%0001017/07/18 01:22:36 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:22:36 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:22:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:34352 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 34352)%%0001017/07/18 01:22:36 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:22:36 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22135%%0001017/07/18 01:22:36 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:22:36 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:22:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:22:36 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:22:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:22:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:34352 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:22:36 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:22:37 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:22:37 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:22:37 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:22:37 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:22:37 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:22:37 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:22:37 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:22:37 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:22:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:22:37 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:22:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:22:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:34352 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:22:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:22:37 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:22:38 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:22:39 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:22:40 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46448] &lt;- [akka.tcp://driverPropsFetcher@hcdnc413:43898]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc413:43898] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc413:43898%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:22:40 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc413:51787/user/Executor#770055931]) with ID 1%%0001017/07/18 01:22:40 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:22:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc413, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:22:41 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc413:44744 with 530.0 MB RAM, BlockManagerId(1, hcdnc413, 44744)%%0001017/07/18 01:22:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc413:44744 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:41 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46448] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:34375]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:34375] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:34375%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:22:41 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:55121/user/Executor#-1670094803]) with ID 2%%0001017/07/18 01:22:41 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:22:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:22:41 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:43935 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 43935)%%0001017/07/18 01:22:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc413:44744 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:43935 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:43935 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5671 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5983 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:47 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.555 s%%0001017/07/18 01:22:47 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:47 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.677909 s%%0001017/07/18 01:22:47 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:22:47 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:22:47 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:22:47 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:22:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:22:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:22:47 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:22:47 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:22:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:22:47 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:22:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:22:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:34352 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:22:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:22:47 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:22:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc413, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:22:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:22:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:43935 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:22:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc413:44744 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:22:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5279 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5442 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:53 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:53 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.444 s%%0001017/07/18 01:22:53 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:53 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:53 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:22:53 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:53 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:22:53 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:22:53 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:22:53 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:22:53 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:22:53 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:34352 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:22:53 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:22:53 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:22:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc413, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:43935 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc413:44744 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:55121%%0001017/07/18 01:22:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:22:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc413:51787%%0001017/07/18 01:22:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 445 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 459 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.461 s%%0001017/07/18 01:22:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.936926 s%%0001017/07/18 01:22:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:22:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:22:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:22:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:22:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:22:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:22:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:22:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:22:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:22:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:22:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:34352 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:22:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:22:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:22:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc413, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:43935 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc413:44744 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:22:54 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 703 ms on hcdnc310 (1/2)%%0001017/07/18 01:22:54 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 706 ms on hcdnc413 (2/2)%%0001017/07/18 01:22:54 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.707 s%%0001017/07/18 01:22:54 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:54 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.721271 s%%0001017/07/18 01:22:54 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:22:54 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:22:54 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:22:54 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:22:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:22:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:22:54 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:22:54 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:22:54 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:22:54 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:22:54 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:22:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:34352 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:22:54 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:22:54 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:22:54 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc413, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:54 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc413:44744 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:22:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:43935 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 712 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 752 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:55 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:55 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.754 s%%0001017/07/18 01:22:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:55 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:55 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:22:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:55 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:22:55 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:22:55 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:22:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:22:55 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:22:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:34352 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:22:55 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:22:55 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc413, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc413:44744 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:43935 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:55121%%0001017/07/18 01:22:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 01:22:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc413:51787%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc413, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 47 ms on hcdnc413 (1/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 48 ms on hcdnc310 (2/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc413, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc310 (3/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 17 ms on hcdnc413 (4/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 16 ms on hcdnc310 (5/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc413, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc413 (6/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc310 (7/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc413, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc413 (8/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc310 (9/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc413 (10/10)%%0001017/07/18 01:22:55 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 01:22:55 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:55 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.878878 s%%0001017/07/18 01:22:55 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:22:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:22:55 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:22:55 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:22:55 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:22:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:22:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:22:55 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:22:55 INFO MemoryStore: ensureFreeSpace(12992) called with curMem=288500, maxMem=556038881%%0001017/07/18 01:22:55 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:22:55 INFO MemoryStore: ensureFreeSpace(7138) called with curMem=301492, maxMem=556038881%%0001017/07/18 01:22:55 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:34352 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:22:55 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:22:55 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc413, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc413:44744 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:43935 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:55121%%0001017/07/18 01:22:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc413:51787%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 3602 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 3714 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:59 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:59 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 3.715 s%%0001017/07/18 01:22:59 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:59 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:59 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:22:59 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:59 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:22:59 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:22:59 INFO MemoryStore: ensureFreeSpace(16080) called with curMem=308630, maxMem=556038881%%0001017/07/18 01:22:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:22:59 INFO MemoryStore: ensureFreeSpace(8494) called with curMem=324710, maxMem=556038881%%0001017/07/18 01:22:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:22:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:34352 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:22:59 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:59 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:22:59 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc413, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc413:44744 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:43935 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc413:51787%%0001017/07/18 01:22:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 01:22:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:55121%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 310 ms on hcdnc310 (1/10)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc413, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 328 ms on hcdnc413 (2/10)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 146 ms on hcdnc310 (3/10)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc413, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 153 ms on hcdnc413 (4/10)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 137 ms on hcdnc310 (5/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc413, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 132 ms on hcdnc413 (6/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 129 ms on hcdnc310 (7/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc413, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 141 ms on hcdnc413 (8/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 128 ms on hcdnc310 (9/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 146 ms on hcdnc413 (10/10)%%0001017/07/18 01:23:00 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.896 s%%0001017/07/18 01:23:00 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:00 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 4.639010 s%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:23:00 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:23:00 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:23:00 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:23:00 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:23:00 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:23:00 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:23:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46448] &lt;- [akka.tcp://sparkExecutor@hcdnc310:55121]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:55121] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:55121%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46448] &lt;- [akka.tcp://sparkExecutor@hcdnc413:51787]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc413:51787] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc413:51787%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:23:00 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:23:00 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:23:00 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:23:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:23:00 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:23:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:23:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:23:00 INFO Remoting: Remoting shut down%%0001017/07/18 01:23:00 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:23:01 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:23:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-33444e31-83ef-42bf-b8dd-6b67f8cd547f/pyspark-0330fc17-0f65-4646-aa4e-988319854e18%%0001017/07/18 01:23:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-33444e31-83ef-42bf-b8dd-6b67f8cd547f%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:23:16 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:23:16 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:23:16 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:23:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:23:17 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:23:17 INFO Remoting: Starting remoting%%0001017/07/18 01:23:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:34182]%%0001017/07/18 01:23:18 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:34182]%%0001017/07/18 01:23:18 INFO Utils: Successfully started service 'sparkDriver' on port 34182.%%0001017/07/18 01:23:18 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:23:18 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:23:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8a18ad3b-bed1-42a0-83cd-bbf8c2c7b20f%%0001017/07/18 01:23:18 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:23:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-bf31177f-f46c-4966-a6c4-0208996045b4/httpd-597d5bf0-74b5-4599-bb6c-b655c901c3da%%0001017/07/18 01:23:18 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:23:18 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:23:18 INFO AbstractConnector: Started SocketConnector@0.0.0.0:43504%%0001017/07/18 01:23:18 INFO Utils: Successfully started service 'HTTP file server' on port 43504.%%0001017/07/18 01:23:18 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:23:18 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:23:19 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:23:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:23:19 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:23:19 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:23:19 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:23:19 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:23:19 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:23:19 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:23:19 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:23:19 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:23:19 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:23:19 INFO Client: Uploading resource file:/tmp/spark-bf31177f-f46c-4966-a6c4-0208996045b4/__spark_conf__4347922760759535458.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22136/__spark_conf__4347922760759535458.zip%%0001017/07/18 01:23:20 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:23:20 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:23:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:23:20 INFO Client: Submitting application 22136 to ResourceManager%%0001017/07/18 01:23:20 INFO YarnClientImpl: Submitted application application_1491786134915_22136%%0001017/07/18 01:23:21 INFO Client: Application report for application_1491786134915_22136 (state: ACCEPTED)%%0001017/07/18 01:23:21 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312200396%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22136/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:23:22 INFO Client: Application report for application_1491786134915_22136 (state: ACCEPTED)%%0001017/07/18 01:23:23 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:45933/user/YarnAM#-2127329377])%%0001017/07/18 01:23:23 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22136,http://hcnnc117:8088/proxy/application_1491786134915_22136), /proxy/application_1491786134915_22136%%0001017/07/18 01:23:23 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:23:23 INFO Client: Application report for application_1491786134915_22136 (state: RUNNING)%%0001017/07/18 01:23:23 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312200396%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22136/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:23:23 INFO YarnClientSchedulerBackend: Application application_1491786134915_22136 has started running.%%0001017/07/18 01:23:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45869.%%0001017/07/18 01:23:23 INFO NettyBlockTransferService: Server created on 45869%%0001017/07/18 01:23:23 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:23:23 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:23:23 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:45869 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 45869)%%0001017/07/18 01:23:23 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:23:23 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22136%%0001017/07/18 01:23:23 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:23:24 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:23:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:23:24 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:23:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:23:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:45869 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:23:24 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:23:24 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:23:24 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:23:24 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:23:24 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:23:24 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:23:24 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:23:24 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:23:24 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:23:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:23:24 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:23:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:23:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:45869 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:23:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:23:24 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:23:25 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:23:26 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:23:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34182] &lt;- [akka.tcp://driverPropsFetcher@hcdnc329:43831]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc329:43831] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc329:43831%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:28 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc329:45303/user/Executor#1305828396]) with ID 1%%0001017/07/18 01:23:28 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:23:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc329, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:23:28 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc329:52897 with 530.0 MB RAM, BlockManagerId(1, hcdnc329, 52897)%%0001017/07/18 01:23:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34182] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:57451]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:57451] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:57451%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc329:52897 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:23:29 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:52700/user/Executor#-388640938]) with ID 2%%0001017/07/18 01:23:29 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:23:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc304, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:23:29 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:46523 with 530.0 MB RAM, BlockManagerId(2, hcdnc304, 46523)%%0001017/07/18 01:23:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc329:52897 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:23:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:46523 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:23:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:46523 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:23:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5613 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5386 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 9.883 s%%0001017/07/18 01:23:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.008374 s%%0001017/07/18 01:23:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:23:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:23:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:23:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:23:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:23:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:23:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:23:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:23:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:23:34 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:23:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:45869 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:23:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:23:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:23:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc304, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:23:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc329, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:46523 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc329:52897 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:23:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5427 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5452 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:40 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.453 s%%0001017/07/18 01:23:40 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:40 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:23:40 INFO DAGScheduler: running: Set()%%0001017/07/18 01:23:40 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:23:40 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:23:40 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:23:40 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:23:40 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:23:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:23:40 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:23:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:45869 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:23:40 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:23:40 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:23:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc329, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:40 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:46523 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc329:52897 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:23:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:52700%%0001017/07/18 01:23:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:23:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc329:45303%%0001017/07/18 01:23:40 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 444 ms on hcdnc304 (1/2)%%0001017/07/18 01:23:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 473 ms on hcdnc329 (2/2)%%0001017/07/18 01:23:40 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:40 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.474 s%%0001017/07/18 01:23:40 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.959531 s%%0001017/07/18 01:23:40 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:23:40 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:23:40 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:23:40 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:23:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:23:40 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:23:40 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:23:40 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:23:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:23:40 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:23:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:45869 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:23:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:23:40 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:23:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc329, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:40 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:46523 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc329:52897 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:23:41 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 707 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:41 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 713 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:41 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:41 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.714 s%%0001017/07/18 01:23:41 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.764131 s%%0001017/07/18 01:23:41 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:23:41 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:23:41 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:23:41 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:23:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:23:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:23:41 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:23:41 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:23:41 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:23:41 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:23:41 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:23:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:45869 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:23:41 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:23:41 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:23:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc304, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:23:41 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc329, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:23:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:46523 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:23:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc329:52897 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 755 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 782 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:42 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:42 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.782 s%%0001017/07/18 01:23:42 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:23:42 INFO DAGScheduler: running: Set()%%0001017/07/18 01:23:42 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:23:42 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:23:42 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:23:42 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:23:42 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:23:42 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:23:42 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:23:42 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:45869 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:23:42 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:42 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:23:42 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc329, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc329:52897 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:46523 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:52700%%0001017/07/18 01:23:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:23:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc329:45303%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc304 (1/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc329, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 48 ms on hcdnc329 (2/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc304 (3/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc329, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc329 (4/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc304 (5/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc329, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc329 (6/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc304 (7/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc329, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 17 ms on hcdnc329 (8/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc304 (9/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc329 (10/10)%%0001017/07/18 01:23:42 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.107 s%%0001017/07/18 01:23:42 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:42 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.911438 s%%0001017/07/18 01:23:42 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:23:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:23:42 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:23:42 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:23:42 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:23:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:23:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:23:42 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:23:42 INFO MemoryStore: ensureFreeSpace(12024) called with curMem=288500, maxMem=556038881%%0001017/07/18 01:23:42 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.7 KB, free 530.0 MB)%%0001017/07/18 01:23:42 INFO MemoryStore: ensureFreeSpace(6601) called with curMem=300524, maxMem=556038881%%0001017/07/18 01:23:42 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:45869 (size: 6.4 KB, free: 530.2 MB)%%0001017/07/18 01:23:42 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:23:42 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc304, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc329, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:46523 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc329:52897 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:52700%%0001017/07/18 01:23:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc329:45303%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 2814 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 2879 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:45 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:45 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 2.879 s%%0001017/07/18 01:23:45 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:23:45 INFO DAGScheduler: running: Set()%%0001017/07/18 01:23:45 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:23:45 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:23:45 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:23:45 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:23:45 INFO MemoryStore: ensureFreeSpace(14904) called with curMem=307125, maxMem=556038881%%0001017/07/18 01:23:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.6 KB, free 530.0 MB)%%0001017/07/18 01:23:45 INFO MemoryStore: ensureFreeSpace(7823) called with curMem=322029, maxMem=556038881%%0001017/07/18 01:23:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:23:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:45869 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:23:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:23:45 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc329, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:46523 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:23:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc329:52897 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:23:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:52700%%0001017/07/18 01:23:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 01:23:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc329:45303%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc329, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 236 ms on hcdnc329 (1/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 246 ms on hcdnc304 (2/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 143 ms on hcdnc304 (3/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc329, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 155 ms on hcdnc329 (4/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc329, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 107 ms on hcdnc329 (5/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 111 ms on hcdnc304 (6/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc329, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 105 ms on hcdnc329 (7/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 127 ms on hcdnc304 (8/10)%%0001017/07/18 01:23:46 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 126 ms on hcdnc329 (9/10)%%0001017/07/18 01:23:46 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 144 ms on hcdnc304 (10/10)%%0001017/07/18 01:23:46 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:46 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.767 s%%0001017/07/18 01:23:46 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 3.672150 s%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:23:46 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:23:46 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:23:46 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:23:46 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:23:46 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:23:46 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:23:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34182] &lt;- [akka.tcp://sparkExecutor@hcdnc329:45303]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc329:45303] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc329:45303%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34182] &lt;- [akka.tcp://sparkExecutor@hcdnc304:52700]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:52700] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:52700%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:23:46 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:23:46 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:23:46 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:23:46 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:23:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:23:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:23:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:23:46 INFO Remoting: Remoting shut down%%0001017/07/18 01:23:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:23:47 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:23:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-bf31177f-f46c-4966-a6c4-0208996045b4%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:24:02 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:24:03 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:24:03 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:24:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:24:04 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:24:04 INFO Remoting: Starting remoting%%0001017/07/18 01:24:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:44031]%%0001017/07/18 01:24:04 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:44031]%%0001017/07/18 01:24:04 INFO Utils: Successfully started service 'sparkDriver' on port 44031.%%0001017/07/18 01:24:04 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:24:04 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:24:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e5f3c74b-337d-4d8b-989f-85be58958323%%0001017/07/18 01:24:04 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:24:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-48143d2b-7dc1-43d9-82fb-cad1be2acae5/httpd-2db14472-f6b1-4136-b509-53bd7ebf660f%%0001017/07/18 01:24:05 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:24:05 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:24:05 INFO AbstractConnector: Started SocketConnector@0.0.0.0:37245%%0001017/07/18 01:24:05 INFO Utils: Successfully started service 'HTTP file server' on port 37245.%%0001017/07/18 01:24:05 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:24:05 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:24:05 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:24:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:24:05 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:24:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:24:05 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:24:05 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:24:05 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:24:05 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:24:05 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:24:05 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:24:05 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:24:06 INFO Client: Uploading resource file:/tmp/spark-48143d2b-7dc1-43d9-82fb-cad1be2acae5/__spark_conf__3321120254950138705.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22137/__spark_conf__3321120254950138705.zip%%0001017/07/18 01:24:06 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:24:06 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:24:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:24:06 INFO Client: Submitting application 22137 to ResourceManager%%0001017/07/18 01:24:06 INFO YarnClientImpl: Submitted application application_1491786134915_22137%%0001017/07/18 01:24:07 INFO Client: Application report for application_1491786134915_22137 (state: ACCEPTED)%%0001017/07/18 01:24:07 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312246537%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22137/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:24:08 INFO Client: Application report for application_1491786134915_22137 (state: ACCEPTED)%%0001017/07/18 01:24:09 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33593/user/YarnAM#-1127319109])%%0001017/07/18 01:24:09 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22137,http://hcnnc117:8088/proxy/application_1491786134915_22137), /proxy/application_1491786134915_22137%%0001017/07/18 01:24:09 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:24:09 INFO Client: Application report for application_1491786134915_22137 (state: ACCEPTED)%%0001017/07/18 01:24:10 INFO Client: Application report for application_1491786134915_22137 (state: RUNNING)%%0001017/07/18 01:24:10 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312246537%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22137/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:24:10 INFO YarnClientSchedulerBackend: Application application_1491786134915_22137 has started running.%%0001017/07/18 01:24:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43656.%%0001017/07/18 01:24:10 INFO NettyBlockTransferService: Server created on 43656%%0001017/07/18 01:24:10 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:24:10 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:24:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:43656 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 43656)%%0001017/07/18 01:24:10 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:24:11 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22137%%0001017/07/18 01:24:11 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:24:12 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:24:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:24:12 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:24:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:24:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:43656 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:24:12 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:24:12 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:24:12 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:24:12 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:24:12 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:24:12 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:24:12 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:24:12 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:24:12 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:24:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:24:12 INFO MemoryStore: ensureFreeSpace(3979) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:24:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:24:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:43656 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:24:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:24:12 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:24:13 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:24:14 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:24:15 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:44031] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:51237]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:51237] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:51237%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:24:16 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:57507/user/Executor#1024885866]) with ID 1%%0001017/07/18 01:24:16 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:24:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:24:16 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:60994 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 60994)%%0001017/07/18 01:24:16 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:44031] &lt;- [akka.tcp://driverPropsFetcher@hcdnc323:57630]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc323:57630] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc323:57630%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:24:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:60994 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:24:17 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc323:44188/user/Executor#530856310]) with ID 2%%0001017/07/18 01:24:17 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:24:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc323, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:24:17 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc323:51974 with 530.0 MB RAM, BlockManagerId(2, hcdnc323, 51974)%%0001017/07/18 01:24:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:60994 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:24:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc323:51974 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:24:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc323:51974 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:24:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5950 ms on hcdnc310 (1/2)%%0001017/07/18 01:24:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5683 ms on hcdnc323 (2/2)%%0001017/07/18 01:24:23 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.674 s%%0001017/07/18 01:24:23 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:23 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.806650 s%%0001017/07/18 01:24:23 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:24:23 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:24:23 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:24:23 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:24:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:24:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:24:23 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:24:23 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237415, maxMem=556038881%%0001017/07/18 01:24:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:24:23 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246071, maxMem=556038881%%0001017/07/18 01:24:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:24:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:43656 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:24:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:24:23 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:24:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc323, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:24:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:24:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:60994 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:24:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc323:51974 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:24:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5438 ms on hcdnc310 (1/2)%%0001017/07/18 01:24:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5548 ms on hcdnc323 (2/2)%%0001017/07/18 01:24:28 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.550 s%%0001017/07/18 01:24:28 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:28 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:24:28 INFO DAGScheduler: running: Set()%%0001017/07/18 01:24:28 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:24:28 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:24:28 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:24:28 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:24:28 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251378, maxMem=556038881%%0001017/07/18 01:24:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:24:28 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258314, maxMem=556038881%%0001017/07/18 01:24:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:24:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:43656 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:24:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:24:28 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:24:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc323, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:60994 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:24:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc323:51974 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:24:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc323:44188%%0001017/07/18 01:24:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:24:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:57507%%0001017/07/18 01:24:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 440 ms on hcdnc323 (1/2)%%0001017/07/18 01:24:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 452 ms on hcdnc310 (2/2)%%0001017/07/18 01:24:29 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:29 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.453 s%%0001017/07/18 01:24:29 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 6.034034 s%%0001017/07/18 01:24:29 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:24:29 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:24:29 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:24:29 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:24:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:24:29 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:24:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:24:29 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262357, maxMem=556038881%%0001017/07/18 01:24:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:24:29 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268877, maxMem=556038881%%0001017/07/18 01:24:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:43656 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:24:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:24:29 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:24:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:29 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc323, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:60994 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc323:51974 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:24:29 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 691 ms on hcdnc323 (1/2)%%0001017/07/18 01:24:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 718 ms on hcdnc310 (2/2)%%0001017/07/18 01:24:29 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:29 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.719 s%%0001017/07/18 01:24:29 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.732658 s%%0001017/07/18 01:24:29 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:24:29 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:24:29 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:24:29 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:24:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:24:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:24:29 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:24:29 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272779, maxMem=556038881%%0001017/07/18 01:24:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:24:29 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279955, maxMem=556038881%%0001017/07/18 01:24:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:43656 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:24:29 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:24:29 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:24:29 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc323, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:24:29 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:60994 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc323:51974 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 750 ms on hcdnc310 (1/2)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 799 ms on hcdnc323 (2/2)%%0001017/07/18 01:24:30 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:30 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.799 s%%0001017/07/18 01:24:30 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:24:30 INFO DAGScheduler: running: Set()%%0001017/07/18 01:24:30 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:24:30 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:24:30 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:24:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:24:30 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284104, maxMem=556038881%%0001017/07/18 01:24:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:24:30 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286888, maxMem=556038881%%0001017/07/18 01:24:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:43656 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:24:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:24:30 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc323, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc323:51974 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:60994 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc323:44188%%0001017/07/18 01:24:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:24:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:57507%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 44 ms on hcdnc310 (1/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc323, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 48 ms on hcdnc323 (2/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc310 (3/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc323, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc323 (4/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc310 (5/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc323, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc323 (6/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc310 (7/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc323, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc323 (8/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc310 (9/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc323 (10/10)%%0001017/07/18 01:24:30 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:24:30 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:30 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.924754 s%%0001017/07/18 01:24:30 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:24:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:24:30 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:24:30 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:24:30 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:24:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:24:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:24:30 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:24:30 INFO MemoryStore: ensureFreeSpace(12024) called with curMem=288503, maxMem=556038881%%0001017/07/18 01:24:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.7 KB, free 530.0 MB)%%0001017/07/18 01:24:30 INFO MemoryStore: ensureFreeSpace(6599) called with curMem=300527, maxMem=556038881%%0001017/07/18 01:24:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:43656 (size: 6.4 KB, free: 530.2 MB)%%0001017/07/18 01:24:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:24:30 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc323, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:60994 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc323:51974 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:57507%%0001017/07/18 01:24:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc323:44188%%0001017/07/18 01:24:33 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 2795 ms on hcdnc323 (1/2)%%0001017/07/18 01:24:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 2819 ms on hcdnc310 (2/2)%%0001017/07/18 01:24:33 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:33 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 2.820 s%%0001017/07/18 01:24:33 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:24:33 INFO DAGScheduler: running: Set()%%0001017/07/18 01:24:33 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:24:33 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:24:33 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:24:33 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:24:33 INFO MemoryStore: ensureFreeSpace(14904) called with curMem=307126, maxMem=556038881%%0001017/07/18 01:24:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.6 KB, free 530.0 MB)%%0001017/07/18 01:24:33 INFO MemoryStore: ensureFreeSpace(7821) called with curMem=322030, maxMem=556038881%%0001017/07/18 01:24:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:24:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:43656 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:24:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:33 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:24:33 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:24:33 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:33 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc323, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc323:51974 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:24:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:60994 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:24:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:57507%%0001017/07/18 01:24:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 01:24:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc323:44188%%0001017/07/18 01:24:33 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 231 ms on hcdnc310 (1/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc323, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 341 ms on hcdnc323 (2/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 148 ms on hcdnc310 (3/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc323, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 147 ms on hcdnc323 (4/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 123 ms on hcdnc310 (5/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc323, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 135 ms on hcdnc323 (6/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 133 ms on hcdnc310 (7/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc323, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 141 ms on hcdnc323 (8/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 144 ms on hcdnc310 (9/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 152 ms on hcdnc323 (10/10)%%0001017/07/18 01:24:34 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:34 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.914 s%%0001017/07/18 01:24:34 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 3.760064 s%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:24:34 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:24:34 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:24:34 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:24:34 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:24:34 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:24:34 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:24:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:44031] &lt;- [akka.tcp://sparkExecutor@hcdnc310:57507]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:57507] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:57507%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:24:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:44031] &lt;- [akka.tcp://sparkExecutor@hcdnc323:44188]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc323:44188] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc323:44188%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:24:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:24:34 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:24:34 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:24:34 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:24:34 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:24:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:24:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:24:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:24:35 INFO Remoting: Remoting shut down%%0001017/07/18 01:24:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:24:35 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:24:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-48143d2b-7dc1-43d9-82fb-cad1be2acae5%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:24:51 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:24:52 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:24:52 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:24:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:24:53 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:24:53 INFO Remoting: Starting remoting%%0001017/07/18 01:24:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:36486]%%0001017/07/18 01:24:53 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:36486]%%0001017/07/18 01:24:53 INFO Utils: Successfully started service 'sparkDriver' on port 36486.%%0001017/07/18 01:24:53 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:24:53 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:24:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e7705ae6-f92e-4e07-8d81-0247f5c1154a%%0001017/07/18 01:24:53 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:24:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-86ded582-f366-4dcd-b7d6-89ff171f005e/httpd-101832e9-4fee-4984-9252-196ec6069f2e%%0001017/07/18 01:24:53 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:24:53 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:24:53 INFO AbstractConnector: Started SocketConnector@0.0.0.0:45506%%0001017/07/18 01:24:53 INFO Utils: Successfully started service 'HTTP file server' on port 45506.%%0001017/07/18 01:24:53 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:24:53 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:24:53 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:24:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:24:53 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:24:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:24:54 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:24:54 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:24:54 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:24:54 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:24:54 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:24:54 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:24:54 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:24:54 INFO Client: Uploading resource file:/tmp/spark-86ded582-f366-4dcd-b7d6-89ff171f005e/__spark_conf__7897731490790202147.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22138/__spark_conf__7897731490790202147.zip%%0001017/07/18 01:24:55 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:24:55 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:24:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:24:55 INFO Client: Submitting application 22138 to ResourceManager%%0001017/07/18 01:24:55 INFO YarnClientImpl: Submitted application application_1491786134915_22138%%0001017/07/18 01:24:56 INFO Client: Application report for application_1491786134915_22138 (state: ACCEPTED)%%0001017/07/18 01:24:56 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312295065%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22138/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:24:57 INFO Client: Application report for application_1491786134915_22138 (state: ACCEPTED)%%0001017/07/18 01:24:58 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33339/user/YarnAM#-2083037658])%%0001017/07/18 01:24:58 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22138,http://hcnnc117:8088/proxy/application_1491786134915_22138), /proxy/application_1491786134915_22138%%0001017/07/18 01:24:58 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:24:58 INFO Client: Application report for application_1491786134915_22138 (state: ACCEPTED)%%0001017/07/18 01:24:59 INFO Client: Application report for application_1491786134915_22138 (state: RUNNING)%%0001017/07/18 01:24:59 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312295065%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22138/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:24:59 INFO YarnClientSchedulerBackend: Application application_1491786134915_22138 has started running.%%0001017/07/18 01:24:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45135.%%0001017/07/18 01:24:59 INFO NettyBlockTransferService: Server created on 45135%%0001017/07/18 01:24:59 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:24:59 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:24:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:45135 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 45135)%%0001017/07/18 01:24:59 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:25:00 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22138%%0001017/07/18 01:25:00 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:25:01 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:25:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:25:01 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:25:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:25:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:45135 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:25:01 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:25:01 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:25:01 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:25:01 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:25:01 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:25:01 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:25:01 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:25:01 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:25:01 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:25:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:25:01 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:25:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:25:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:45135 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:25:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:25:01 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:25:02 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:25:03 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:25:04 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36486] &lt;- [akka.tcp://driverPropsFetcher@hcdnc316:38824]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc316:38824] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc316:38824%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:25:05 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc316:51414/user/Executor#1459596726]) with ID 1%%0001017/07/18 01:25:05 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:25:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc316, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:25:05 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc316:42608 with 530.0 MB RAM, BlockManagerId(1, hcdnc316, 42608)%%0001017/07/18 01:25:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36486] &lt;- [akka.tcp://driverPropsFetcher@hcdnc340:55123]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc340:55123] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc340:55123%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:25:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc316:42608 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:25:06 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc340:40672/user/Executor#-1068516597]) with ID 2%%0001017/07/18 01:25:06 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:25:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc340, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:25:06 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc340:37950 with 530.0 MB RAM, BlockManagerId(2, hcdnc340, 37950)%%0001017/07/18 01:25:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc340:37950 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:25:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc316:42608 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:25:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc340:37950 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:25:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5794 ms on hcdnc316 (1/2)%%0001017/07/18 01:25:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5415 ms on hcdnc340 (2/2)%%0001017/07/18 01:25:11 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.212 s%%0001017/07/18 01:25:11 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:11 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.332655 s%%0001017/07/18 01:25:11 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:25:11 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:25:11 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:25:11 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:25:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:25:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:25:11 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:25:11 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:25:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:25:11 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:25:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:25:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:45135 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:25:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:25:11 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:25:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc340, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:25:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc316, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:25:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc340:37950 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:25:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc316:42608 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:25:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5191 ms on hcdnc316 (1/2)%%0001017/07/18 01:25:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5433 ms on hcdnc340 (2/2)%%0001017/07/18 01:25:17 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:17 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.433 s%%0001017/07/18 01:25:17 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:25:17 INFO DAGScheduler: running: Set()%%0001017/07/18 01:25:17 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:25:17 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:25:17 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:25:17 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:25:17 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:25:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:25:17 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:25:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:45135 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:25:17 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:25:17 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:25:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc340, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc340:37950 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc316:42608 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:25:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc340:40672%%0001017/07/18 01:25:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:25:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc316:51414%%0001017/07/18 01:25:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 430 ms on hcdnc340 (1/2)%%0001017/07/18 01:25:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 460 ms on hcdnc316 (2/2)%%0001017/07/18 01:25:17 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:17 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.461 s%%0001017/07/18 01:25:17 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.932761 s%%0001017/07/18 01:25:17 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:25:17 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:25:17 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:25:17 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:25:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:25:17 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:25:17 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:25:17 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:25:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:25:17 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:25:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:45135 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:25:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:25:17 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:25:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc340, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:17 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc340:37950 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc316:42608 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:25:18 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 662 ms on hcdnc316 (1/2)%%0001017/07/18 01:25:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 676 ms on hcdnc340 (2/2)%%0001017/07/18 01:25:18 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:18 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.677 s%%0001017/07/18 01:25:18 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.690563 s%%0001017/07/18 01:25:18 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:25:18 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:25:18 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:25:18 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:25:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:25:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:25:18 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:25:18 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:25:18 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:25:18 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:25:18 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:25:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:45135 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:25:18 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:25:18 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:25:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc316, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:25:18 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc340, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:25:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc340:37950 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:25:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc316:42608 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:25:18 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 713 ms on hcdnc340 (1/2)%%0001017/07/18 01:25:18 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 714 ms on hcdnc316 (2/2)%%0001017/07/18 01:25:18 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:18 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.716 s%%0001017/07/18 01:25:18 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:25:18 INFO DAGScheduler: running: Set()%%0001017/07/18 01:25:18 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:25:18 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:25:18 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:25:18 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:25:18 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:25:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:25:18 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:25:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:25:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:45135 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:25:18 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:18 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:25:18 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:25:18 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc316, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc340:37950 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc316:42608 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:25:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc340:40672%%0001017/07/18 01:25:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:25:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc316:51414%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc340, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 43 ms on hcdnc340 (1/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc316, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc316 (2/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc340, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc340 (3/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc316, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc316 (4/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc340, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 16 ms on hcdnc340 (5/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc316, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc316 (6/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc340, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc340 (7/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc316, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc316 (8/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc340 (9/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc316 (10/10)%%0001017/07/18 01:25:19 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 01:25:19 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:19 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.852716 s%%0001017/07/18 01:25:19 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:25:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:25:19 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:25:19 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:25:19 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:25:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:25:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:25:19 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:25:19 INFO MemoryStore: ensureFreeSpace(12024) called with curMem=288500, maxMem=556038881%%0001017/07/18 01:25:19 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.7 KB, free 530.0 MB)%%0001017/07/18 01:25:19 INFO MemoryStore: ensureFreeSpace(6599) called with curMem=300524, maxMem=556038881%%0001017/07/18 01:25:19 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:45135 (size: 6.4 KB, free: 530.2 MB)%%0001017/07/18 01:25:19 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:25:19 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc340, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc316, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc340:37950 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc316:42608 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:25:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc340:40672%%0001017/07/18 01:25:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc316:51414%%0001017/07/18 01:25:21 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 2730 ms on hcdnc316 (1/2)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 2874 ms on hcdnc340 (2/2)%%0001017/07/18 01:25:22 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:22 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 2.875 s%%0001017/07/18 01:25:22 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:25:22 INFO DAGScheduler: running: Set()%%0001017/07/18 01:25:22 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:25:22 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:25:22 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:25:22 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:25:22 INFO MemoryStore: ensureFreeSpace(14904) called with curMem=307123, maxMem=556038881%%0001017/07/18 01:25:22 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.6 KB, free 530.0 MB)%%0001017/07/18 01:25:22 INFO MemoryStore: ensureFreeSpace(7821) called with curMem=322027, maxMem=556038881%%0001017/07/18 01:25:22 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:25:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:45135 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:25:22 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:22 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:25:22 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc340, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc340:37950 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:25:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc316:42608 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:25:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc316:51414%%0001017/07/18 01:25:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 01:25:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc340:40672%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc340, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 249 ms on hcdnc340 (1/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc316, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 252 ms on hcdnc316 (2/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc340, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 135 ms on hcdnc340 (3/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc316, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 163 ms on hcdnc316 (4/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc340, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 132 ms on hcdnc340 (5/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc316, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 129 ms on hcdnc316 (6/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc340, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 104 ms on hcdnc340 (7/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc316, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 133 ms on hcdnc316 (8/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 129 ms on hcdnc340 (9/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 132 ms on hcdnc316 (10/10)%%0001017/07/18 01:25:22 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:22 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.806 s%%0001017/07/18 01:25:22 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 3.708826 s%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:25:22 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:25:22 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:25:22 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:25:22 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:25:22 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:25:22 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:25:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36486] &lt;- [akka.tcp://sparkExecutor@hcdnc316:51414]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc316:51414] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc316:51414%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:25:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36486] &lt;- [akka.tcp://sparkExecutor@hcdnc340:40672]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc340:40672] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc340:40672%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:25:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:25:23 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:25:23 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:25:23 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:25:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:25:23 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:25:23 INFO Remoting: Remoting shut down%%0001017/07/18 01:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:25:24 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:25:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-86ded582-f366-4dcd-b7d6-89ff171f005e%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_1">
<entry key="column_name" type="xstring" value="FailingNodeMessage"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:18:21 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:18:22 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:18:22 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:18:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:18:22 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:18:22 INFO Remoting: Starting remoting%%0001017/07/18 01:18:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37367]%%0001017/07/18 01:18:23 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37367]%%0001017/07/18 01:18:23 INFO Utils: Successfully started service 'sparkDriver' on port 37367.%%0001017/07/18 01:18:23 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:18:23 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:18:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d157f2a4-5bb6-492a-b4a4-c70e2b5d9cf8%%0001017/07/18 01:18:23 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:18:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-166b01c8-01ef-45b5-9828-2937e401ffce/httpd-9d4180f6-2627-4e39-97a5-0230e99549e5%%0001017/07/18 01:18:23 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:18:23 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:18:23 INFO AbstractConnector: Started SocketConnector@0.0.0.0:42112%%0001017/07/18 01:18:23 INFO Utils: Successfully started service 'HTTP file server' on port 42112.%%0001017/07/18 01:18:23 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:18:23 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:18:23 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:18:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:18:23 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:18:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:18:24 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:18:24 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:18:24 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:18:24 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:18:24 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:18:24 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:18:24 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:18:25 INFO Client: Uploading resource file:/tmp/spark-166b01c8-01ef-45b5-9828-2937e401ffce/__spark_conf__2349566215010369748.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22130/__spark_conf__2349566215010369748.zip%%0001017/07/18 01:18:25 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:18:25 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:18:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:18:25 INFO Client: Submitting application 22130 to ResourceManager%%0001017/07/18 01:18:26 INFO YarnClientImpl: Submitted application application_1491786134915_22130%%0001017/07/18 01:18:27 INFO Client: Application report for application_1491786134915_22130 (state: ACCEPTED)%%0001017/07/18 01:18:27 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311905783%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22130/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:18:28 INFO Client: Application report for application_1491786134915_22130 (state: ACCEPTED)%%0001017/07/18 01:18:28 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:53822/user/YarnAM#-817914922])%%0001017/07/18 01:18:28 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22130,http://hcnnc117:8088/proxy/application_1491786134915_22130), /proxy/application_1491786134915_22130%%0001017/07/18 01:18:28 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:18:29 INFO Client: Application report for application_1491786134915_22130 (state: ACCEPTED)%%0001017/07/18 01:18:30 INFO Client: Application report for application_1491786134915_22130 (state: RUNNING)%%0001017/07/18 01:18:30 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311905783%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22130/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:18:30 INFO YarnClientSchedulerBackend: Application application_1491786134915_22130 has started running.%%0001017/07/18 01:18:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39488.%%0001017/07/18 01:18:30 INFO NettyBlockTransferService: Server created on 39488%%0001017/07/18 01:18:30 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:18:30 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:18:30 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:39488 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 39488)%%0001017/07/18 01:18:30 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:18:30 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22130%%0001017/07/18 01:18:30 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:18:30 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:18:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:18:30 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:18:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:18:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:39488 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:18:30 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:18:30 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:18:30 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:18:30 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:18:30 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:18:30 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:18:30 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:18:30 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:18:30 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:18:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:18:30 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:18:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:18:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:39488 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:18:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:18:31 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:18:32 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:18:33 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:18:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37367] &lt;- [akka.tcp://driverPropsFetcher@hcdnc226:33767]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc226:33767] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc226:33767%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:18:34 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc226:33845/user/Executor#-63220186]) with ID 1%%0001017/07/18 01:18:34 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:18:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc226, partition 0,NODE_LOCAL, 2150 bytes)%%0001017/07/18 01:18:35 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc226:59868 with 530.0 MB RAM, BlockManagerId(1, hcdnc226, 59868)%%0001017/07/18 01:18:35 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37367] &lt;- [akka.tcp://driverPropsFetcher@hcdnc240:41342]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc240:41342] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc240:41342%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:18:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc226:59868 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:18:35 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc240:38058/user/Executor#-1496461239]) with ID 2%%0001017/07/18 01:18:35 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:18:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc240, partition 1,NODE_LOCAL, 2150 bytes)%%0001017/07/18 01:18:35 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc240:45519 with 530.0 MB RAM, BlockManagerId(2, hcdnc240, 45519)%%0001017/07/18 01:18:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc226:59868 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:18:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc240:45519 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:18:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc240:45519 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:18:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5899 ms on hcdnc226 (1/2)%%0001017/07/18 01:18:40 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5317 ms on hcdnc240 (2/2)%%0001017/07/18 01:18:40 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 9.819 s%%0001017/07/18 01:18:40 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:40 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 9.942036 s%%0001017/07/18 01:18:40 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:18:40 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:18:40 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:18:40 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:18:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:18:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:18:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:18:40 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:18:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:18:40 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:18:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:18:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:39488 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:18:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:18:40 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:18:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc226, partition 0,NODE_LOCAL, 2139 bytes)%%0001017/07/18 01:18:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc240, partition 1,NODE_LOCAL, 2139 bytes)%%0001017/07/18 01:18:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc226:59868 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:18:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc240:45519 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:18:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5260 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5442 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:46 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:46 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.443 s%%0001017/07/18 01:18:46 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:18:46 INFO DAGScheduler: running: Set()%%0001017/07/18 01:18:46 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:18:46 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:18:46 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:18:46 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:18:46 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:18:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:18:46 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:18:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:39488 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:18:46 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:18:46 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:18:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc240, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc226, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc226:59868 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc240:45519 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:18:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc226:33845%%0001017/07/18 01:18:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:18:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc240:38058%%0001017/07/18 01:18:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 472 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 453 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:46 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:46 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.474 s%%0001017/07/18 01:18:46 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.947371 s%%0001017/07/18 01:18:46 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:18:46 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:18:46 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:18:46 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:18:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:18:46 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:18:46 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:18:46 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:18:46 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:18:46 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:18:46 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:39488 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:18:46 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:18:46 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:18:46 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc240, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:46 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc226, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc240:45519 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:18:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc226:59868 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:18:47 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 665 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:47 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 704 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:47 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:47 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.705 s%%0001017/07/18 01:18:47 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.718407 s%%0001017/07/18 01:18:47 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:18:47 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:18:47 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:18:47 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:18:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:18:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:18:47 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:18:47 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:18:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:18:47 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:18:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:18:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:39488 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:18:47 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:18:47 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:18:47 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc240, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:18:47 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc226, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:18:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc226:59868 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:18:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc240:45519 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 709 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 709 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:48 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:48 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.710 s%%0001017/07/18 01:18:48 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:18:48 INFO DAGScheduler: running: Set()%%0001017/07/18 01:18:48 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:18:48 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:18:48 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:18:48 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:18:48 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:18:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:18:48 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:18:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:39488 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:18:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:48 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:18:48 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc240, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc226, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc240:45519 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc226:59868 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc226:33845%%0001017/07/18 01:18:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:18:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc240:38058%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc240, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc240 (1/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc226, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc226 (2/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc240, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 12 ms on hcdnc240 (3/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc226, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc226 (4/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc240, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 16 ms on hcdnc240 (5/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc226, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 16 ms on hcdnc226 (6/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc226, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc240, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 13 ms on hcdnc226 (7/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 18 ms on hcdnc240 (8/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 10 ms on hcdnc226 (9/10)%%0001017/07/18 01:18:48 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc240 (10/10)%%0001017/07/18 01:18:48 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:48 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.099 s%%0001017/07/18 01:18:48 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.829421 s%%0001017/07/18 01:18:48 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:18:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:18:48 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:18:48 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:18:48 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:18:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:18:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:18:48 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:18:48 INFO MemoryStore: ensureFreeSpace(14160) called with curMem=288498, maxMem=556038881%%0001017/07/18 01:18:48 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.8 KB, free 530.0 MB)%%0001017/07/18 01:18:48 INFO MemoryStore: ensureFreeSpace(7802) called with curMem=302658, maxMem=556038881%%0001017/07/18 01:18:48 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:39488 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:18:48 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:18:48 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc226, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:18:48 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc240, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc240:45519 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc226:59868 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:18:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc240:38058%%0001017/07/18 01:18:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc226:33845%%0001017/07/18 01:18:52 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 4024 ms on hcdnc240 (1/2)%%0001017/07/18 01:18:52 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 4176 ms on hcdnc226 (2/2)%%0001017/07/18 01:18:52 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:52 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 4.177 s%%0001017/07/18 01:18:52 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:18:52 INFO DAGScheduler: running: Set()%%0001017/07/18 01:18:52 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:18:52 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:18:52 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:18:52 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:18:52 INFO MemoryStore: ensureFreeSpace(17512) called with curMem=310460, maxMem=556038881%%0001017/07/18 01:18:52 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.1 KB, free 530.0 MB)%%0001017/07/18 01:18:52 INFO MemoryStore: ensureFreeSpace(9322) called with curMem=327972, maxMem=556038881%%0001017/07/18 01:18:52 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 530.0 MB)%%0001017/07/18 01:18:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:39488 (size: 9.1 KB, free: 530.2 MB)%%0001017/07/18 01:18:52 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:18:52 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:18:52 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:18:52 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc226, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:52 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc240, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc226:59868 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:18:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc240:45519 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:18:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc226:33845%%0001017/07/18 01:18:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 01:18:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc240:38058%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc226, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 348 ms on hcdnc226 (1/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc240, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 354 ms on hcdnc240 (2/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc240, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 182 ms on hcdnc240 (3/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc226, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 225 ms on hcdnc226 (4/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc226, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 158 ms on hcdnc226 (5/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc240, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 201 ms on hcdnc240 (6/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc226, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 160 ms on hcdnc226 (7/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc240, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 200 ms on hcdnc240 (8/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 178 ms on hcdnc226 (9/10)%%0001017/07/18 01:18:53 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 183 ms on hcdnc240 (10/10)%%0001017/07/18 01:18:53 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:18:53 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.118 s%%0001017/07/18 01:18:53 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 5.322727 s%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:18:54 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:18:54 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:18:54 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:18:54 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:18:54 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:18:54 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:18:54 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:18:54 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37367] &lt;- [akka.tcp://sparkExecutor@hcdnc240:38058]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc240:38058] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc240:38058%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:18:54 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37367] &lt;- [akka.tcp://sparkExecutor@hcdnc226:33845]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc226:33845] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc226:33845%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:18:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:18:54 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:18:54 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:18:54 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:18:54 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:18:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:18:54 INFO Remoting: Remoting shut down%%0001017/07/18 01:18:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:18:55 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:18:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-166b01c8-01ef-45b5-9828-2937e401ffce%%00010"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:19:10 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:19:11 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:19:11 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:19:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:19:11 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:19:11 INFO Remoting: Starting remoting%%0001017/07/18 01:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37078]%%0001017/07/18 01:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37078]%%0001017/07/18 01:19:11 INFO Utils: Successfully started service 'sparkDriver' on port 37078.%%0001017/07/18 01:19:11 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:19:11 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:19:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a40a5255-9b97-4c72-b3ee-d69aead542b0%%0001017/07/18 01:19:12 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:19:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-a4d0f18e-8df6-477d-9179-0ce338032683/httpd-744d3d90-5a5d-4ba0-900a-11b0518e21a1%%0001017/07/18 01:19:12 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:19:12 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:19:12 INFO AbstractConnector: Started SocketConnector@0.0.0.0:42535%%0001017/07/18 01:19:12 INFO Utils: Successfully started service 'HTTP file server' on port 42535.%%0001017/07/18 01:19:12 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:19:12 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:19:13 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:19:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:19:13 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:19:13 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:19:13 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:19:13 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:19:13 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:19:13 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:19:13 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:19:13 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:19:13 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:19:14 INFO Client: Uploading resource file:/tmp/spark-a4d0f18e-8df6-477d-9179-0ce338032683/__spark_conf__7136701991496476249.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22131/__spark_conf__7136701991496476249.zip%%0001017/07/18 01:19:14 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:19:14 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:19:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:19:14 INFO Client: Submitting application 22131 to ResourceManager%%0001017/07/18 01:19:14 INFO YarnClientImpl: Submitted application application_1491786134915_22131%%0001017/07/18 01:19:15 INFO Client: Application report for application_1491786134915_22131 (state: ACCEPTED)%%0001017/07/18 01:19:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311954442%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22131/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:19:16 INFO Client: Application report for application_1491786134915_22131 (state: ACCEPTED)%%0001017/07/18 01:19:17 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:34576/user/YarnAM#663296323])%%0001017/07/18 01:19:17 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22131,http://hcnnc117:8088/proxy/application_1491786134915_22131), /proxy/application_1491786134915_22131%%0001017/07/18 01:19:17 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:19:17 INFO Client: Application report for application_1491786134915_22131 (state: RUNNING)%%0001017/07/18 01:19:17 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500311954442%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22131/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:19:17 INFO YarnClientSchedulerBackend: Application application_1491786134915_22131 has started running.%%0001017/07/18 01:19:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38669.%%0001017/07/18 01:19:17 INFO NettyBlockTransferService: Server created on 38669%%0001017/07/18 01:19:17 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:19:17 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:19:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:38669 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 38669)%%0001017/07/18 01:19:17 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:19:18 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22131%%0001017/07/18 01:19:18 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:19:18 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:19:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:19:18 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:19:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:19:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:38669 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:19:18 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:19:18 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:19:18 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:19:18 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:19:18 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:19:18 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:19:18 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:19:18 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:19:18 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:19:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:19:18 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:19:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:19:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:38669 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:19:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:19:18 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:19:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:19:20 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:19:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37078] &lt;- [akka.tcp://driverPropsFetcher@hcdnc333:42341]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc333:42341] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc333:42341%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:19:22 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc333:46754/user/Executor#-2033028249]) with ID 1%%0001017/07/18 01:19:22 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:19:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc333, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:19:22 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc333:52903 with 530.0 MB RAM, BlockManagerId(1, hcdnc333, 52903)%%0001017/07/18 01:19:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc333:52903 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:19:23 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37078] &lt;- [akka.tcp://driverPropsFetcher@hcdnc307:35330]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc307:35330] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc307:35330%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:19:23 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc307:44459/user/Executor#714642931]) with ID 2%%0001017/07/18 01:19:23 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:19:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc307, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:19:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc333:52903 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:19:23 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc307:53568 with 530.0 MB RAM, BlockManagerId(2, hcdnc307, 53568)%%0001017/07/18 01:19:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc307:53568 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:19:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc307:53568 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:19:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5704 ms on hcdnc333 (1/2)%%0001017/07/18 01:19:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5350 ms on hcdnc307 (2/2)%%0001017/07/18 01:19:28 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 9.979 s%%0001017/07/18 01:19:28 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:28 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.105776 s%%0001017/07/18 01:19:28 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:19:28 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:19:28 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:19:28 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:19:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:19:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:19:28 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:19:28 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:19:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:19:28 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:19:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:19:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:38669 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:19:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:19:28 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:19:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc307, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:19:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc333, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:19:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc333:52903 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:19:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc307:53568 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:19:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5322 ms on hcdnc307 (1/2)%%0001017/07/18 01:19:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5511 ms on hcdnc333 (2/2)%%0001017/07/18 01:19:34 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:34 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.514 s%%0001017/07/18 01:19:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:19:34 INFO DAGScheduler: running: Set()%%0001017/07/18 01:19:34 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:19:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:19:34 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:19:34 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:19:34 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:19:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:19:34 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:19:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:38669 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:19:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:19:34 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:19:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc307, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc333, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc333:52903 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc307:53568 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:19:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc307:44459%%0001017/07/18 01:19:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:19:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc333:46754%%0001017/07/18 01:19:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 449 ms on hcdnc307 (1/2)%%0001017/07/18 01:19:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 451 ms on hcdnc333 (2/2)%%0001017/07/18 01:19:34 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:34 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.452 s%%0001017/07/18 01:19:34 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 6.000259 s%%0001017/07/18 01:19:34 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:19:34 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:19:34 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:19:34 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:19:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:19:34 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:19:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:19:34 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:19:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:19:34 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:19:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:38669 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:19:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:19:34 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:19:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc333, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:34 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc333:52903 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:19:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc307:53568 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:19:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 711 ms on hcdnc333 (1/2)%%0001017/07/18 01:19:35 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 752 ms on hcdnc307 (2/2)%%0001017/07/18 01:19:35 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:35 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.753 s%%0001017/07/18 01:19:35 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.767834 s%%0001017/07/18 01:19:35 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:19:35 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:19:35 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:19:35 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:19:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:19:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:19:35 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:19:35 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:19:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:19:35 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:19:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:19:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:38669 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:19:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:19:35 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:19:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc307, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:19:35 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc333, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:19:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc307:53568 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:19:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc333:52903 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 734 ms on hcdnc307 (1/2)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 752 ms on hcdnc333 (2/2)%%0001017/07/18 01:19:36 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:36 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.753 s%%0001017/07/18 01:19:36 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:19:36 INFO DAGScheduler: running: Set()%%0001017/07/18 01:19:36 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:19:36 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:19:36 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:19:36 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:19:36 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:19:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:19:36 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:19:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:38669 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:19:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:36 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:19:36 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc333, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc333:52903 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc307:53568 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc333:46754%%0001017/07/18 01:19:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:19:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc307:44459%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc333, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc333 (1/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc307, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc307 (2/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc333, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc333 (3/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc307, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc307 (4/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc333, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 16 ms on hcdnc333 (5/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc307, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 21 ms on hcdnc307 (6/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc333, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc333 (7/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc307, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc307 (8/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc333 (9/10)%%0001017/07/18 01:19:36 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc307 (10/10)%%0001017/07/18 01:19:36 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:36 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.107 s%%0001017/07/18 01:19:36 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.883410 s%%0001017/07/18 01:19:36 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:19:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:19:36 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:19:36 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:19:36 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:19:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:19:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:19:36 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:19:36 INFO MemoryStore: ensureFreeSpace(14160) called with curMem=288498, maxMem=556038881%%0001017/07/18 01:19:36 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.8 KB, free 530.0 MB)%%0001017/07/18 01:19:36 INFO MemoryStore: ensureFreeSpace(7802) called with curMem=302658, maxMem=556038881%%0001017/07/18 01:19:36 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:38669 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:19:36 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:19:36 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc333, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:19:36 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc307, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc307:53568 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc333:52903 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:19:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc307:44459%%0001017/07/18 01:19:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc333:46754%%0001017/07/18 01:19:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 4244 ms on hcdnc333 (1/2)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 4350 ms on hcdnc307 (2/2)%%0001017/07/18 01:19:41 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:41 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 4.351 s%%0001017/07/18 01:19:41 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:19:41 INFO DAGScheduler: running: Set()%%0001017/07/18 01:19:41 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:19:41 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:19:41 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:19:41 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:19:41 INFO MemoryStore: ensureFreeSpace(17512) called with curMem=310460, maxMem=556038881%%0001017/07/18 01:19:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.1 KB, free 530.0 MB)%%0001017/07/18 01:19:41 INFO MemoryStore: ensureFreeSpace(9322) called with curMem=327972, maxMem=556038881%%0001017/07/18 01:19:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 530.0 MB)%%0001017/07/18 01:19:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:38669 (size: 9.1 KB, free: 530.2 MB)%%0001017/07/18 01:19:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:19:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:19:41 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc333, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc307, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc307:53568 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:19:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc333:52903 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:19:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc307:44459%%0001017/07/18 01:19:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 01:19:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc333:46754%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc307, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 332 ms on hcdnc307 (1/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc333, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 336 ms on hcdnc333 (2/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc333, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 171 ms on hcdnc333 (3/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc307, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 222 ms on hcdnc307 (4/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc333, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 155 ms on hcdnc333 (5/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc307, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 194 ms on hcdnc307 (6/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc333, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 160 ms on hcdnc333 (7/10)%%0001017/07/18 01:19:41 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc307, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:19:41 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 181 ms on hcdnc307 (8/10)%%0001017/07/18 01:19:42 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 181 ms on hcdnc333 (9/10)%%0001017/07/18 01:19:42 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 189 ms on hcdnc307 (10/10)%%0001017/07/18 01:19:42 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:19:42 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.118 s%%0001017/07/18 01:19:42 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 5.499536 s%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:19:42 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:19:42 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:19:42 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:19:42 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:19:42 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:19:42 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:19:42 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:19:42 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37078] &lt;- [akka.tcp://sparkExecutor@hcdnc333:46754]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc333:46754] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc333:46754%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:19:42 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37078] &lt;- [akka.tcp://sparkExecutor@hcdnc307:44459]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc307:44459] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc307:44459%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:19:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:19:42 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:19:42 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:19:42 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:19:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:19:42 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:19:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:19:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:19:43 INFO Remoting: Remoting shut down%%0001017/07/18 01:19:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:19:43 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:19:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-a4d0f18e-8df6-477d-9179-0ce338032683%%00010"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:19:59 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:19:59 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:19:59 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:19:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:20:00 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:20:00 INFO Remoting: Starting remoting%%0001017/07/18 01:20:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:41779]%%0001017/07/18 01:20:00 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:41779]%%0001017/07/18 01:20:00 INFO Utils: Successfully started service 'sparkDriver' on port 41779.%%0001017/07/18 01:20:00 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:20:00 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:20:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b3a5064-a0d7-40d0-b0af-01ae6af706c2%%0001017/07/18 01:20:00 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:20:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3eda37af-a4e4-484e-b4c2-56c53115b140/httpd-c5bbefb0-7bdc-45d8-8c99-fb8fc9320720%%0001017/07/18 01:20:01 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:20:01 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:20:01 INFO AbstractConnector: Started SocketConnector@0.0.0.0:44915%%0001017/07/18 01:20:01 INFO Utils: Successfully started service 'HTTP file server' on port 44915.%%0001017/07/18 01:20:01 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:20:01 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:20:01 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:20:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:20:01 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:20:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:20:01 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:20:01 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:20:01 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:20:01 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:20:01 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:20:01 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:20:01 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:20:02 INFO Client: Uploading resource file:/tmp/spark-3eda37af-a4e4-484e-b4c2-56c53115b140/__spark_conf__3325903943632158223.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22132/__spark_conf__3325903943632158223.zip%%0001017/07/18 01:20:02 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:20:02 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:20:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:20:02 INFO Client: Submitting application 22132 to ResourceManager%%0001017/07/18 01:20:03 INFO YarnClientImpl: Submitted application application_1491786134915_22132%%0001017/07/18 01:20:04 INFO Client: Application report for application_1491786134915_22132 (state: ACCEPTED)%%0001017/07/18 01:20:04 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312003009%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22132/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:20:05 INFO Client: Application report for application_1491786134915_22132 (state: ACCEPTED)%%0001017/07/18 01:20:06 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:57905/user/YarnAM#1241885629])%%0001017/07/18 01:20:06 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22132,http://hcnnc117:8088/proxy/application_1491786134915_22132), /proxy/application_1491786134915_22132%%0001017/07/18 01:20:06 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:20:06 INFO Client: Application report for application_1491786134915_22132 (state: RUNNING)%%0001017/07/18 01:20:06 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312003009%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22132/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:20:06 INFO YarnClientSchedulerBackend: Application application_1491786134915_22132 has started running.%%0001017/07/18 01:20:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33620.%%0001017/07/18 01:20:06 INFO NettyBlockTransferService: Server created on 33620%%0001017/07/18 01:20:06 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:20:06 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:20:06 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:33620 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 33620)%%0001017/07/18 01:20:06 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:20:06 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22132%%0001017/07/18 01:20:06 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:20:06 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:20:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:20:07 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:20:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:20:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:33620 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:20:07 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:20:07 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:20:07 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:20:07 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:20:07 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:20:07 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:20:07 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:20:07 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:20:07 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:20:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:20:07 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:20:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:20:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:33620 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:20:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:20:07 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:20:08 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:20:09 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:20:10 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41779] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:44913]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:44913] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:44913%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:20:11 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:37069/user/Executor#664190157]) with ID 1%%0001017/07/18 01:20:11 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:20:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc304, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:20:11 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:41229 with 530.0 MB RAM, BlockManagerId(1, hcdnc304, 41229)%%0001017/07/18 01:20:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:41229 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:20:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41779] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:46389]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:46389] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:46389%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:20:11 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:35377/user/Executor#-1947656875]) with ID 2%%0001017/07/18 01:20:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,NODE_LOCAL, 2150 bytes)%%0001017/07/18 01:20:11 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:20:11 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:40782 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 40782)%%0001017/07/18 01:20:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:41229 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:20:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:40782 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:20:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:40782 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:20:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5619 ms on hcdnc304 (1/2)%%0001017/07/18 01:20:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5782 ms on hcdnc310 (2/2)%%0001017/07/18 01:20:17 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.360 s%%0001017/07/18 01:20:17 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:17 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.484887 s%%0001017/07/18 01:20:17 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:20:17 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:20:17 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:20:17 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:20:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:20:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:20:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:20:17 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:20:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:20:17 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:20:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:20:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:33620 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:20:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:20:17 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:20:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc310, partition 0,NODE_LOCAL, 2139 bytes)%%0001017/07/18 01:20:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:40782 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:20:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:20:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc304, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:20:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:41229 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:20:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5581 ms on hcdnc310 (1/2)%%0001017/07/18 01:20:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5251 ms on hcdnc304 (2/2)%%0001017/07/18 01:20:26 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:26 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 8.758 s%%0001017/07/18 01:20:26 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:20:26 INFO DAGScheduler: running: Set()%%0001017/07/18 01:20:26 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:20:26 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:20:26 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:20:26 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:20:26 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:20:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:20:26 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:20:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:20:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:33620 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:20:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:20:26 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:20:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:41229 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:20:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:40782 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:20:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:37069%%0001017/07/18 01:20:26 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:20:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:35377%%0001017/07/18 01:20:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 435 ms on hcdnc304 (1/2)%%0001017/07/18 01:20:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 491 ms on hcdnc310 (2/2)%%0001017/07/18 01:20:26 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:26 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.493 s%%0001017/07/18 01:20:26 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 9.282114 s%%0001017/07/18 01:20:27 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:20:27 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:20:27 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:20:27 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:20:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:20:27 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:20:27 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:20:27 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:20:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:20:27 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:20:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:33620 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:20:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:20:27 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:20:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:27 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:41229 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:40782 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:20:27 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 714 ms on hcdnc310 (1/2)%%0001017/07/18 01:20:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 747 ms on hcdnc304 (2/2)%%0001017/07/18 01:20:27 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:27 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.749 s%%0001017/07/18 01:20:27 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.760965 s%%0001017/07/18 01:20:27 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:20:27 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:20:27 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:20:27 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:20:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:20:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:20:27 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:20:27 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:20:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:20:27 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:20:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:33620 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:20:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:20:27 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:20:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc304, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:20:27 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:41229 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:20:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:40782 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 705 ms on hcdnc304 (1/2)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 779 ms on hcdnc310 (2/2)%%0001017/07/18 01:20:28 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:28 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.780 s%%0001017/07/18 01:20:28 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:20:28 INFO DAGScheduler: running: Set()%%0001017/07/18 01:20:28 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:20:28 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:20:28 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:20:28 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:20:28 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:20:28 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:20:28 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:20:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:33620 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 01:20:28 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:28 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:20:28 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:40782 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:41229 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:35377%%0001017/07/18 01:20:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:20:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:37069%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 41 ms on hcdnc310 (1/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 51 ms on hcdnc304 (2/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc310 (3/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc304, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 13 ms on hcdnc304 (4/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc310 (5/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 16 ms on hcdnc304 (6/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc310 (7/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc304 (8/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc310 (9/10)%%0001017/07/18 01:20:28 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc304 (10/10)%%0001017/07/18 01:20:28 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:28 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 01:20:28 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.902961 s%%0001017/07/18 01:20:28 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:20:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:20:28 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:20:28 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:20:28 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:20:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:20:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:20:28 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:20:28 INFO MemoryStore: ensureFreeSpace(14160) called with curMem=288498, maxMem=556038881%%0001017/07/18 01:20:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.8 KB, free 530.0 MB)%%0001017/07/18 01:20:28 INFO MemoryStore: ensureFreeSpace(7802) called with curMem=302658, maxMem=556038881%%0001017/07/18 01:20:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:33620 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:20:28 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:20:28 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:20:28 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:40782 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:41229 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:20:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:35377%%0001017/07/18 01:20:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:37069%%0001017/07/18 01:20:32 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 3999 ms on hcdnc304 (1/2)%%0001017/07/18 01:20:32 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 4091 ms on hcdnc310 (2/2)%%0001017/07/18 01:20:32 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 4.091 s%%0001017/07/18 01:20:32 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:32 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:20:32 INFO DAGScheduler: running: Set()%%0001017/07/18 01:20:32 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:20:32 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:20:32 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:20:32 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:20:32 INFO MemoryStore: ensureFreeSpace(17512) called with curMem=310460, maxMem=556038881%%0001017/07/18 01:20:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.1 KB, free 530.0 MB)%%0001017/07/18 01:20:32 INFO MemoryStore: ensureFreeSpace(9322) called with curMem=327972, maxMem=556038881%%0001017/07/18 01:20:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 530.0 MB)%%0001017/07/18 01:20:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:33620 (size: 9.1 KB, free: 530.2 MB)%%0001017/07/18 01:20:32 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:32 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:20:32 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:20:32 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:32 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:40782 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:20:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:41229 (size: 9.1 KB, free: 529.9 MB)%%0001017/07/18 01:20:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:35377%%0001017/07/18 01:20:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 01:20:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:37069%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 309 ms on hcdnc304 (1/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 329 ms on hcdnc310 (2/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 181 ms on hcdnc304 (3/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 218 ms on hcdnc310 (4/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 163 ms on hcdnc304 (5/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 167 ms on hcdnc310 (6/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 189 ms on hcdnc304 (7/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 177 ms on hcdnc310 (8/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 187 ms on hcdnc304 (9/10)%%0001017/07/18 01:20:33 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 162 ms on hcdnc310 (10/10)%%0001017/07/18 01:20:33 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:20:33 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.049 s%%0001017/07/18 01:20:33 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 5.165355 s%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:20:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:20:34 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:20:34 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:20:34 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:20:34 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:20:34 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:20:34 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:20:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41779] &lt;- [akka.tcp://sparkExecutor@hcdnc310:35377]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:35377] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:35377%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:20:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:41779] &lt;- [akka.tcp://sparkExecutor@hcdnc304:37069]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:37069] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:37069%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:20:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:20:34 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:20:34 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:20:34 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:20:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:20:34 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:20:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:20:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:20:34 INFO Remoting: Remoting shut down%%0001017/07/18 01:20:34 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:20:35 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:20:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-3eda37af-a4e4-484e-b4c2-56c53115b140/pyspark-90913d2c-e2a8-45a7-80f5-de2424b90e9e%%0001017/07/18 01:20:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-3eda37af-a4e4-484e-b4c2-56c53115b140%%00010"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:20:49 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:20:50 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:20:50 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:20:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:20:51 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:20:51 INFO Remoting: Starting remoting%%0001017/07/18 01:20:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38439]%%0001017/07/18 01:20:51 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38439]%%0001017/07/18 01:20:51 INFO Utils: Successfully started service 'sparkDriver' on port 38439.%%0001017/07/18 01:20:51 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:20:51 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:20:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a2b1b3dc-72b9-4d4c-8d66-7bb0c8f6ba50%%0001017/07/18 01:20:51 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:20:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-14ed47ee-6376-4583-ad1b-9b22839d8a0c/httpd-22a2206e-12fb-49ae-b7e1-0ea3480529dc%%0001017/07/18 01:20:51 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:20:51 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:20:51 INFO AbstractConnector: Started SocketConnector@0.0.0.0:35314%%0001017/07/18 01:20:51 INFO Utils: Successfully started service 'HTTP file server' on port 35314.%%0001017/07/18 01:20:51 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:20:52 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:20:52 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:20:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:20:52 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:20:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:20:52 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:20:52 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:20:52 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:20:52 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:20:52 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:20:52 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:20:52 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:20:52 INFO Client: Uploading resource file:/tmp/spark-14ed47ee-6376-4583-ad1b-9b22839d8a0c/__spark_conf__1113759508732526743.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22133/__spark_conf__1113759508732526743.zip%%0001017/07/18 01:20:53 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:20:53 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:20:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:20:53 INFO Client: Submitting application 22133 to ResourceManager%%0001017/07/18 01:20:53 INFO YarnClientImpl: Submitted application application_1491786134915_22133%%0001017/07/18 01:20:54 INFO Client: Application report for application_1491786134915_22133 (state: ACCEPTED)%%0001017/07/18 01:20:54 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312053389%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22133/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:20:55 INFO Client: Application report for application_1491786134915_22133 (state: ACCEPTED)%%0001017/07/18 01:20:56 INFO Client: Application report for application_1491786134915_22133 (state: ACCEPTED)%%0001017/07/18 01:20:56 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:53212/user/YarnAM#1392167049])%%0001017/07/18 01:20:56 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22133,http://hcnnc117:8088/proxy/application_1491786134915_22133), /proxy/application_1491786134915_22133%%0001017/07/18 01:20:56 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:20:57 INFO Client: Application report for application_1491786134915_22133 (state: RUNNING)%%0001017/07/18 01:20:57 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312053389%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22133/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:20:57 INFO YarnClientSchedulerBackend: Application application_1491786134915_22133 has started running.%%0001017/07/18 01:20:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38762.%%0001017/07/18 01:20:57 INFO NettyBlockTransferService: Server created on 38762%%0001017/07/18 01:20:57 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:20:57 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:20:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:38762 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 38762)%%0001017/07/18 01:20:57 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:20:58 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22133%%0001017/07/18 01:20:58 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:20:59 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:20:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:20:59 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:20:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:20:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:38762 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:20:59 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:20:59 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:20:59 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:20:59 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:20:59 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:20:59 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:20:59 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:20:59 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:20:59 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:20:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:20:59 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:20:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:20:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:38762 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:20:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:20:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:20:59 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:21:00 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:21:01 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:21:03 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38439] &lt;- [akka.tcp://driverPropsFetcher@hcdnc823:56136]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:56136] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:56136%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:03 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc823:36870/user/Executor#73418100]) with ID 1%%0001017/07/18 01:21:03 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:21:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc823, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:21:03 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc823:35364 with 530.0 MB RAM, BlockManagerId(1, hcdnc823, 35364)%%0001017/07/18 01:21:03 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38439] &lt;- [akka.tcp://driverPropsFetcher@hcdnc822:38629]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc822:38629] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc822:38629%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc823:35364 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:04 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc822:50981/user/Executor#1866875818]) with ID 2%%0001017/07/18 01:21:04 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:21:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc822, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:21:04 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc822:54085 with 530.0 MB RAM, BlockManagerId(2, hcdnc822, 54085)%%0001017/07/18 01:21:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc823:35364 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc822:54085 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc822:54085 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5600 ms on hcdnc823 (1/2)%%0001017/07/18 01:21:09 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5322 ms on hcdnc822 (2/2)%%0001017/07/18 01:21:09 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 9.912 s%%0001017/07/18 01:21:09 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:09 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.035407 s%%0001017/07/18 01:21:09 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:21:09 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:21:09 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:21:09 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:21:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:21:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:21:09 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:21:09 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:21:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:21:09 INFO MemoryStore: ensureFreeSpace(5306) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:21:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:21:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:38762 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:21:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:21:09 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:21:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc822, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:21:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc823, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:21:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc822:54085 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:21:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc823:35364 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:21:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5340 ms on hcdnc822 (1/2)%%0001017/07/18 01:21:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5446 ms on hcdnc823 (2/2)%%0001017/07/18 01:21:15 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.448 s%%0001017/07/18 01:21:15 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:15 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:21:15 INFO DAGScheduler: running: Set()%%0001017/07/18 01:21:15 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:21:15 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:21:15 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:21:15 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:21:15 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251374, maxMem=556038881%%0001017/07/18 01:21:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:21:15 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258310, maxMem=556038881%%0001017/07/18 01:21:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:38762 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:21:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:21:15 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:21:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc822, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc822:54085 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc823:35364 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc822:50981%%0001017/07/18 01:21:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:21:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:36870%%0001017/07/18 01:21:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 436 ms on hcdnc822 (1/2)%%0001017/07/18 01:21:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 494 ms on hcdnc823 (2/2)%%0001017/07/18 01:21:15 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.495 s%%0001017/07/18 01:21:15 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:15 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.974024 s%%0001017/07/18 01:21:15 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:21:15 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:21:15 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:21:15 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:21:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:21:15 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:21:15 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:21:15 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262353, maxMem=556038881%%0001017/07/18 01:21:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:21:15 INFO MemoryStore: ensureFreeSpace(3901) called with curMem=268873, maxMem=556038881%%0001017/07/18 01:21:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:38762 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:21:15 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:21:15 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:21:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:15 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc822, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc823:35364 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:21:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc822:54085 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:21:16 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 654 ms on hcdnc822 (1/2)%%0001017/07/18 01:21:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 707 ms on hcdnc823 (2/2)%%0001017/07/18 01:21:16 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.708 s%%0001017/07/18 01:21:16 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:16 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.721044 s%%0001017/07/18 01:21:16 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:21:16 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:21:16 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:21:16 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:21:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:21:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:21:16 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:21:16 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272774, maxMem=556038881%%0001017/07/18 01:21:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:21:16 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279950, maxMem=556038881%%0001017/07/18 01:21:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:21:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:38762 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:21:16 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:21:16 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:21:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc823, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:21:16 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc822, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:21:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc822:54085 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:21:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc823:35364 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 695 ms on hcdnc822 (1/2)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 769 ms on hcdnc823 (2/2)%%0001017/07/18 01:21:17 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:17 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.770 s%%0001017/07/18 01:21:17 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:21:17 INFO DAGScheduler: running: Set()%%0001017/07/18 01:21:17 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:21:17 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:21:17 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:21:17 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:21:17 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284099, maxMem=556038881%%0001017/07/18 01:21:17 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:21:17 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286883, maxMem=556038881%%0001017/07/18 01:21:17 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:38762 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:21:17 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:17 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:21:17 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc822, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc823, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc822:54085 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc823:35364 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc822:50981%%0001017/07/18 01:21:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 164 bytes%%0001017/07/18 01:21:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc823:36870%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc822, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 42 ms on hcdnc822 (1/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc823, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 48 ms on hcdnc823 (2/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc822, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc822 (3/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc823 (4/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc822, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc822 (5/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc823 (6/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc822, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc822 (7/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 13 ms on hcdnc823 (8/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc822 (9/10)%%0001017/07/18 01:21:17 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc823 (10/10)%%0001017/07/18 01:21:17 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 01:21:17 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:17 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.894061 s%%0001017/07/18 01:21:17 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:21:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:21:17 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:21:17 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:21:17 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:21:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:21:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:21:17 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:21:17 INFO MemoryStore: ensureFreeSpace(12992) called with curMem=288498, maxMem=556038881%%0001017/07/18 01:21:17 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:21:17 INFO MemoryStore: ensureFreeSpace(7138) called with curMem=301490, maxMem=556038881%%0001017/07/18 01:21:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:38762 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:21:17 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:21:17 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc822, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:21:17 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc823, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc822:54085 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc823:35364 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:21:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:36870%%0001017/07/18 01:21:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc822:50981%%0001017/07/18 01:21:20 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 3533 ms on hcdnc823 (1/2)%%0001017/07/18 01:21:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 3717 ms on hcdnc822 (2/2)%%0001017/07/18 01:21:20 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:20 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 3.718 s%%0001017/07/18 01:21:20 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:21:20 INFO DAGScheduler: running: Set()%%0001017/07/18 01:21:20 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:21:20 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:21:20 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:21:20 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:21:21 INFO MemoryStore: ensureFreeSpace(16080) called with curMem=308628, maxMem=556038881%%0001017/07/18 01:21:21 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:21:21 INFO MemoryStore: ensureFreeSpace(8494) called with curMem=324708, maxMem=556038881%%0001017/07/18 01:21:21 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:21:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:38762 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:21:21 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:21 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:21:21 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc822, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc822:54085 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc823:35364 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc822:50981%%0001017/07/18 01:21:21 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 162 bytes%%0001017/07/18 01:21:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc823:36870%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc823, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 312 ms on hcdnc823 (1/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc822, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 315 ms on hcdnc822 (2/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc822, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 173 ms on hcdnc822 (3/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 204 ms on hcdnc823 (4/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc822, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 160 ms on hcdnc822 (5/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 163 ms on hcdnc823 (6/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc822, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 169 ms on hcdnc822 (7/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 176 ms on hcdnc823 (8/10)%%0001017/07/18 01:21:21 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 163 ms on hcdnc822 (9/10)%%0001017/07/18 01:21:22 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 174 ms on hcdnc823 (10/10)%%0001017/07/18 01:21:22 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:22 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.027 s%%0001017/07/18 01:21:22 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 4.771325 s%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:21:22 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:21:22 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:21:22 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:21:22 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:21:22 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:21:22 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:21:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38439] &lt;- [akka.tcp://sparkExecutor@hcdnc822:50981]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc822:50981] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc822:50981%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38439] &lt;- [akka.tcp://sparkExecutor@hcdnc823:36870]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc823:36870] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc823:36870%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:21:22 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:21:22 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:21:22 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:21:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:21:22 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:21:22 INFO Remoting: Remoting shut down%%0001017/07/18 01:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:21:23 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:21:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-14ed47ee-6376-4583-ad1b-9b22839d8a0c/pyspark-9fa4a827-cea3-4e50-bfa8-1838978f3b8b%%0001017/07/18 01:21:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-14ed47ee-6376-4583-ad1b-9b22839d8a0c%%00010"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:21:37 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:21:38 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:21:38 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:21:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:21:38 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:21:38 INFO Remoting: Starting remoting%%0001017/07/18 01:21:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:36018]%%0001017/07/18 01:21:39 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:36018]%%0001017/07/18 01:21:39 INFO Utils: Successfully started service 'sparkDriver' on port 36018.%%0001017/07/18 01:21:40 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:21:40 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:21:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-906a5a97-e098-476d-a456-a353a6655433%%0001017/07/18 01:21:40 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:21:40 INFO HttpFileServer: HTTP File server directory is /tmp/spark-066e657a-3fcb-4f41-b470-47f295f12ba8/httpd-39796388-9652-4876-8d3f-66474db1c1ee%%0001017/07/18 01:21:40 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:21:40 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:21:40 INFO AbstractConnector: Started SocketConnector@0.0.0.0:34506%%0001017/07/18 01:21:40 INFO Utils: Successfully started service 'HTTP file server' on port 34506.%%0001017/07/18 01:21:40 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:21:40 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:21:40 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:21:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:21:40 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:21:40 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:21:40 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:21:40 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:21:40 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:21:40 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:21:40 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:21:40 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:21:40 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:21:41 INFO Client: Uploading resource file:/tmp/spark-066e657a-3fcb-4f41-b470-47f295f12ba8/__spark_conf__7263393439660899890.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22134/__spark_conf__7263393439660899890.zip%%0001017/07/18 01:21:41 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:21:41 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:21:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:21:41 INFO Client: Submitting application 22134 to ResourceManager%%0001017/07/18 01:21:42 INFO YarnClientImpl: Submitted application application_1491786134915_22134%%0001017/07/18 01:21:43 INFO Client: Application report for application_1491786134915_22134 (state: ACCEPTED)%%0001017/07/18 01:21:43 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312101839%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22134/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:21:44 INFO Client: Application report for application_1491786134915_22134 (state: ACCEPTED)%%0001017/07/18 01:21:45 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.39:47283/user/YarnAM#-212673071])%%0001017/07/18 01:21:45 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22134,http://hcnnc117:8088/proxy/application_1491786134915_22134), /proxy/application_1491786134915_22134%%0001017/07/18 01:21:45 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:21:45 INFO Client: Application report for application_1491786134915_22134 (state: ACCEPTED)%%0001017/07/18 01:21:46 INFO Client: Application report for application_1491786134915_22134 (state: RUNNING)%%0001017/07/18 01:21:46 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.39%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312101839%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22134/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:21:46 INFO YarnClientSchedulerBackend: Application application_1491786134915_22134 has started running.%%0001017/07/18 01:21:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43067.%%0001017/07/18 01:21:46 INFO NettyBlockTransferService: Server created on 43067%%0001017/07/18 01:21:46 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:21:46 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:21:46 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:43067 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 43067)%%0001017/07/18 01:21:46 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:21:46 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22134%%0001017/07/18 01:21:46 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:21:46 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:21:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:21:46 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:21:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:21:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:43067 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:21:46 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:21:47 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:21:47 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:21:47 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:21:47 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:21:47 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:21:47 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:21:47 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:21:47 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:21:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:21:47 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:21:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:21:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:43067 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:21:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:21:47 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:21:48 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:21:49 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:21:50 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36018] &lt;- [akka.tcp://driverPropsFetcher@hcdnc340:37771]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc340:37771] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc340:37771%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:51 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc340:39290/user/Executor#-1098327346]) with ID 1%%0001017/07/18 01:21:51 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:21:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc340, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:21:51 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc340:38811 with 530.0 MB RAM, BlockManagerId(1, hcdnc340, 38811)%%0001017/07/18 01:21:51 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36018] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:56776]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:56776] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:56776%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:21:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc340:38811 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:51 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:50944/user/Executor#648366636]) with ID 2%%0001017/07/18 01:21:51 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:21:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:21:51 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:54641 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 54641)%%0001017/07/18 01:21:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc340:38811 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:54641 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:21:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:54641 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:21:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5577 ms on hcdnc340 (1/2)%%0001017/07/18 01:21:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5482 ms on hcdnc310 (2/2)%%0001017/07/18 01:21:57 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.016 s%%0001017/07/18 01:21:57 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:21:57 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.139969 s%%0001017/07/18 01:21:57 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:21:57 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:21:57 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:21:57 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:21:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:21:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:21:57 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:21:57 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:21:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:21:57 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:21:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:21:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:43067 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:21:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:21:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:21:57 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:21:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc340, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:21:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:21:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:54641 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:21:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc340:38811 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:22:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5234 ms on hcdnc310 (1/2)%%0001017/07/18 01:22:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5629 ms on hcdnc340 (2/2)%%0001017/07/18 01:22:02 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.631 s%%0001017/07/18 01:22:02 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:02 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:02 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:02 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:22:02 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:02 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:22:02 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:22:02 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:22:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:22:02 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:22:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:22:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:43067 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:22:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:22:02 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:22:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc340:38811 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:54641 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc340:39290%%0001017/07/18 01:22:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:22:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:50944%%0001017/07/18 01:22:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 439 ms on hcdnc340 (1/2)%%0001017/07/18 01:22:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 443 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:03 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:03 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.443 s%%0001017/07/18 01:22:03 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 6.105119 s%%0001017/07/18 01:22:03 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:22:03 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:22:03 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:22:03 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:22:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:22:03 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:22:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:22:03 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:22:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:22:03 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:22:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:22:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:43067 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:22:03 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:22:03 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:22:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:03 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:54641 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:22:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc340:38811 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 680 ms on hcdnc340 (1/2)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 694 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:04 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.694 s%%0001017/07/18 01:22:04 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:04 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.707512 s%%0001017/07/18 01:22:04 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:22:04 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:22:04 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:22:04 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:22:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:22:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:22:04 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:22:04 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:22:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:22:04 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:22:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:43067 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:22:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:22:04 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc340, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc340:38811 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:54641 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 726 ms on hcdnc310 (1/2)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 750 ms on hcdnc340 (2/2)%%0001017/07/18 01:22:04 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:04 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.751 s%%0001017/07/18 01:22:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:04 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:04 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:22:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:04 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:22:04 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:22:04 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:22:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:22:04 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:22:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:43067 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:22:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:22:04 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc340:38811 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:54641 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:22:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc340:39290%%0001017/07/18 01:22:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 164 bytes%%0001017/07/18 01:22:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:50944%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc340, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 48 ms on hcdnc340 (1/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 54 ms on hcdnc310 (2/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc340, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 18 ms on hcdnc340 (3/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 19 ms on hcdnc310 (4/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc340, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc340 (5/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc310 (6/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc340, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc340 (7/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc310 (8/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc340 (9/10)%%0001017/07/18 01:22:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc310 (10/10)%%0001017/07/18 01:22:04 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.115 s%%0001017/07/18 01:22:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:04 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.885969 s%%0001017/07/18 01:22:05 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:22:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 01:22:05 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:22:05 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:22:05 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:22:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:22:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:22:05 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:22:05 INFO MemoryStore: ensureFreeSpace(12992) called with curMem=288500, maxMem=556038881%%0001017/07/18 01:22:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:22:05 INFO MemoryStore: ensureFreeSpace(7138) called with curMem=301492, maxMem=556038881%%0001017/07/18 01:22:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:22:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:43067 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:22:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:22:05 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:22:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc340, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:05 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc340:38811 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:22:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:54641 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:22:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc340:39290%%0001017/07/18 01:22:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:50944%%0001017/07/18 01:22:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 3582 ms on hcdnc340 (1/2)%%0001017/07/18 01:22:08 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 3583 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:08 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:08 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 3.584 s%%0001017/07/18 01:22:08 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:08 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:08 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:22:08 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:08 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:22:08 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:22:08 INFO MemoryStore: ensureFreeSpace(16080) called with curMem=308630, maxMem=556038881%%0001017/07/18 01:22:08 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:22:08 INFO MemoryStore: ensureFreeSpace(8494) called with curMem=324710, maxMem=556038881%%0001017/07/18 01:22:08 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:22:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:43067 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:22:08 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:08 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:22:08 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:22:08 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:08 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:54641 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc340:38811 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:50944%%0001017/07/18 01:22:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 162 bytes%%0001017/07/18 01:22:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc340:39290%%0001017/07/18 01:22:08 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:08 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 278 ms on hcdnc310 (1/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc340, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 328 ms on hcdnc340 (2/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 198 ms on hcdnc310 (3/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc340, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 185 ms on hcdnc340 (4/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 155 ms on hcdnc310 (5/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc340, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 162 ms on hcdnc340 (6/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 163 ms on hcdnc310 (7/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc340, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 170 ms on hcdnc340 (8/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 161 ms on hcdnc310 (9/10)%%0001017/07/18 01:22:09 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 133 ms on hcdnc340 (10/10)%%0001017/07/18 01:22:09 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:09 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.976 s%%0001017/07/18 01:22:09 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 4.587364 s%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:22:09 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:22:09 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:22:09 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:22:09 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:22:09 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:22:09 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:22:09 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:22:09 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36018] &lt;- [akka.tcp://sparkExecutor@hcdnc340:39290]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc340:39290] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc340:39290%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:22:09 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36018] &lt;- [akka.tcp://sparkExecutor@hcdnc310:50944]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:50944] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:50944%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:22:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:22:09 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:22:09 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:22:09 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:22:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:22:09 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:22:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:22:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:22:10 INFO Remoting: Remoting shut down%%0001017/07/18 01:22:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:22:10 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:22:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-066e657a-3fcb-4f41-b470-47f295f12ba8/pyspark-b9293a9d-469c-462f-ab11-21b48630a8ac%%0001017/07/18 01:22:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-066e657a-3fcb-4f41-b470-47f295f12ba8%%00010"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:22:27 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:22:28 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:22:28 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:22:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:22:28 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:22:28 INFO Remoting: Starting remoting%%0001017/07/18 01:22:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46448]%%0001017/07/18 01:22:28 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46448]%%0001017/07/18 01:22:28 INFO Utils: Successfully started service 'sparkDriver' on port 46448.%%0001017/07/18 01:22:28 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:22:28 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:22:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-33c864bc-e9e8-4175-bbdb-2e57a3266940%%0001017/07/18 01:22:28 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:22:29 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33444e31-83ef-42bf-b8dd-6b67f8cd547f/httpd-1983c499-1031-4103-85e9-87d84b26dc45%%0001017/07/18 01:22:29 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:22:29 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:22:29 INFO AbstractConnector: Started SocketConnector@0.0.0.0:38550%%0001017/07/18 01:22:29 INFO Utils: Successfully started service 'HTTP file server' on port 38550.%%0001017/07/18 01:22:29 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:22:29 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:22:29 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:22:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:22:29 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:22:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:22:30 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:22:30 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:22:30 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:22:30 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:22:30 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:22:30 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:22:30 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:22:30 INFO Client: Uploading resource file:/tmp/spark-33444e31-83ef-42bf-b8dd-6b67f8cd547f/__spark_conf__6393886764586091181.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22135/__spark_conf__6393886764586091181.zip%%0001017/07/18 01:22:31 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:22:31 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:22:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:22:31 INFO Client: Submitting application 22135 to ResourceManager%%0001017/07/18 01:22:31 INFO YarnClientImpl: Submitted application application_1491786134915_22135%%0001017/07/18 01:22:32 INFO Client: Application report for application_1491786134915_22135 (state: ACCEPTED)%%0001017/07/18 01:22:32 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312151211%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22135/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:22:33 INFO Client: Application report for application_1491786134915_22135 (state: ACCEPTED)%%0001017/07/18 01:22:35 INFO Client: Application report for application_1491786134915_22135 (state: ACCEPTED)%%0001017/07/18 01:22:35 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:49712/user/YarnAM#2056305724])%%0001017/07/18 01:22:35 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22135,http://hcnnc117:8088/proxy/application_1491786134915_22135), /proxy/application_1491786134915_22135%%0001017/07/18 01:22:35 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:22:36 INFO Client: Application report for application_1491786134915_22135 (state: RUNNING)%%0001017/07/18 01:22:36 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312151211%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22135/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:22:36 INFO YarnClientSchedulerBackend: Application application_1491786134915_22135 has started running.%%0001017/07/18 01:22:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34352.%%0001017/07/18 01:22:36 INFO NettyBlockTransferService: Server created on 34352%%0001017/07/18 01:22:36 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:22:36 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:22:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:34352 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 34352)%%0001017/07/18 01:22:36 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:22:36 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22135%%0001017/07/18 01:22:36 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:22:36 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:22:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:22:36 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:22:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:22:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:34352 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:22:36 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:22:37 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:22:37 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:22:37 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:22:37 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:22:37 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:22:37 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:22:37 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:22:37 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:22:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:22:37 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:22:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:22:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:34352 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:22:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:22:37 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:22:38 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:22:39 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:22:40 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46448] &lt;- [akka.tcp://driverPropsFetcher@hcdnc413:43898]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc413:43898] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc413:43898%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:22:40 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc413:51787/user/Executor#770055931]) with ID 1%%0001017/07/18 01:22:40 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:22:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc413, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:22:41 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc413:44744 with 530.0 MB RAM, BlockManagerId(1, hcdnc413, 44744)%%0001017/07/18 01:22:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc413:44744 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:41 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46448] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:34375]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:34375] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:34375%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:22:41 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:55121/user/Executor#-1670094803]) with ID 2%%0001017/07/18 01:22:41 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:22:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:22:41 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:43935 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 43935)%%0001017/07/18 01:22:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc413:44744 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:43935 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:43935 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5671 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5983 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:47 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.555 s%%0001017/07/18 01:22:47 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:47 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.677909 s%%0001017/07/18 01:22:47 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:22:47 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:22:47 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:22:47 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:22:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:22:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:22:47 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:22:47 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:22:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:22:47 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:22:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:22:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:34352 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:22:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:22:47 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:22:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc413, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:22:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:22:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:43935 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:22:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc413:44744 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:22:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5279 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5442 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:53 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:53 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.444 s%%0001017/07/18 01:22:53 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:53 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:53 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:22:53 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:53 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:22:53 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:22:53 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:22:53 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:22:53 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:22:53 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:34352 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:22:53 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:22:53 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:22:53 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc413, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:53 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:43935 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc413:44744 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:22:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:55121%%0001017/07/18 01:22:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:22:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc413:51787%%0001017/07/18 01:22:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 445 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 459 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.461 s%%0001017/07/18 01:22:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.936926 s%%0001017/07/18 01:22:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:22:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:22:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:22:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:22:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:22:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:22:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:22:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:22:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:22:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:22:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:34352 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:22:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:22:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:22:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc413, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:43935 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:22:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc413:44744 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:22:54 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 703 ms on hcdnc310 (1/2)%%0001017/07/18 01:22:54 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 706 ms on hcdnc413 (2/2)%%0001017/07/18 01:22:54 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.707 s%%0001017/07/18 01:22:54 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:54 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.721271 s%%0001017/07/18 01:22:54 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:22:54 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:22:54 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:22:54 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:22:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:22:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:22:54 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:22:54 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:22:54 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:22:54 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:22:54 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:22:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:34352 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:22:54 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:22:54 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:22:54 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc413, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:54 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc413:44744 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:22:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:43935 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 712 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 752 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:55 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:55 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.754 s%%0001017/07/18 01:22:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:55 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:55 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:22:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:55 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:22:55 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:22:55 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:22:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:22:55 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:22:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:34352 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:22:55 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:22:55 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc413, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc413:44744 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:43935 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:55121%%0001017/07/18 01:22:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 01:22:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc413:51787%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc413, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 47 ms on hcdnc413 (1/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 48 ms on hcdnc310 (2/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc413, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc310 (3/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 17 ms on hcdnc413 (4/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 16 ms on hcdnc310 (5/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc413, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc413 (6/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc310 (7/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc413, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc413 (8/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc310 (9/10)%%0001017/07/18 01:22:55 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc413 (10/10)%%0001017/07/18 01:22:55 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 01:22:55 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:55 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.878878 s%%0001017/07/18 01:22:55 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:22:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 01:22:55 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:22:55 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:22:55 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:22:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:22:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:22:55 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:22:55 INFO MemoryStore: ensureFreeSpace(12992) called with curMem=288500, maxMem=556038881%%0001017/07/18 01:22:55 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 530.0 MB)%%0001017/07/18 01:22:55 INFO MemoryStore: ensureFreeSpace(7138) called with curMem=301492, maxMem=556038881%%0001017/07/18 01:22:55 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:34352 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 01:22:55 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:22:55 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:55 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc413, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc413:44744 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:43935 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 01:22:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:55121%%0001017/07/18 01:22:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc413:51787%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 3602 ms on hcdnc413 (1/2)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 3714 ms on hcdnc310 (2/2)%%0001017/07/18 01:22:59 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:22:59 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 3.715 s%%0001017/07/18 01:22:59 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:22:59 INFO DAGScheduler: running: Set()%%0001017/07/18 01:22:59 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:22:59 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:22:59 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:22:59 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:22:59 INFO MemoryStore: ensureFreeSpace(16080) called with curMem=308630, maxMem=556038881%%0001017/07/18 01:22:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.7 KB, free 530.0 MB)%%0001017/07/18 01:22:59 INFO MemoryStore: ensureFreeSpace(8494) called with curMem=324710, maxMem=556038881%%0001017/07/18 01:22:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 01:22:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:34352 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 01:22:59 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:22:59 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:22:59 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc413, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc413:44744 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:43935 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 01:22:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc413:51787%%0001017/07/18 01:22:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 01:22:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:55121%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 310 ms on hcdnc310 (1/10)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc413, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 328 ms on hcdnc413 (2/10)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 146 ms on hcdnc310 (3/10)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc413, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 153 ms on hcdnc413 (4/10)%%0001017/07/18 01:22:59 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:22:59 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 137 ms on hcdnc310 (5/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc413, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 132 ms on hcdnc413 (6/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 129 ms on hcdnc310 (7/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc413, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 141 ms on hcdnc413 (8/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 128 ms on hcdnc310 (9/10)%%0001017/07/18 01:23:00 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 146 ms on hcdnc413 (10/10)%%0001017/07/18 01:23:00 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.896 s%%0001017/07/18 01:23:00 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:00 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 4.639010 s%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:23:00 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:23:00 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:23:00 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:23:00 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:23:00 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:23:00 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:23:00 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:23:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46448] &lt;- [akka.tcp://sparkExecutor@hcdnc310:55121]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:55121] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:55121%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:00 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46448] &lt;- [akka.tcp://sparkExecutor@hcdnc413:51787]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc413:51787] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc413:51787%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:23:00 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:23:00 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:23:00 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:23:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:23:00 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:23:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:23:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:23:00 INFO Remoting: Remoting shut down%%0001017/07/18 01:23:00 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:23:01 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:23:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-33444e31-83ef-42bf-b8dd-6b67f8cd547f/pyspark-0330fc17-0f65-4646-aa4e-988319854e18%%0001017/07/18 01:23:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-33444e31-83ef-42bf-b8dd-6b67f8cd547f%%00010"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:23:16 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:23:16 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:23:16 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:23:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:23:17 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:23:17 INFO Remoting: Starting remoting%%0001017/07/18 01:23:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:34182]%%0001017/07/18 01:23:18 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:34182]%%0001017/07/18 01:23:18 INFO Utils: Successfully started service 'sparkDriver' on port 34182.%%0001017/07/18 01:23:18 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:23:18 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:23:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8a18ad3b-bed1-42a0-83cd-bbf8c2c7b20f%%0001017/07/18 01:23:18 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:23:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-bf31177f-f46c-4966-a6c4-0208996045b4/httpd-597d5bf0-74b5-4599-bb6c-b655c901c3da%%0001017/07/18 01:23:18 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:23:18 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:23:18 INFO AbstractConnector: Started SocketConnector@0.0.0.0:43504%%0001017/07/18 01:23:18 INFO Utils: Successfully started service 'HTTP file server' on port 43504.%%0001017/07/18 01:23:18 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:23:18 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:23:19 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:23:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:23:19 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:23:19 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:23:19 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:23:19 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:23:19 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:23:19 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:23:19 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:23:19 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:23:19 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:23:19 INFO Client: Uploading resource file:/tmp/spark-bf31177f-f46c-4966-a6c4-0208996045b4/__spark_conf__4347922760759535458.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22136/__spark_conf__4347922760759535458.zip%%0001017/07/18 01:23:20 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:23:20 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:23:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:23:20 INFO Client: Submitting application 22136 to ResourceManager%%0001017/07/18 01:23:20 INFO YarnClientImpl: Submitted application application_1491786134915_22136%%0001017/07/18 01:23:21 INFO Client: Application report for application_1491786134915_22136 (state: ACCEPTED)%%0001017/07/18 01:23:21 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312200396%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22136/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:23:22 INFO Client: Application report for application_1491786134915_22136 (state: ACCEPTED)%%0001017/07/18 01:23:23 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:45933/user/YarnAM#-2127329377])%%0001017/07/18 01:23:23 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22136,http://hcnnc117:8088/proxy/application_1491786134915_22136), /proxy/application_1491786134915_22136%%0001017/07/18 01:23:23 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:23:23 INFO Client: Application report for application_1491786134915_22136 (state: RUNNING)%%0001017/07/18 01:23:23 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312200396%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22136/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:23:23 INFO YarnClientSchedulerBackend: Application application_1491786134915_22136 has started running.%%0001017/07/18 01:23:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45869.%%0001017/07/18 01:23:23 INFO NettyBlockTransferService: Server created on 45869%%0001017/07/18 01:23:23 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:23:23 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:23:23 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:45869 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 45869)%%0001017/07/18 01:23:23 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:23:23 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22136%%0001017/07/18 01:23:23 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:23:24 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:23:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:23:24 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:23:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:23:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:45869 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:23:24 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:23:24 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:23:24 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:23:24 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:23:24 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:23:24 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:23:24 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:23:24 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:23:24 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:23:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:23:24 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:23:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:23:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:45869 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:23:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:23:24 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:23:25 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:23:26 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:23:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34182] &lt;- [akka.tcp://driverPropsFetcher@hcdnc329:43831]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc329:43831] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc329:43831%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:28 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc329:45303/user/Executor#1305828396]) with ID 1%%0001017/07/18 01:23:28 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:23:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc329, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:23:28 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc329:52897 with 530.0 MB RAM, BlockManagerId(1, hcdnc329, 52897)%%0001017/07/18 01:23:28 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34182] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:57451]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:57451] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:57451%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc329:52897 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:23:29 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:52700/user/Executor#-388640938]) with ID 2%%0001017/07/18 01:23:29 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:23:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc304, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:23:29 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:46523 with 530.0 MB RAM, BlockManagerId(2, hcdnc304, 46523)%%0001017/07/18 01:23:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc329:52897 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:23:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:46523 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:23:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:46523 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:23:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5613 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5386 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 9.883 s%%0001017/07/18 01:23:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.008374 s%%0001017/07/18 01:23:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:23:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:23:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:23:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:23:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:23:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:23:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:23:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:23:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:23:34 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:23:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:45869 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:23:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:23:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:23:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc304, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:23:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc329, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:46523 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc329:52897 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:23:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5427 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5452 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:40 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.453 s%%0001017/07/18 01:23:40 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:40 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:23:40 INFO DAGScheduler: running: Set()%%0001017/07/18 01:23:40 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:23:40 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:23:40 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:23:40 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:23:40 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:23:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:23:40 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:23:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:45869 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:23:40 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:23:40 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:23:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc329, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:40 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:46523 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc329:52897 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:23:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:52700%%0001017/07/18 01:23:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:23:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc329:45303%%0001017/07/18 01:23:40 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 444 ms on hcdnc304 (1/2)%%0001017/07/18 01:23:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 473 ms on hcdnc329 (2/2)%%0001017/07/18 01:23:40 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:40 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.474 s%%0001017/07/18 01:23:40 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.959531 s%%0001017/07/18 01:23:40 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:23:40 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:23:40 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:23:40 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:23:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:23:40 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:23:40 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:23:40 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:23:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:23:40 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:23:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:45869 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:23:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:23:40 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:23:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc329, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:40 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:46523 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:23:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc329:52897 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:23:41 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 707 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:41 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 713 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:41 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:41 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.714 s%%0001017/07/18 01:23:41 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.764131 s%%0001017/07/18 01:23:41 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:23:41 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:23:41 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:23:41 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:23:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:23:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:23:41 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:23:41 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:23:41 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:23:41 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:23:41 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:23:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:45869 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:23:41 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:23:41 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:23:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc304, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:23:41 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc329, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:23:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:46523 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:23:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc329:52897 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 755 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 782 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:42 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:42 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.782 s%%0001017/07/18 01:23:42 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:23:42 INFO DAGScheduler: running: Set()%%0001017/07/18 01:23:42 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:23:42 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:23:42 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:23:42 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:23:42 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:23:42 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:23:42 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:23:42 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:45869 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:23:42 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:42 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:23:42 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc329, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc329:52897 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:46523 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:52700%%0001017/07/18 01:23:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:23:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc329:45303%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc304 (1/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc329, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 48 ms on hcdnc329 (2/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc304 (3/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc329, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc329 (4/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc304 (5/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc329, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc329 (6/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc304 (7/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc329, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 17 ms on hcdnc329 (8/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc304 (9/10)%%0001017/07/18 01:23:42 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc329 (10/10)%%0001017/07/18 01:23:42 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.107 s%%0001017/07/18 01:23:42 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:42 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.911438 s%%0001017/07/18 01:23:42 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:23:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:23:42 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:23:42 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:23:42 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:23:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:23:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:23:42 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:23:42 INFO MemoryStore: ensureFreeSpace(12024) called with curMem=288500, maxMem=556038881%%0001017/07/18 01:23:42 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.7 KB, free 530.0 MB)%%0001017/07/18 01:23:42 INFO MemoryStore: ensureFreeSpace(6601) called with curMem=300524, maxMem=556038881%%0001017/07/18 01:23:42 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:45869 (size: 6.4 KB, free: 530.2 MB)%%0001017/07/18 01:23:42 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:23:42 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc304, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:23:42 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc329, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:46523 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc329:52897 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:23:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:52700%%0001017/07/18 01:23:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc329:45303%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 2814 ms on hcdnc329 (1/2)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 2879 ms on hcdnc304 (2/2)%%0001017/07/18 01:23:45 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:45 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 2.879 s%%0001017/07/18 01:23:45 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:23:45 INFO DAGScheduler: running: Set()%%0001017/07/18 01:23:45 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:23:45 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:23:45 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:23:45 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:23:45 INFO MemoryStore: ensureFreeSpace(14904) called with curMem=307125, maxMem=556038881%%0001017/07/18 01:23:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.6 KB, free 530.0 MB)%%0001017/07/18 01:23:45 INFO MemoryStore: ensureFreeSpace(7823) called with curMem=322029, maxMem=556038881%%0001017/07/18 01:23:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:23:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:45869 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:23:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:23:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:23:45 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc329, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:46523 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:23:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc329:52897 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:23:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:52700%%0001017/07/18 01:23:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 01:23:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc329:45303%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc329, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 236 ms on hcdnc329 (1/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 246 ms on hcdnc304 (2/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 143 ms on hcdnc304 (3/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc329, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 155 ms on hcdnc329 (4/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc329, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 107 ms on hcdnc329 (5/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 111 ms on hcdnc304 (6/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc329, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 105 ms on hcdnc329 (7/10)%%0001017/07/18 01:23:45 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:23:45 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 127 ms on hcdnc304 (8/10)%%0001017/07/18 01:23:46 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 126 ms on hcdnc329 (9/10)%%0001017/07/18 01:23:46 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 144 ms on hcdnc304 (10/10)%%0001017/07/18 01:23:46 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:23:46 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.767 s%%0001017/07/18 01:23:46 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 3.672150 s%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:23:46 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:23:46 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:23:46 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:23:46 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:23:46 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:23:46 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:23:46 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:23:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34182] &lt;- [akka.tcp://sparkExecutor@hcdnc329:45303]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc329:45303] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc329:45303%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:34182] &lt;- [akka.tcp://sparkExecutor@hcdnc304:52700]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:52700] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:52700%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:23:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:23:46 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:23:46 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:23:46 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:23:46 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:23:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:23:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:23:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:23:46 INFO Remoting: Remoting shut down%%0001017/07/18 01:23:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:23:47 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:23:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-bf31177f-f46c-4966-a6c4-0208996045b4%%00010"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:24:02 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:24:03 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:24:03 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:24:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:24:04 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:24:04 INFO Remoting: Starting remoting%%0001017/07/18 01:24:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:44031]%%0001017/07/18 01:24:04 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:44031]%%0001017/07/18 01:24:04 INFO Utils: Successfully started service 'sparkDriver' on port 44031.%%0001017/07/18 01:24:04 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:24:04 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:24:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e5f3c74b-337d-4d8b-989f-85be58958323%%0001017/07/18 01:24:04 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:24:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-48143d2b-7dc1-43d9-82fb-cad1be2acae5/httpd-2db14472-f6b1-4136-b509-53bd7ebf660f%%0001017/07/18 01:24:05 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:24:05 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:24:05 INFO AbstractConnector: Started SocketConnector@0.0.0.0:37245%%0001017/07/18 01:24:05 INFO Utils: Successfully started service 'HTTP file server' on port 37245.%%0001017/07/18 01:24:05 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:24:05 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:24:05 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:24:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:24:05 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:24:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:24:05 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:24:05 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:24:05 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:24:05 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:24:05 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:24:05 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:24:05 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:24:06 INFO Client: Uploading resource file:/tmp/spark-48143d2b-7dc1-43d9-82fb-cad1be2acae5/__spark_conf__3321120254950138705.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22137/__spark_conf__3321120254950138705.zip%%0001017/07/18 01:24:06 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:24:06 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:24:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:24:06 INFO Client: Submitting application 22137 to ResourceManager%%0001017/07/18 01:24:06 INFO YarnClientImpl: Submitted application application_1491786134915_22137%%0001017/07/18 01:24:07 INFO Client: Application report for application_1491786134915_22137 (state: ACCEPTED)%%0001017/07/18 01:24:07 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312246537%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22137/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:24:08 INFO Client: Application report for application_1491786134915_22137 (state: ACCEPTED)%%0001017/07/18 01:24:09 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33593/user/YarnAM#-1127319109])%%0001017/07/18 01:24:09 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22137,http://hcnnc117:8088/proxy/application_1491786134915_22137), /proxy/application_1491786134915_22137%%0001017/07/18 01:24:09 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:24:09 INFO Client: Application report for application_1491786134915_22137 (state: ACCEPTED)%%0001017/07/18 01:24:10 INFO Client: Application report for application_1491786134915_22137 (state: RUNNING)%%0001017/07/18 01:24:10 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312246537%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22137/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:24:10 INFO YarnClientSchedulerBackend: Application application_1491786134915_22137 has started running.%%0001017/07/18 01:24:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43656.%%0001017/07/18 01:24:10 INFO NettyBlockTransferService: Server created on 43656%%0001017/07/18 01:24:10 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:24:10 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:24:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:43656 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 43656)%%0001017/07/18 01:24:10 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:24:11 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22137%%0001017/07/18 01:24:11 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:24:12 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:24:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:24:12 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:24:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:24:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:43656 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:24:12 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:24:12 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:24:12 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:24:12 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:24:12 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:24:12 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:24:12 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:24:12 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:24:12 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:24:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:24:12 INFO MemoryStore: ensureFreeSpace(3979) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:24:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:24:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:43656 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:24:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:24:12 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:24:13 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:24:14 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:24:15 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:44031] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:51237]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:51237] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:51237%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:24:16 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:57507/user/Executor#1024885866]) with ID 1%%0001017/07/18 01:24:16 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:24:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:24:16 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:60994 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 60994)%%0001017/07/18 01:24:16 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:44031] &lt;- [akka.tcp://driverPropsFetcher@hcdnc323:57630]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc323:57630] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc323:57630%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:24:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:60994 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:24:17 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc323:44188/user/Executor#530856310]) with ID 2%%0001017/07/18 01:24:17 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:24:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc323, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:24:17 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc323:51974 with 530.0 MB RAM, BlockManagerId(2, hcdnc323, 51974)%%0001017/07/18 01:24:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:60994 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:24:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc323:51974 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:24:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc323:51974 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:24:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5950 ms on hcdnc310 (1/2)%%0001017/07/18 01:24:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5683 ms on hcdnc323 (2/2)%%0001017/07/18 01:24:23 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.674 s%%0001017/07/18 01:24:23 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:23 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.806650 s%%0001017/07/18 01:24:23 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:24:23 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:24:23 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:24:23 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:24:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:24:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:24:23 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:24:23 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237415, maxMem=556038881%%0001017/07/18 01:24:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:24:23 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246071, maxMem=556038881%%0001017/07/18 01:24:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:24:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:43656 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:24:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:24:23 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:24:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc323, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:24:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:24:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:60994 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:24:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc323:51974 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:24:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5438 ms on hcdnc310 (1/2)%%0001017/07/18 01:24:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5548 ms on hcdnc323 (2/2)%%0001017/07/18 01:24:28 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.550 s%%0001017/07/18 01:24:28 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:28 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:24:28 INFO DAGScheduler: running: Set()%%0001017/07/18 01:24:28 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:24:28 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:24:28 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:24:28 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:24:28 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251378, maxMem=556038881%%0001017/07/18 01:24:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:24:28 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258314, maxMem=556038881%%0001017/07/18 01:24:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:24:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:43656 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:24:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:24:28 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:24:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc323, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:60994 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:24:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc323:51974 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:24:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc323:44188%%0001017/07/18 01:24:28 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:24:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:57507%%0001017/07/18 01:24:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 440 ms on hcdnc323 (1/2)%%0001017/07/18 01:24:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 452 ms on hcdnc310 (2/2)%%0001017/07/18 01:24:29 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:29 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.453 s%%0001017/07/18 01:24:29 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 6.034034 s%%0001017/07/18 01:24:29 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:24:29 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:24:29 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:24:29 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:24:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:24:29 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:24:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:24:29 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262357, maxMem=556038881%%0001017/07/18 01:24:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:24:29 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268877, maxMem=556038881%%0001017/07/18 01:24:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:43656 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:24:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:24:29 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:24:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:29 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc323, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:60994 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc323:51974 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:24:29 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 691 ms on hcdnc323 (1/2)%%0001017/07/18 01:24:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 718 ms on hcdnc310 (2/2)%%0001017/07/18 01:24:29 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:29 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.719 s%%0001017/07/18 01:24:29 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.732658 s%%0001017/07/18 01:24:29 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:24:29 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:24:29 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:24:29 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:24:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:24:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:24:29 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:24:29 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272779, maxMem=556038881%%0001017/07/18 01:24:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:24:29 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279955, maxMem=556038881%%0001017/07/18 01:24:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:43656 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:24:29 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:29 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:24:29 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:24:29 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc323, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:24:29 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:60994 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:24:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc323:51974 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 750 ms on hcdnc310 (1/2)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 799 ms on hcdnc323 (2/2)%%0001017/07/18 01:24:30 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:30 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.799 s%%0001017/07/18 01:24:30 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:24:30 INFO DAGScheduler: running: Set()%%0001017/07/18 01:24:30 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:24:30 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:24:30 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:24:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:24:30 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284104, maxMem=556038881%%0001017/07/18 01:24:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:24:30 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286888, maxMem=556038881%%0001017/07/18 01:24:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:43656 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:24:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:24:30 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc323, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc323:51974 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:60994 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc323:44188%%0001017/07/18 01:24:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:24:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:57507%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 44 ms on hcdnc310 (1/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc323, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 48 ms on hcdnc323 (2/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc310 (3/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc323, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc323 (4/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc310 (5/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc323, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 17 ms on hcdnc323 (6/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 14 ms on hcdnc310 (7/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc323, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc323 (8/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc310 (9/10)%%0001017/07/18 01:24:30 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc323 (10/10)%%0001017/07/18 01:24:30 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 01:24:30 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:30 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.924754 s%%0001017/07/18 01:24:30 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:24:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:24:30 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:24:30 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:24:30 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:24:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:24:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:24:30 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:24:30 INFO MemoryStore: ensureFreeSpace(12024) called with curMem=288503, maxMem=556038881%%0001017/07/18 01:24:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.7 KB, free 530.0 MB)%%0001017/07/18 01:24:30 INFO MemoryStore: ensureFreeSpace(6599) called with curMem=300527, maxMem=556038881%%0001017/07/18 01:24:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:43656 (size: 6.4 KB, free: 530.2 MB)%%0001017/07/18 01:24:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:24:30 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:24:30 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc323, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:60994 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc323:51974 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:24:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:57507%%0001017/07/18 01:24:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc323:44188%%0001017/07/18 01:24:33 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 2795 ms on hcdnc323 (1/2)%%0001017/07/18 01:24:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 2819 ms on hcdnc310 (2/2)%%0001017/07/18 01:24:33 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:33 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 2.820 s%%0001017/07/18 01:24:33 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:24:33 INFO DAGScheduler: running: Set()%%0001017/07/18 01:24:33 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:24:33 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:24:33 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:24:33 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:24:33 INFO MemoryStore: ensureFreeSpace(14904) called with curMem=307126, maxMem=556038881%%0001017/07/18 01:24:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.6 KB, free 530.0 MB)%%0001017/07/18 01:24:33 INFO MemoryStore: ensureFreeSpace(7821) called with curMem=322030, maxMem=556038881%%0001017/07/18 01:24:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:24:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:43656 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:24:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:24:33 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:24:33 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:24:33 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:33 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc323, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc323:51974 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:24:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:60994 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:24:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:57507%%0001017/07/18 01:24:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 01:24:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc323:44188%%0001017/07/18 01:24:33 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 231 ms on hcdnc310 (1/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc323, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 341 ms on hcdnc323 (2/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 148 ms on hcdnc310 (3/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc323, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 147 ms on hcdnc323 (4/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 123 ms on hcdnc310 (5/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc323, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 135 ms on hcdnc323 (6/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 133 ms on hcdnc310 (7/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc323, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 141 ms on hcdnc323 (8/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 144 ms on hcdnc310 (9/10)%%0001017/07/18 01:24:34 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 152 ms on hcdnc323 (10/10)%%0001017/07/18 01:24:34 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:24:34 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.914 s%%0001017/07/18 01:24:34 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 3.760064 s%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:24:34 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:24:34 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:24:34 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:24:34 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:24:34 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:24:34 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:24:34 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:24:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:44031] &lt;- [akka.tcp://sparkExecutor@hcdnc310:57507]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:57507] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:57507%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:24:34 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:44031] &lt;- [akka.tcp://sparkExecutor@hcdnc323:44188]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc323:44188] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc323:44188%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:24:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:24:34 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:24:34 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:24:34 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:24:34 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:24:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:24:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:24:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:24:35 INFO Remoting: Remoting shut down%%0001017/07/18 01:24:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:24:35 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:24:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-48143d2b-7dc1-43d9-82fb-cad1be2acae5%%00010"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 01:24:51 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 01:24:52 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:24:52 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:24:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:24:53 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 01:24:53 INFO Remoting: Starting remoting%%0001017/07/18 01:24:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:36486]%%0001017/07/18 01:24:53 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:36486]%%0001017/07/18 01:24:53 INFO Utils: Successfully started service 'sparkDriver' on port 36486.%%0001017/07/18 01:24:53 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 01:24:53 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 01:24:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e7705ae6-f92e-4e07-8d81-0247f5c1154a%%0001017/07/18 01:24:53 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 01:24:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-86ded582-f366-4dcd-b7d6-89ff171f005e/httpd-101832e9-4fee-4984-9252-196ec6069f2e%%0001017/07/18 01:24:53 INFO HttpServer: Starting HTTP Server%%0001017/07/18 01:24:53 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:24:53 INFO AbstractConnector: Started SocketConnector@0.0.0.0:45506%%0001017/07/18 01:24:53 INFO Utils: Successfully started service 'HTTP file server' on port 45506.%%0001017/07/18 01:24:53 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 01:24:53 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 01:24:53 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 01:24:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 01:24:53 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 01:24:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 01:24:54 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 01:24:54 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 01:24:54 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 01:24:54 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 01:24:54 INFO Client: Setting up container launch context for our AM%%0001017/07/18 01:24:54 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 01:24:54 INFO Client: Preparing resources for our AM container%%0001017/07/18 01:24:54 INFO Client: Uploading resource file:/tmp/spark-86ded582-f366-4dcd-b7d6-89ff171f005e/__spark_conf__7897731490790202147.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22138/__spark_conf__7897731490790202147.zip%%0001017/07/18 01:24:55 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 01:24:55 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 01:24:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 01:24:55 INFO Client: Submitting application 22138 to ResourceManager%%0001017/07/18 01:24:55 INFO YarnClientImpl: Submitted application application_1491786134915_22138%%0001017/07/18 01:24:56 INFO Client: Application report for application_1491786134915_22138 (state: ACCEPTED)%%0001017/07/18 01:24:56 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312295065%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22138/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:24:57 INFO Client: Application report for application_1491786134915_22138 (state: ACCEPTED)%%0001017/07/18 01:24:58 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33339/user/YarnAM#-2083037658])%%0001017/07/18 01:24:58 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22138,http://hcnnc117:8088/proxy/application_1491786134915_22138), /proxy/application_1491786134915_22138%%0001017/07/18 01:24:58 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 01:24:58 INFO Client: Application report for application_1491786134915_22138 (state: ACCEPTED)%%0001017/07/18 01:24:59 INFO Client: Application report for application_1491786134915_22138 (state: RUNNING)%%0001017/07/18 01:24:59 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500312295065%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22138/%%00010%%00009 user: y23ycc01%%0001017/07/18 01:24:59 INFO YarnClientSchedulerBackend: Application application_1491786134915_22138 has started running.%%0001017/07/18 01:24:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45135.%%0001017/07/18 01:24:59 INFO NettyBlockTransferService: Server created on 45135%%0001017/07/18 01:24:59 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 01:24:59 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 01:24:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:45135 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 45135)%%0001017/07/18 01:24:59 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 01:25:00 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22138%%0001017/07/18 01:25:00 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 01:25:01 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 01:25:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 01:25:01 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 01:25:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 01:25:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:45135 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 01:25:01 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 01:25:01 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 01:25:01 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 01:25:01 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 01:25:01 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:25:01 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 01:25:01 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:25:01 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 01:25:01 INFO MemoryStore: ensureFreeSpace(6800) called with curMem=226636, maxMem=556038881%%0001017/07/18 01:25:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 01:25:01 INFO MemoryStore: ensureFreeSpace(3976) called with curMem=233436, maxMem=556038881%%0001017/07/18 01:25:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 01:25:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:45135 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 01:25:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 01:25:01 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 01:25:02 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 01:25:03 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 01:25:04 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36486] &lt;- [akka.tcp://driverPropsFetcher@hcdnc316:38824]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc316:38824] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc316:38824%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:25:05 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc316:51414/user/Executor#1459596726]) with ID 1%%0001017/07/18 01:25:05 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 01:25:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc316, partition 0,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:25:05 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc316:42608 with 530.0 MB RAM, BlockManagerId(1, hcdnc316, 42608)%%0001017/07/18 01:25:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36486] &lt;- [akka.tcp://driverPropsFetcher@hcdnc340:55123]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc340:55123] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc340:55123%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:25:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc316:42608 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:25:06 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc340:40672/user/Executor#-1068516597]) with ID 2%%0001017/07/18 01:25:06 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 01:25:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc340, partition 1,RACK_LOCAL, 2150 bytes)%%0001017/07/18 01:25:06 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc340:37950 with 530.0 MB RAM, BlockManagerId(2, hcdnc340, 37950)%%0001017/07/18 01:25:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc340:37950 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:25:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc316:42608 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:25:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc340:37950 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 01:25:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5794 ms on hcdnc316 (1/2)%%0001017/07/18 01:25:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 5415 ms on hcdnc340 (2/2)%%0001017/07/18 01:25:11 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 10.212 s%%0001017/07/18 01:25:11 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:11 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 10.332655 s%%0001017/07/18 01:25:11 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 01:25:11 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:25:11 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 01:25:11 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:25:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 01:25:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 01:25:11 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 01:25:11 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237412, maxMem=556038881%%0001017/07/18 01:25:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 01:25:11 INFO MemoryStore: ensureFreeSpace(5307) called with curMem=246068, maxMem=556038881%%0001017/07/18 01:25:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 01:25:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:45135 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 01:25:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 01:25:11 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 01:25:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc340, partition 0,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:25:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc316, partition 1,RACK_LOCAL, 2139 bytes)%%0001017/07/18 01:25:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc340:37950 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:25:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc316:42608 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 01:25:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5191 ms on hcdnc316 (1/2)%%0001017/07/18 01:25:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5433 ms on hcdnc340 (2/2)%%0001017/07/18 01:25:17 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:17 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 5.433 s%%0001017/07/18 01:25:17 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:25:17 INFO DAGScheduler: running: Set()%%0001017/07/18 01:25:17 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 01:25:17 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:25:17 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 01:25:17 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 01:25:17 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251375, maxMem=556038881%%0001017/07/18 01:25:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 01:25:17 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258311, maxMem=556038881%%0001017/07/18 01:25:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:45135 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 01:25:17 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 01:25:17 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 01:25:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc340, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc340:37950 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc316:42608 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 01:25:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc340:40672%%0001017/07/18 01:25:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:25:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc316:51414%%0001017/07/18 01:25:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 430 ms on hcdnc340 (1/2)%%0001017/07/18 01:25:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 460 ms on hcdnc316 (2/2)%%0001017/07/18 01:25:17 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:17 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 0.461 s%%0001017/07/18 01:25:17 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 5.932761 s%%0001017/07/18 01:25:17 WARN FPGrowth: Input data is not cached.%%0001017/07/18 01:25:17 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 01:25:17 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 01:25:17 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 01:25:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 01:25:17 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 01:25:17 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 01:25:17 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262354, maxMem=556038881%%0001017/07/18 01:25:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:25:17 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268874, maxMem=556038881%%0001017/07/18 01:25:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:45135 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 01:25:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 01:25:17 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 01:25:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc340, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:17 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc340:37950 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc316:42608 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 01:25:18 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 662 ms on hcdnc316 (1/2)%%0001017/07/18 01:25:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 676 ms on hcdnc340 (2/2)%%0001017/07/18 01:25:18 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:18 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 0.677 s%%0001017/07/18 01:25:18 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 0.690563 s%%0001017/07/18 01:25:18 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 01:25:18 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 01:25:18 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 01:25:18 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 01:25:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 01:25:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 01:25:18 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 01:25:18 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272776, maxMem=556038881%%0001017/07/18 01:25:18 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 01:25:18 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279952, maxMem=556038881%%0001017/07/18 01:25:18 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 01:25:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:45135 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 01:25:18 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 01:25:18 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 01:25:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc316, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:25:18 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc340, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:25:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc340:37950 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:25:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc316:42608 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 01:25:18 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 713 ms on hcdnc340 (1/2)%%0001017/07/18 01:25:18 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 714 ms on hcdnc316 (2/2)%%0001017/07/18 01:25:18 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:18 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 0.716 s%%0001017/07/18 01:25:18 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:25:18 INFO DAGScheduler: running: Set()%%0001017/07/18 01:25:18 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 01:25:18 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:25:18 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 01:25:18 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 01:25:18 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284101, maxMem=556038881%%0001017/07/18 01:25:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 01:25:18 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286885, maxMem=556038881%%0001017/07/18 01:25:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 01:25:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:45135 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 01:25:18 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:18 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 01:25:18 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 01:25:18 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc316, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc340, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc340:37950 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc316:42608 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 01:25:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc340:40672%%0001017/07/18 01:25:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 01:25:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc316:51414%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc340, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 43 ms on hcdnc340 (1/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc316, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc316 (2/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc340, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc340 (3/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc316, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc316 (4/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc340, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 16 ms on hcdnc340 (5/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc316, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc316 (6/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc340, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc340 (7/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc316, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc316 (8/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc340 (9/10)%%0001017/07/18 01:25:19 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc316 (10/10)%%0001017/07/18 01:25:19 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 01:25:19 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:19 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 0.852716 s%%0001017/07/18 01:25:19 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 01:25:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 01:25:19 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 01:25:19 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 01:25:19 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:25:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 01:25:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 01:25:19 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 01:25:19 INFO MemoryStore: ensureFreeSpace(12024) called with curMem=288500, maxMem=556038881%%0001017/07/18 01:25:19 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.7 KB, free 530.0 MB)%%0001017/07/18 01:25:19 INFO MemoryStore: ensureFreeSpace(6599) called with curMem=300524, maxMem=556038881%%0001017/07/18 01:25:19 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:45135 (size: 6.4 KB, free: 530.2 MB)%%0001017/07/18 01:25:19 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 01:25:19 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc340, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:25:19 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc316, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc340:37950 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:25:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc316:42608 (size: 6.4 KB, free: 530.0 MB)%%0001017/07/18 01:25:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc340:40672%%0001017/07/18 01:25:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc316:51414%%0001017/07/18 01:25:21 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 2730 ms on hcdnc316 (1/2)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 2874 ms on hcdnc340 (2/2)%%0001017/07/18 01:25:22 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:22 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 2.875 s%%0001017/07/18 01:25:22 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 01:25:22 INFO DAGScheduler: running: Set()%%0001017/07/18 01:25:22 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 01:25:22 INFO DAGScheduler: failed: Set()%%0001017/07/18 01:25:22 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 01:25:22 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 01:25:22 INFO MemoryStore: ensureFreeSpace(14904) called with curMem=307123, maxMem=556038881%%0001017/07/18 01:25:22 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.6 KB, free 530.0 MB)%%0001017/07/18 01:25:22 INFO MemoryStore: ensureFreeSpace(7821) called with curMem=322027, maxMem=556038881%%0001017/07/18 01:25:22 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 01:25:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:45135 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 01:25:22 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 01:25:22 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 01:25:22 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc340, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc340:37950 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:25:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc316:42608 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 01:25:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc316:51414%%0001017/07/18 01:25:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 168 bytes%%0001017/07/18 01:25:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc340:40672%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc340, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 249 ms on hcdnc340 (1/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc316, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 252 ms on hcdnc316 (2/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc340, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 135 ms on hcdnc340 (3/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc316, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 163 ms on hcdnc316 (4/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc340, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 132 ms on hcdnc340 (5/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc316, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 129 ms on hcdnc316 (6/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc340, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 104 ms on hcdnc340 (7/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc316, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 133 ms on hcdnc316 (8/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 129 ms on hcdnc340 (9/10)%%0001017/07/18 01:25:22 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 132 ms on hcdnc316 (10/10)%%0001017/07/18 01:25:22 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 01:25:22 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 0.806 s%%0001017/07/18 01:25:22 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 3.708826 s%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 01:25:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 01:25:22 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 01:25:22 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 01:25:22 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 01:25:22 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 01:25:22 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 01:25:22 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 01:25:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36486] &lt;- [akka.tcp://sparkExecutor@hcdnc316:51414]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc316:51414] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc316:51414%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:25:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:36486] &lt;- [akka.tcp://sparkExecutor@hcdnc340:40672]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc340:40672] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc340:40672%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 01:25:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 01:25:23 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 01:25:23 INFO BlockManager: BlockManager stopped%%0001017/07/18 01:25:23 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 01:25:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 01:25:23 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 01:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 01:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 01:25:23 INFO Remoting: Remoting shut down%%0001017/07/18 01:25:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 01:25:24 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 01:25:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-86ded582-f366-4dcd-b7d6-89ff171f005e%%00010"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_2">
<entry key="column_name" type="xstring" value="FailingNode"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Bash"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_3">
<entry key="column_name" type="xstring" value="currentIteration"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.IntCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="8"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_4">
<entry key="column_name" type="xstring" value="maxIterations"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.IntCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="9"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="9"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_5">
<entry key="column_name" type="xstring" value="index_of_drugColumn"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="6.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="6.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_6">
<entry key="column_name" type="xstring" value="minSupport"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.005"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.009999999999999998"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_7">
<entry key="column_name" type="xstring" value="minConfidence"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.2"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.4000000000000001"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_8">
<entry key="column_name" type="xstring" value="cmd"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.005 0.2"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.005 0.3"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.005 0.4"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.0075 0.2"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.0075 0.3"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.0075 0.4"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.01 0.2"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.01 0.3"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.urticaria.csv 6 0.01 0.4"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_9">
<entry key="column_name" type="xstring" value="RowID"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="0"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="2"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="3"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="4"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="5"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="6"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="7"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="8"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_10">
<entry key="column_name" type="xstring" value="config_host_ip"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="140.110.30.32"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_11">
<entry key="column_name" type="xstring" value="task_minConfidenceLower"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="20.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="20.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_12">
<entry key="column_name" type="xstring" value="task_local_attr_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.feature.TCM.summary.level123.QiFlavorMeri.20170621.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_13">
<entry key="column_name" type="xstring" value="config_password"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1q2w3e4r"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_14">
<entry key="column_name" type="xstring" value="config_local_NHIcode_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.TCM.HF_SH.20170703.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_15">
<entry key="column_name" type="xstring" value="config_local_metadata_fullpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_16">
<entry key="column_name" type="xstring" value="task_minConfidenceStep"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="10.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="10.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_17">
<entry key="column_name" type="xstring" value="task_local_keyword_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.keyword.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_18">
<entry key="column_name" type="xstring" value="task_drugColumnIndex"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="6.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="6.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_19">
<entry key="column_name" type="xstring" value="task_updateCachedDataFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_20">
<entry key="column_name" type="xstring" value="task_name_Ch"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value=""/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_21">
<entry key="column_name" type="xstring" value="config_local_output_fullpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData/Sample"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_22">
<entry key="column_name" type="xstring" value="task_minSupportUpper"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="1.25"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="1.25"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_23">
<entry key="column_name" type="xstring" value="task_local_cachedData_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.cachedData.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_24">
<entry key="column_name" type="xstring" value="task_updateCachedPubmedFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="N"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_25">
<entry key="column_name" type="xstring" value="task_name"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Urticaria"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_26">
<entry key="column_name" type="xstring" value="task_minConfidenceUpper"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="50.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="50.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_27">
<entry key="column_name" type="xstring" value="config_local_translation_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.NAME.translation_shortform.20170625.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_28">
<entry key="column_name" type="xstring" value="task_local_translation_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.NAME.translation_shortform.20170625.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_29">
<entry key="column_name" type="xstring" value="config_graphspace_id"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="yuchn.chen@gmail.com"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_30">
<entry key="column_name" type="xstring" value="task_local_NHIcode_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.TCM.HF_SH.20170703.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_31">
<entry key="column_name" type="xstring" value="config_graphspace_pwd"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1q2w3e4r"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_32">
<entry key="column_name" type="xstring" value="task_local_cachedPubmed_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.cachedPubmed.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_33">
<entry key="column_name" type="xstring" value="config_local_cachedData_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.cachedData.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_34">
<entry key="column_name" type="xstring" value="task_remote_srcFilemname"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="/home_i1/y23ycc01/incoming/tid.urticaria.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_35">
<entry key="column_name" type="xstring" value="config_local_cachedPubmed_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.cachedPubmed.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_36">
<entry key="column_name" type="xstring" value="task_remote_srcFilepath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="/home_i1/y23ycc01/incoming"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_37">
<entry key="column_name" type="xstring" value="config_user_id"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="y23ycc01"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_38">
<entry key="column_name" type="xstring" value="task_forceReanalyze"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_39">
<entry key="column_name" type="xstring" value="config_workpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="incoming"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_40">
<entry key="column_name" type="xstring" value="task_reuploadSrcFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_41">
<entry key="column_name" type="xstring" value="task_minSupportLower"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.5"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.5"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_42">
<entry key="column_name" type="xstring" value="config_local_keyword_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.keyword.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_43">
<entry key="column_name" type="xstring" value="task_minSupportStep"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.25"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.25"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_44">
<entry key="column_name" type="xstring" value="config_local_attr_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.feature.TCM.summary.level123.QiFlavorMeri.20170621.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_45">
<entry key="column_name" type="xstring" value="task_srcFileExt"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value=".csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_46">
<entry key="column_name" type="xstring" value="task_srcFilename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="tid.urticaria"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_47">
<entry key="column_name" type="xstring" value="task_srcDirectory"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Dropbox\1.Projects\Cytoscape\testData\Sample"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_48">
<entry key="column_name" type="xstring" value="task_local_srcfilename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Dropbox\1.Projects\Cytoscape\testData\Sample\tid.urticaria.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_49">
<entry key="column_name" type="xstring" value="knime.workspace"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Users\yuchn\knime-workspace"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
</config>
