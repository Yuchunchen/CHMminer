<?xml version="1.0" encoding="UTF-8"?>
<config xmlns="http://www.knime.org/2008/09/XMLConfig" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.knime.org/2008/09/XMLConfig http://www.knime.org/XMLConfig_2008_09.xsd" key="spec.xml">
<entry key="spec_name" type="xstring" value="default"/>
<entry key="number_columns" type="xint" value="50"/>
<config key="column_spec_0">
<entry key="column_name" type="xstring" value="FailingNodeStackTrace"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:20:13 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:20:13 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:20:13 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:20:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:20:15 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:20:15 INFO Remoting: Starting remoting%%0001017/07/18 00:20:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37866]%%0001017/07/18 00:20:15 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37866]%%0001017/07/18 00:20:15 INFO Utils: Successfully started service 'sparkDriver' on port 37866.%%0001017/07/18 00:20:15 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:20:15 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:20:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fec229ec-cac1-40d2-93e9-68f7e8622739%%0001017/07/18 00:20:15 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:20:16 INFO HttpFileServer: HTTP File server directory is /tmp/spark-6521cb87-2158-4374-9443-4c1c8aaa6e56/httpd-1e26b171-e529-4129-bf45-004d2fcbded7%%0001017/07/18 00:20:16 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:20:16 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:20:16 INFO AbstractConnector: Started SocketConnector@0.0.0.0:33890%%0001017/07/18 00:20:16 INFO Utils: Successfully started service 'HTTP file server' on port 33890.%%0001017/07/18 00:20:16 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:20:16 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:20:16 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:20:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:20:16 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:20:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:20:16 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:20:16 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:20:16 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:20:16 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:20:16 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:20:16 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:20:16 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:20:17 INFO Client: Uploading resource file:/tmp/spark-6521cb87-2158-4374-9443-4c1c8aaa6e56/__spark_conf__5110204394930781122.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22103/__spark_conf__5110204394930781122.zip%%0001017/07/18 00:20:17 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:20:17 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:20:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:20:17 INFO Client: Submitting application 22103 to ResourceManager%%0001017/07/18 00:20:17 INFO YarnClientImpl: Submitted application application_1491786134915_22103%%0001017/07/18 00:20:18 INFO Client: Application report for application_1491786134915_22103 (state: ACCEPTED)%%0001017/07/18 00:20:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308417636%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22103/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:20:19 INFO Client: Application report for application_1491786134915_22103 (state: ACCEPTED)%%0001017/07/18 00:20:20 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33366/user/YarnAM#732571533])%%0001017/07/18 00:20:20 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22103,http://hcnnc117:8088/proxy/application_1491786134915_22103), /proxy/application_1491786134915_22103%%0001017/07/18 00:20:20 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:20:20 INFO Client: Application report for application_1491786134915_22103 (state: RUNNING)%%0001017/07/18 00:20:20 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308417636%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22103/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:20:20 INFO YarnClientSchedulerBackend: Application application_1491786134915_22103 has started running.%%0001017/07/18 00:20:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44216.%%0001017/07/18 00:20:20 INFO NettyBlockTransferService: Server created on 44216%%0001017/07/18 00:20:20 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:20:20 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:20:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:44216 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 44216)%%0001017/07/18 00:20:20 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:20:21 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22103%%0001017/07/18 00:20:22 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:20:22 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:20:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:20:22 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:20:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:20:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:44216 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:20:22 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:20:22 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.34:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.32:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.35:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.3:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.23:50010%%0001017/07/18 00:20:22 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:20:22 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:20:22 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:20:22 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:20:22 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:20:22 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:20:22 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:20:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:20:22 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:20:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:20:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:44216 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:20:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:20:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:20:22 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:20:23 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:20:24 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:20:26 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37866] &lt;- [akka.tcp://driverPropsFetcher@hcdnc213:34504]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc213:34504] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc213:34504%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:20:26 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc213:53498/user/Executor#-615378246]) with ID 1%%0001017/07/18 00:20:26 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:20:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc213, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:20:26 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc213:37680 with 530.0 MB RAM, BlockManagerId(1, hcdnc213, 37680)%%0001017/07/18 00:20:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc213:37680 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:20:27 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37866] &lt;- [akka.tcp://driverPropsFetcher@hcdnc306:37871]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:37871] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:37871%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:20:27 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc306:35465/user/Executor#1926258327]) with ID 2%%0001017/07/18 00:20:27 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:20:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc213:37680 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:20:27 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc306:44767 with 530.0 MB RAM, BlockManagerId(2, hcdnc306, 44767)%%0001017/07/18 00:20:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc306, partition 1,ANY, 2145 bytes)%%0001017/07/18 00:20:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc306:44767 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:20:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc306:44767 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:20:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11637 ms on hcdnc213 (1/2)%%0001017/07/18 00:20:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11633 ms on hcdnc306 (2/2)%%0001017/07/18 00:20:41 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 18.593 s%%0001017/07/18 00:20:41 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:20:41 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 18.741660 s%%0001017/07/18 00:20:41 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:20:41 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:20:41 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:20:41 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:20:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:20:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:20:41 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:20:41 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:20:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:20:41 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:20:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:20:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:44216 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:20:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:20:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:20:41 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:20:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc306, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:20:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc213, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:20:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc306:44767 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:20:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc213:37680 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:20:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17008 ms on hcdnc213 (1/2)%%0001017/07/18 00:20:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17312 ms on hcdnc306 (2/2)%%0001017/07/18 00:20:58 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:20:58 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.312 s%%0001017/07/18 00:20:58 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:20:58 INFO DAGScheduler: running: Set()%%0001017/07/18 00:20:58 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:20:58 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:20:58 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:20:58 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:20:58 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:20:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:20:58 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:20:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:20:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:44216 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:20:58 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:20:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:20:58 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:20:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:20:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc213, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:20:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc306:44767 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:20:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc213:37680 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:20:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:35465%%0001017/07/18 00:20:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:20:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc213:53498%%0001017/07/18 00:21:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1349 ms on hcdnc306 (1/2)%%0001017/07/18 00:21:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1377 ms on hcdnc213 (2/2)%%0001017/07/18 00:21:00 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:00 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.378 s%%0001017/07/18 00:21:00 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 18.722483 s%%0001017/07/18 00:21:00 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:21:00 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:21:00 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:21:00 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:21:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:21:00 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:21:00 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:21:00 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:21:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:21:00 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:21:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:21:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:44216 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:21:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:21:00 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:21:00 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:00 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc213, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc306:44767 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:21:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc213:37680 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:21:02 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2564 ms on hcdnc213 (1/2)%%0001017/07/18 00:21:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2603 ms on hcdnc306 (2/2)%%0001017/07/18 00:21:02 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:02 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.603 s%%0001017/07/18 00:21:02 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.617427 s%%0001017/07/18 00:21:02 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:21:02 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:21:02 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:21:02 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:21:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:21:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:21:02 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:21:02 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:21:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:21:02 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:21:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:21:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:44216 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:21:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:21:02 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:21:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc306, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:21:02 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc213, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:21:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc213:37680 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:21:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc306:44767 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2580 ms on hcdnc213 (1/2)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2591 ms on hcdnc306 (2/2)%%0001017/07/18 00:21:05 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:05 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.592 s%%0001017/07/18 00:21:05 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:21:05 INFO DAGScheduler: running: Set()%%0001017/07/18 00:21:05 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:21:05 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:21:05 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:21:05 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:21:05 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:21:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:21:05 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:21:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:44216 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 00:21:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:05 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:21:05 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc213, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc306, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc213:37680 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc306:44767 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc213:53498%%0001017/07/18 00:21:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:21:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc306:35465%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc306, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc213, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc306 (1/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc213 (2/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc306, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc213, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc306 (3/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc213 (4/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc306, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc306 (5/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc213, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc213 (6/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc306, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc306 (7/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc213, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc213 (8/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc306 (9/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc213 (10/10)%%0001017/07/18 00:21:05 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 00:21:05 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:05 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.717496 s%%0001017/07/18 00:21:05 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:21:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:21:05 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:21:05 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:21:05 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:21:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:21:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:21:05 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:21:05 INFO MemoryStore: ensureFreeSpace(14024) called with curMem=288482, maxMem=556038881%%0001017/07/18 00:21:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:21:05 INFO MemoryStore: ensureFreeSpace(7740) called with curMem=302506, maxMem=556038881%%0001017/07/18 00:21:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:44216 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:21:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:21:05 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc306, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc213, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc213:37680 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc306:44767 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc213:53498%%0001017/07/18 00:21:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:35465%%0001017/07/18 00:21:18 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 12965 ms on hcdnc213 (1/2)%%0001017/07/18 00:21:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 13562 ms on hcdnc306 (2/2)%%0001017/07/18 00:21:19 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:19 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 13.563 s%%0001017/07/18 00:21:19 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:21:19 INFO DAGScheduler: running: Set()%%0001017/07/18 00:21:19 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:21:19 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:21:19 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:21:19 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:21:19 INFO MemoryStore: ensureFreeSpace(17344) called with curMem=310246, maxMem=556038881%%0001017/07/18 00:21:19 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.9 KB, free 530.0 MB)%%0001017/07/18 00:21:19 INFO MemoryStore: ensureFreeSpace(9233) called with curMem=327590, maxMem=556038881%%0001017/07/18 00:21:19 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 00:21:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:44216 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 00:21:19 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:19 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:21:19 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:21:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:19 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc213, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc306:44767 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:21:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc213:37680 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:21:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc306:35465%%0001017/07/18 00:21:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 165 bytes%%0001017/07/18 00:21:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc213:53498%%0001017/07/18 00:21:19 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc213, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:19 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 628 ms on hcdnc213 (1/10)%%0001017/07/18 00:21:20 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc306, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:20 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 707 ms on hcdnc306 (2/10)%%0001017/07/18 00:21:20 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:21:20 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc213, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:20 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 512 ms on hcdnc213 (3/10)%%0001017/07/18 00:21:20 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc306, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:20 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 558 ms on hcdnc306 (4/10)%%0001017/07/18 00:21:20 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc213, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:20 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 481 ms on hcdnc213 (5/10)%%0001017/07/18 00:21:21 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc306, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:21 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 470 ms on hcdnc306 (6/10)%%0001017/07/18 00:21:21 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 4)%%0001017/07/18 00:21:21 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc213, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:21 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 542 ms on hcdnc213 (7/10)%%0001017/07/18 00:21:21 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc306, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:21 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 583 ms on hcdnc306 (8/10)%%0001017/07/18 00:21:22 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 549 ms on hcdnc213 (9/10)%%0001017/07/18 00:21:22 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 534 ms on hcdnc306 (10/10)%%0001017/07/18 00:21:22 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:22 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.849 s%%0001017/07/18 00:21:22 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 16.438286 s%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:21:22 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:21:22 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:21:22 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:21:22 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:21:22 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:21:22 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:21:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37866] &lt;- [akka.tcp://sparkExecutor@hcdnc213:53498]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc213:53498] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc213:53498%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:21:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37866] &lt;- [akka.tcp://sparkExecutor@hcdnc306:35465]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc306:35465] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc306:35465%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:21:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:21:22 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:21:22 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:21:22 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:21:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:21:22 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:21:22 INFO Remoting: Remoting shut down%%0001017/07/18 00:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:21:23 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:21:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-6521cb87-2158-4374-9443-4c1c8aaa6e56/pyspark-a43a12f3-97d0-4c1f-aa22-65f43644c130%%0001017/07/18 00:21:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-6521cb87-2158-4374-9443-4c1c8aaa6e56%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:21:37 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:21:38 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:21:38 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:21:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:21:38 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:21:39 INFO Remoting: Starting remoting%%0001017/07/18 00:21:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:33819]%%0001017/07/18 00:21:39 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:33819]%%0001017/07/18 00:21:39 INFO Utils: Successfully started service 'sparkDriver' on port 33819.%%0001017/07/18 00:21:39 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:21:39 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:21:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-73372352-70b1-405d-8d6e-792a91b8c89f%%0001017/07/18 00:21:39 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:21:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-cb24707b-5060-466a-a599-2b5af5627c51/httpd-91578644-6daf-4d8b-9acf-49e6b88187d0%%0001017/07/18 00:21:39 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:21:39 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:21:39 INFO AbstractConnector: Started SocketConnector@0.0.0.0:46260%%0001017/07/18 00:21:39 INFO Utils: Successfully started service 'HTTP file server' on port 46260.%%0001017/07/18 00:21:39 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:21:39 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:21:39 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:21:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:21:39 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:21:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:21:40 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:21:40 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:21:40 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:21:40 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:21:40 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:21:40 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:21:40 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:21:40 INFO Client: Uploading resource file:/tmp/spark-cb24707b-5060-466a-a599-2b5af5627c51/__spark_conf__9150238668380521165.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22104/__spark_conf__9150238668380521165.zip%%0001017/07/18 00:21:40 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:21:40 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:21:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:21:41 INFO Client: Submitting application 22104 to ResourceManager%%0001017/07/18 00:21:41 INFO YarnClientImpl: Submitted application application_1491786134915_22104%%0001017/07/18 00:21:42 INFO Client: Application report for application_1491786134915_22104 (state: ACCEPTED)%%0001017/07/18 00:21:42 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308501014%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22104/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:21:43 INFO Client: Application report for application_1491786134915_22104 (state: ACCEPTED)%%0001017/07/18 00:21:44 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:42554/user/YarnAM#1637362184])%%0001017/07/18 00:21:44 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22104,http://hcnnc117:8088/proxy/application_1491786134915_22104), /proxy/application_1491786134915_22104%%0001017/07/18 00:21:44 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:21:44 INFO Client: Application report for application_1491786134915_22104 (state: ACCEPTED)%%0001017/07/18 00:21:45 INFO Client: Application report for application_1491786134915_22104 (state: RUNNING)%%0001017/07/18 00:21:45 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308501014%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22104/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:21:45 INFO YarnClientSchedulerBackend: Application application_1491786134915_22104 has started running.%%0001017/07/18 00:21:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45774.%%0001017/07/18 00:21:45 INFO NettyBlockTransferService: Server created on 45774%%0001017/07/18 00:21:45 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:21:45 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:21:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:45774 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 45774)%%0001017/07/18 00:21:45 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:21:46 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22104%%0001017/07/18 00:21:46 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:21:46 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:21:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:21:47 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:21:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:21:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:45774 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:21:47 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:21:47 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.3:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.10:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.31:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.17:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.18:50010%%0001017/07/18 00:21:47 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:21:47 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:21:47 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:21:47 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:21:47 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:21:47 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:21:47 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:21:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:21:47 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:21:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:21:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:45774 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:21:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:21:47 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:21:48 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:21:49 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:21:50 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:33819] &lt;- [akka.tcp://driverPropsFetcher@hcdnc419:43972]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc419:43972] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc419:43972%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:21:51 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc419:40710/user/Executor#454427462]) with ID 1%%0001017/07/18 00:21:51 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:21:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc419, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:21:51 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc419:55768 with 530.0 MB RAM, BlockManagerId(1, hcdnc419, 55768)%%0001017/07/18 00:21:51 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:33819] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:43141]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:43141] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:43141%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:21:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc419:55768 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:21:51 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:40244/user/Executor#-1848429002]) with ID 2%%0001017/07/18 00:21:51 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:21:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:21:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc419:55768 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:21:51 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:60575 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 60575)%%0001017/07/18 00:21:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:60575 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:21:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:60575 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:22:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11697 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11656 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:03 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.239 s%%0001017/07/18 00:22:03 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:03 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.359774 s%%0001017/07/18 00:22:03 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:22:03 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:22:03 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:22:03 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:22:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:22:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:22:03 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:22:03 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:22:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:22:03 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:22:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:22:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:45774 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:22:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:22:03 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:22:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc419, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:22:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:22:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc419:55768 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:22:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:60575 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:22:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17481 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 18548 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:22 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:22 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 18.552 s%%0001017/07/18 00:22:22 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:22:22 INFO DAGScheduler: running: Set()%%0001017/07/18 00:22:22 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:22:22 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:22:22 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:22:22 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:22:22 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:22:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:22:22 INFO MemoryStore: ensureFreeSpace(4048) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:22:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 530.0 MB)%%0001017/07/18 00:22:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:45774 (size: 4.0 KB, free: 530.2 MB)%%0001017/07/18 00:22:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:22:22 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:22:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc419, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:60575 (size: 4.0 KB, free: 530.0 MB)%%0001017/07/18 00:22:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc419:55768 (size: 4.0 KB, free: 530.0 MB)%%0001017/07/18 00:22:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:40244%%0001017/07/18 00:22:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:22:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc419:40710%%0001017/07/18 00:22:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1509 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1544 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:23 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:23 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.544 s%%0001017/07/18 00:22:23 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 20.127949 s%%0001017/07/18 00:22:23 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:22:23 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:22:23 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:22:23 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:22:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:22:23 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:22:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:22:23 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262341, maxMem=556038881%%0001017/07/18 00:22:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:22:23 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268861, maxMem=556038881%%0001017/07/18 00:22:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:22:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:45774 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:22:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:22:23 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:22:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc419, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:23 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc419:55768 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:22:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:60575 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:22:26 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2683 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:26 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 3108 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:26 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:26 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 3.110 s%%0001017/07/18 00:22:26 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 3.124242 s%%0001017/07/18 00:22:26 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:22:26 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:22:26 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:22:26 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:22:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:22:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:22:26 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:22:26 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272763, maxMem=556038881%%0001017/07/18 00:22:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:22:26 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279939, maxMem=556038881%%0001017/07/18 00:22:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:22:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:45774 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:22:26 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:22:26 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:22:26 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc419, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:22:26 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:22:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc419:55768 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:22:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:60575 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:22:29 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2673 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 3140 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:30 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:30 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 3.141 s%%0001017/07/18 00:22:30 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:22:30 INFO DAGScheduler: running: Set()%%0001017/07/18 00:22:30 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:22:30 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:22:30 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:22:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:22:30 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284088, maxMem=556038881%%0001017/07/18 00:22:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:22:30 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286872, maxMem=556038881%%0001017/07/18 00:22:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:45774 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 00:22:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:22:30 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc419, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc419:55768 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:60575 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:22:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:40244%%0001017/07/18 00:22:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:22:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc419:40710%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc419, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 44 ms on hcdnc419 (1/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc310 (2/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc419, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc419 (3/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 18 ms on hcdnc310 (4/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc419, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc419 (5/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc310 (6/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc419, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc419 (7/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 14 ms on hcdnc310 (8/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc419 (9/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 11 ms on hcdnc310 (10/10)%%0001017/07/18 00:22:30 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.106 s%%0001017/07/18 00:22:30 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:30 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 3.269401 s%%0001017/07/18 00:22:30 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:22:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:22:30 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:22:30 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:22:30 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:22:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:22:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:22:30 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:22:30 INFO MemoryStore: ensureFreeSpace(14024) called with curMem=288487, maxMem=556038881%%0001017/07/18 00:22:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:22:30 INFO MemoryStore: ensureFreeSpace(7740) called with curMem=302511, maxMem=556038881%%0001017/07/18 00:22:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:45774 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:22:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:22:30 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc419, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:60575 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc419:55768 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:22:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:40244%%0001017/07/18 00:22:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc419:40710%%0001017/07/18 00:22:44 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 13775 ms on hcdnc310 (1/2)%%0001017/07/18 00:22:44 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 14541 ms on hcdnc419 (2/2)%%0001017/07/18 00:22:44 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:44 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 14.542 s%%0001017/07/18 00:22:44 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:22:44 INFO DAGScheduler: running: Set()%%0001017/07/18 00:22:44 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:22:44 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:22:44 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:22:44 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:22:44 INFO MemoryStore: ensureFreeSpace(17344) called with curMem=310251, maxMem=556038881%%0001017/07/18 00:22:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.9 KB, free 530.0 MB)%%0001017/07/18 00:22:44 INFO MemoryStore: ensureFreeSpace(9233) called with curMem=327595, maxMem=556038881%%0001017/07/18 00:22:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 00:22:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:45774 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 00:22:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:22:44 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:22:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc419, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:44 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc419:55768 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:22:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:60575 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:22:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc419:40710%%0001017/07/18 00:22:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 165 bytes%%0001017/07/18 00:22:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:40244%%0001017/07/18 00:22:45 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc419, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 601 ms on hcdnc419 (1/10)%%0001017/07/18 00:22:45 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:45 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 722 ms on hcdnc310 (2/10)%%0001017/07/18 00:22:45 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 486 ms on hcdnc310 (3/10)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc419, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 725 ms on hcdnc419 (4/10)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 477 ms on hcdnc310 (5/10)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc419, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 613 ms on hcdnc419 (6/10)%%0001017/07/18 00:22:46 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 4)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 511 ms on hcdnc310 (7/10)%%0001017/07/18 00:22:47 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc419, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:47 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 547 ms on hcdnc419 (8/10)%%0001017/07/18 00:22:47 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 516 ms on hcdnc310 (9/10)%%0001017/07/18 00:22:47 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 529 ms on hcdnc419 (10/10)%%0001017/07/18 00:22:47 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:47 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 3.011 s%%0001017/07/18 00:22:47 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 17.580705 s%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:22:47 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:22:47 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:22:47 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:22:47 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:22:47 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:22:47 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:22:48 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:33819] &lt;- [akka.tcp://sparkExecutor@hcdnc419:40710]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc419:40710] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc419:40710%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:22:48 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:33819] &lt;- [akka.tcp://sparkExecutor@hcdnc310:40244]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:40244] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:40244%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:22:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:22:48 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:22:48 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:22:48 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:22:48 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:22:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:22:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:22:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:22:48 INFO Remoting: Remoting shut down%%0001017/07/18 00:22:48 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:22:48 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:22:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-cb24707b-5060-466a-a599-2b5af5627c51%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:23:03 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:23:03 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:23:03 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:23:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:23:04 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:23:04 INFO Remoting: Starting remoting%%0001017/07/18 00:23:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:32849]%%0001017/07/18 00:23:04 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:32849]%%0001017/07/18 00:23:04 INFO Utils: Successfully started service 'sparkDriver' on port 32849.%%0001017/07/18 00:23:04 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:23:04 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:23:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-be37ba71-e9e8-41f3-a50b-6dc74ac8fbf4%%0001017/07/18 00:23:04 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:23:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0c70c4de-250f-4d13-9c2e-53e1f8e4f62a/httpd-a5d65b98-b456-44b8-ac5b-22cb2ecaa266%%0001017/07/18 00:23:04 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:23:04 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:23:05 INFO AbstractConnector: Started SocketConnector@0.0.0.0:33519%%0001017/07/18 00:23:05 INFO Utils: Successfully started service 'HTTP file server' on port 33519.%%0001017/07/18 00:23:05 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:23:05 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:23:06 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:23:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:23:06 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:23:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:23:06 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:23:06 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:23:06 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:23:06 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:23:06 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:23:06 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:23:06 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:23:07 INFO Client: Uploading resource file:/tmp/spark-0c70c4de-250f-4d13-9c2e-53e1f8e4f62a/__spark_conf__5472358139873679719.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22105/__spark_conf__5472358139873679719.zip%%0001017/07/18 00:23:07 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:23:07 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:23:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:23:07 INFO Client: Submitting application 22105 to ResourceManager%%0001017/07/18 00:23:07 INFO YarnClientImpl: Submitted application application_1491786134915_22105%%0001017/07/18 00:23:08 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:08 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308587621%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22105/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:23:09 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:10 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:11 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:12 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:13 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:14 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:15 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.3.27:59248/user/YarnAM#-1737969702])%%0001017/07/18 00:23:15 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22105,http://hcnnc117:8088/proxy/application_1491786134915_22105), /proxy/application_1491786134915_22105%%0001017/07/18 00:23:15 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:23:15 INFO Client: Application report for application_1491786134915_22105 (state: RUNNING)%%0001017/07/18 00:23:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.3.27%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308587621%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22105/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:23:15 INFO YarnClientSchedulerBackend: Application application_1491786134915_22105 has started running.%%0001017/07/18 00:23:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39917.%%0001017/07/18 00:23:15 INFO NettyBlockTransferService: Server created on 39917%%0001017/07/18 00:23:15 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:23:15 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:23:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:39917 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 39917)%%0001017/07/18 00:23:15 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:23:16 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22105%%0001017/07/18 00:23:16 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:23:16 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:23:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:23:17 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:23:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:23:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:39917 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:23:17 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:23:17 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.17:50010%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.15:50010%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.18:50010%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.7:50010%%0001017/07/18 00:23:17 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:23:17 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:23:17 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:23:17 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:23:17 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:23:17 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:23:17 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:23:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:23:17 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:23:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:23:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:39917 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:23:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:23:17 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:23:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:23:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:23:20 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:32849] &lt;- [akka.tcp://driverPropsFetcher@hcdnc305:51994]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc305:51994] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc305:51994%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:23:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc305:35082/user/Executor#-316650948]) with ID 1%%0001017/07/18 00:23:21 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:23:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc305, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:23:21 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc305:47632 with 530.0 MB RAM, BlockManagerId(1, hcdnc305, 47632)%%0001017/07/18 00:23:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:32849] &lt;- [akka.tcp://driverPropsFetcher@hcdnc235:57288]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc235:57288] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc235:57288%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:23:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc305:47632 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:23:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc235:55382/user/Executor#-724987626]) with ID 2%%0001017/07/18 00:23:21 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:23:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc235, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:23:22 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc235:36240 with 530.0 MB RAM, BlockManagerId(2, hcdnc235, 36240)%%0001017/07/18 00:23:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc305:47632 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:23:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc235:36240 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:23:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc235:36240 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:23:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11967 ms on hcdnc305 (1/2)%%0001017/07/18 00:23:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12352 ms on hcdnc235 (2/2)%%0001017/07/18 00:23:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.956 s%%0001017/07/18 00:23:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:23:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.100442 s%%0001017/07/18 00:23:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:23:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:23:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:23:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:23:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:23:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:23:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:23:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:23:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:23:34 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:23:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:39917 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:23:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:23:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:23:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc235, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc235:36240 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:23:35 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:23:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc305, partition 1,ANY, 2134 bytes)%%0001017/07/18 00:23:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc305:47632 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:23:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 18130 ms on hcdnc235 (1/2)%%0001017/07/18 00:23:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17535 ms on hcdnc305 (2/2)%%0001017/07/18 00:23:55 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:23:55 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 21.052 s%%0001017/07/18 00:23:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:23:55 INFO DAGScheduler: running: Set()%%0001017/07/18 00:23:55 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:23:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:23:55 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:23:55 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:23:55 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:23:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:23:55 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:23:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:23:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:39917 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:23:55 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:23:55 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:23:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:23:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc235, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:23:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc305:47632 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:23:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc235:36240 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:23:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc305:35082%%0001017/07/18 00:23:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:23:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc235:55382%%0001017/07/18 00:23:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1428 ms on hcdnc305 (1/2)%%0001017/07/18 00:23:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1471 ms on hcdnc235 (2/2)%%0001017/07/18 00:23:56 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:23:56 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.473 s%%0001017/07/18 00:23:56 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 22.567359 s%%0001017/07/18 00:23:56 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:23:56 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:23:56 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:23:56 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:23:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:23:56 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:23:56 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:23:56 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:23:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:23:56 INFO MemoryStore: ensureFreeSpace(3901) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:23:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:23:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:39917 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:23:56 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:23:56 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:23:56 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:23:56 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc235, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:23:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc305:47632 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:23:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc235:36240 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:23:59 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2730 ms on hcdnc235 (1/2)%%0001017/07/18 00:23:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2734 ms on hcdnc305 (2/2)%%0001017/07/18 00:23:59 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:23:59 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.734 s%%0001017/07/18 00:23:59 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.749007 s%%0001017/07/18 00:23:59 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:23:59 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:23:59 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:23:59 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:23:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:23:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:23:59 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:23:59 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272757, maxMem=556038881%%0001017/07/18 00:23:59 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:23:59 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279933, maxMem=556038881%%0001017/07/18 00:23:59 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:23:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:39917 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:23:59 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:23:59 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:23:59 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc235, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:23:59 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc305, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:23:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc235:36240 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:23:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc305:47632 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2719 ms on hcdnc235 (1/2)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2779 ms on hcdnc305 (2/2)%%0001017/07/18 00:24:02 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:02 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.780 s%%0001017/07/18 00:24:02 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:24:02 INFO DAGScheduler: running: Set()%%0001017/07/18 00:24:02 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:24:02 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:24:02 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:24:02 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:24:02 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284082, maxMem=556038881%%0001017/07/18 00:24:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:24:02 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286866, maxMem=556038881%%0001017/07/18 00:24:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:39917 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 00:24:02 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:02 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:24:02 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc235, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc305, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc235:36240 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc305:47632 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc305:35082%%0001017/07/18 00:24:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:24:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc235:55382%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc305, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc305 (1/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc305, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc305 (2/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc235, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 65 ms on hcdnc235 (3/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc305, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 19 ms on hcdnc305 (4/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc235, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc235 (5/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc305, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 16 ms on hcdnc305 (6/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc235, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 18 ms on hcdnc235 (7/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc305, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 14 ms on hcdnc305 (8/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc235 (9/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc305 (10/10)%%0001017/07/18 00:24:02 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:02 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.114 s%%0001017/07/18 00:24:02 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.915616 s%%0001017/07/18 00:24:02 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:24:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:24:02 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:24:02 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:24:02 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:24:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:24:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:24:02 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:24:02 INFO MemoryStore: ensureFreeSpace(14024) called with curMem=288481, maxMem=556038881%%0001017/07/18 00:24:02 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:24:02 INFO MemoryStore: ensureFreeSpace(7740) called with curMem=302505, maxMem=556038881%%0001017/07/18 00:24:02 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:39917 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:24:02 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:24:02 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc305, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc235, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc305:47632 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc235:36240 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc305:35082%%0001017/07/18 00:24:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc235:55382%%0001017/07/18 00:24:16 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 13555 ms on hcdnc305 (1/2)%%0001017/07/18 00:24:16 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 13602 ms on hcdnc235 (2/2)%%0001017/07/18 00:24:16 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:16 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 13.603 s%%0001017/07/18 00:24:16 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:24:16 INFO DAGScheduler: running: Set()%%0001017/07/18 00:24:16 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:24:16 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:24:16 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:24:16 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:24:16 INFO MemoryStore: ensureFreeSpace(17344) called with curMem=310245, maxMem=556038881%%0001017/07/18 00:24:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.9 KB, free 530.0 MB)%%0001017/07/18 00:24:16 INFO MemoryStore: ensureFreeSpace(9233) called with curMem=327589, maxMem=556038881%%0001017/07/18 00:24:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 00:24:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:39917 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 00:24:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:16 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:24:16 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:24:16 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc235, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:16 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc305, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc305:47632 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:24:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc235:36240 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:24:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc305:35082%%0001017/07/18 00:24:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 00:24:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc235:55382%%0001017/07/18 00:24:16 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc305, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:16 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 633 ms on hcdnc305 (1/10)%%0001017/07/18 00:24:17 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc235, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:17 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 678 ms on hcdnc235 (2/10)%%0001017/07/18 00:24:17 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:24:17 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc235, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:17 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 487 ms on hcdnc235 (3/10)%%0001017/07/18 00:24:17 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc305, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:17 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 540 ms on hcdnc305 (4/10)%%0001017/07/18 00:24:18 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc305, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 492 ms on hcdnc305 (5/10)%%0001017/07/18 00:24:18 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc235, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 546 ms on hcdnc235 (6/10)%%0001017/07/18 00:24:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 4)%%0001017/07/18 00:24:18 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc305, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 511 ms on hcdnc305 (7/10)%%0001017/07/18 00:24:18 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc235, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 519 ms on hcdnc235 (8/10)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 463 ms on hcdnc305 (9/10)%%0001017/07/18 00:24:19 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 485 ms on hcdnc235 (10/10)%%0001017/07/18 00:24:19 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:19 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.713 s%%0001017/07/18 00:24:19 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 16.343022 s%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:24:19 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:24:19 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:24:19 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:24:19 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:24:19 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:24:19 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:24:19 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:32849] &lt;- [akka.tcp://sparkExecutor@hcdnc235:55382]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc235:55382] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc235:55382%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:24:19 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:32849] &lt;- [akka.tcp://sparkExecutor@hcdnc305:35082]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc305:35082] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc305:35082%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:24:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:24:19 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:24:19 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:24:19 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:24:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:24:19 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:24:19 INFO Remoting: Remoting shut down%%0001017/07/18 00:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:24:20 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:24:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-0c70c4de-250f-4d13-9c2e-53e1f8e4f62a/pyspark-91ccdb90-5f5b-4df8-ba46-5fb90111cd32%%0001017/07/18 00:24:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-0c70c4de-250f-4d13-9c2e-53e1f8e4f62a%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:24:33 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:24:34 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:24:34 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:24:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:24:34 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:24:34 INFO Remoting: Starting remoting%%0001017/07/18 00:24:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37659]%%0001017/07/18 00:24:35 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37659]%%0001017/07/18 00:24:35 INFO Utils: Successfully started service 'sparkDriver' on port 37659.%%0001017/07/18 00:24:35 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:24:35 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:24:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a27826c8-a68d-4448-8217-201a38b17c3a%%0001017/07/18 00:24:35 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:24:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-73eb15c7-f5e4-4194-b169-d63121342d43/httpd-d298e4a2-a24a-4e2c-8720-99cc466ded7e%%0001017/07/18 00:24:35 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:24:35 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:24:35 INFO AbstractConnector: Started SocketConnector@0.0.0.0:36872%%0001017/07/18 00:24:35 INFO Utils: Successfully started service 'HTTP file server' on port 36872.%%0001017/07/18 00:24:35 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:24:35 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:24:35 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:24:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:24:35 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:24:35 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:24:35 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:24:35 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:24:35 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:24:35 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:24:35 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:24:35 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:24:35 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:24:36 INFO Client: Uploading resource file:/tmp/spark-73eb15c7-f5e4-4194-b169-d63121342d43/__spark_conf__818153191684606821.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22106/__spark_conf__818153191684606821.zip%%0001017/07/18 00:24:36 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:24:36 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:24:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:24:36 INFO Client: Submitting application 22106 to ResourceManager%%0001017/07/18 00:24:36 INFO YarnClientImpl: Submitted application application_1491786134915_22106%%0001017/07/18 00:24:37 INFO Client: Application report for application_1491786134915_22106 (state: ACCEPTED)%%0001017/07/18 00:24:37 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308676754%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22106/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:24:38 INFO Client: Application report for application_1491786134915_22106 (state: ACCEPTED)%%0001017/07/18 00:24:39 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:48955/user/YarnAM#-2080359981])%%0001017/07/18 00:24:39 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22106,http://hcnnc117:8088/proxy/application_1491786134915_22106), /proxy/application_1491786134915_22106%%0001017/07/18 00:24:39 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:24:39 INFO Client: Application report for application_1491786134915_22106 (state: RUNNING)%%0001017/07/18 00:24:39 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308676754%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22106/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:24:39 INFO YarnClientSchedulerBackend: Application application_1491786134915_22106 has started running.%%0001017/07/18 00:24:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41804.%%0001017/07/18 00:24:40 INFO NettyBlockTransferService: Server created on 41804%%0001017/07/18 00:24:40 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:24:40 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:24:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41804 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41804)%%0001017/07/18 00:24:40 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:24:41 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22106%%0001017/07/18 00:24:41 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:24:41 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:24:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:24:41 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:24:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:24:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41804 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:24:41 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:24:41 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.22:50010%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.36:50010%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.23:50010%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.4:50010%%0001017/07/18 00:24:41 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:24:41 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:24:41 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:24:41 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:24:41 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:24:41 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:24:41 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:24:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:24:41 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:24:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:24:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41804 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:24:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:24:41 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:24:42 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:24:43 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:24:45 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37659] &lt;- [akka.tcp://driverPropsFetcher@hcdnc823:51461]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:51461] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:51461%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:24:45 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc823:48750/user/Executor#-433458982]) with ID 1%%0001017/07/18 00:24:45 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:24:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc823, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:24:45 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc823:46039 with 530.0 MB RAM, BlockManagerId(1, hcdnc823, 46039)%%0001017/07/18 00:24:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc823:46039 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:24:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37659] &lt;- [akka.tcp://driverPropsFetcher@hcdnc316:39091]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc316:39091] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc316:39091%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:24:46 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc316:53852/user/Executor#320444702]) with ID 2%%0001017/07/18 00:24:46 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:24:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc316, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:24:46 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc316:49066 with 530.0 MB RAM, BlockManagerId(2, hcdnc316, 49066)%%0001017/07/18 00:24:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc823:46039 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:24:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc316:49066 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:24:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc316:49066 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:24:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12386 ms on hcdnc823 (1/2)%%0001017/07/18 00:24:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11693 ms on hcdnc316 (2/2)%%0001017/07/18 00:24:58 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.253 s%%0001017/07/18 00:24:58 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:58 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.374166 s%%0001017/07/18 00:24:58 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:24:58 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:24:58 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:24:58 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:24:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:24:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:24:58 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:24:58 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:24:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:24:58 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:24:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:24:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41804 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:24:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:24:58 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:24:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc823, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:24:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc316, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:24:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc823:46039 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:24:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc316:49066 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:25:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17045 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17895 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:16 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:16 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.895 s%%0001017/07/18 00:25:16 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:25:16 INFO DAGScheduler: running: Set()%%0001017/07/18 00:25:16 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:25:16 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:25:16 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:25:16 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:25:16 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:25:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:25:16 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:25:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:25:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41804 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:25:16 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:25:16 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:25:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc316, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc823, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc823:46039 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:25:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc316:49066 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:25:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:48750%%0001017/07/18 00:25:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:25:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc316:53852%%0001017/07/18 00:25:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1362 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1455 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:17 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:17 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.458 s%%0001017/07/18 00:25:17 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.383326 s%%0001017/07/18 00:25:17 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:25:17 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:25:17 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:25:17 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:25:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:25:17 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:25:17 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:25:17 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:25:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:25:17 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:25:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41804 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:25:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:25:17 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:25:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc316, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:17 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc823, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc316:49066 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc823:46039 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:25:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2558 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:20 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2744 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:20 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:20 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.745 s%%0001017/07/18 00:25:20 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.758066 s%%0001017/07/18 00:25:20 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:25:20 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:25:20 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:25:20 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:25:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:25:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:25:20 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:25:20 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:25:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:25:20 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:25:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:25:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41804 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:25:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:25:20 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:25:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc823, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:25:20 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc316, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:25:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc316:49066 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:25:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc823:46039 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2627 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2753 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:23 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:23 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.753 s%%0001017/07/18 00:25:23 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:25:23 INFO DAGScheduler: running: Set()%%0001017/07/18 00:25:23 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:25:23 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:25:23 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:25:23 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:25:23 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:25:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:25:23 INFO MemoryStore: ensureFreeSpace(1614) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:25:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1614.0 B, free 530.0 MB)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41804 (size: 1614.0 B, free: 530.2 MB)%%0001017/07/18 00:25:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:23 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:25:23 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc823:46039 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc316:49066 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc823:48750%%0001017/07/18 00:25:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:25:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc316:53852%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc316, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 44 ms on hcdnc316 (1/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc823, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 47 ms on hcdnc823 (2/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc316, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc316 (3/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc823 (4/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc316, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc316 (5/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc823 (6/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc316, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc316 (7/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc823 (8/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc316 (9/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc823 (10/10)%%0001017/07/18 00:25:23 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 00:25:23 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:23 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.878391 s%%0001017/07/18 00:25:23 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:25:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:25:23 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:25:23 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:25:23 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:25:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:25:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:25:23 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:25:23 INFO MemoryStore: ensureFreeSpace(12936) called with curMem=288481, maxMem=556038881%%0001017/07/18 00:25:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 530.0 MB)%%0001017/07/18 00:25:23 INFO MemoryStore: ensureFreeSpace(7135) called with curMem=301417, maxMem=556038881%%0001017/07/18 00:25:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41804 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 00:25:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:25:23 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc823, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc316, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc823:46039 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc316:49066 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:48750%%0001017/07/18 00:25:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc316:53852%%0001017/07/18 00:25:35 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 11711 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:35 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 12085 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:35 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:35 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 12.085 s%%0001017/07/18 00:25:35 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:25:35 INFO DAGScheduler: running: Set()%%0001017/07/18 00:25:35 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:25:35 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:25:35 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:25:35 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:25:35 INFO MemoryStore: ensureFreeSpace(16008) called with curMem=308552, maxMem=556038881%%0001017/07/18 00:25:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.6 KB, free 530.0 MB)%%0001017/07/18 00:25:35 INFO MemoryStore: ensureFreeSpace(8481) called with curMem=324560, maxMem=556038881%%0001017/07/18 00:25:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 00:25:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41804 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 00:25:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:35 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:25:35 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:25:35 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:35 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc823:46039 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:25:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc316:49066 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:25:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc823:48750%%0001017/07/18 00:25:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 163 bytes%%0001017/07/18 00:25:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc316:53852%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc316, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 524 ms on hcdnc316 (1/10)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc823, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 622 ms on hcdnc823 (2/10)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc316, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 439 ms on hcdnc316 (3/10)%%0001017/07/18 00:25:36 INFO ExecutorAllocationManager: Requesting 2 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 399 ms on hcdnc823 (4/10)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc316, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 393 ms on hcdnc316 (5/10)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 360 ms on hcdnc823 (6/10)%%0001017/07/18 00:25:37 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc316, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:37 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 399 ms on hcdnc316 (7/10)%%0001017/07/18 00:25:37 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:37 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 574 ms on hcdnc823 (8/10)%%0001017/07/18 00:25:37 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 402 ms on hcdnc316 (9/10)%%0001017/07/18 00:25:38 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 566 ms on hcdnc823 (10/10)%%0001017/07/18 00:25:38 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:38 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.518 s%%0001017/07/18 00:25:38 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 14.629216 s%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:25:38 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:25:38 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:25:38 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:25:38 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:25:38 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:25:38 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:25:38 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37659] &lt;- [akka.tcp://sparkExecutor@hcdnc823:48750]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc823:48750] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc823:48750%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:25:38 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37659] &lt;- [akka.tcp://sparkExecutor@hcdnc316:53852]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc316:53852] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc316:53852%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:25:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:25:38 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:25:38 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:25:38 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:25:38 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:25:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:25:38 INFO Remoting: Remoting shut down%%0001017/07/18 00:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:25:39 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:25:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-73eb15c7-f5e4-4194-b169-d63121342d43%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:25:52 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:25:54 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:25:54 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:25:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:25:54 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:25:54 INFO Remoting: Starting remoting%%0001017/07/18 00:25:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38802]%%0001017/07/18 00:25:54 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38802]%%0001017/07/18 00:25:54 INFO Utils: Successfully started service 'sparkDriver' on port 38802.%%0001017/07/18 00:25:54 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:25:54 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:25:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-41ef7b83-9984-436e-89cd-d5d709cb5c98%%0001017/07/18 00:25:54 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:25:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-4cd27c74-f47e-4f7b-9482-a778d468c37e/httpd-7ff2b5c9-0540-4dd9-93df-5ac8073e2da6%%0001017/07/18 00:25:54 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:25:54 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:25:54 INFO AbstractConnector: Started SocketConnector@0.0.0.0:42268%%0001017/07/18 00:25:54 INFO Utils: Successfully started service 'HTTP file server' on port 42268.%%0001017/07/18 00:25:54 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:25:55 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:25:55 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:25:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:25:55 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:25:55 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:25:55 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:25:55 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:25:56 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:25:56 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:25:56 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:25:56 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:25:56 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:25:56 INFO Client: Uploading resource file:/tmp/spark-4cd27c74-f47e-4f7b-9482-a778d468c37e/__spark_conf__1057274651183876044.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22107/__spark_conf__1057274651183876044.zip%%0001017/07/18 00:25:56 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:25:56 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:25:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:25:56 INFO Client: Submitting application 22107 to ResourceManager%%0001017/07/18 00:25:57 INFO YarnClientImpl: Submitted application application_1491786134915_22107%%0001017/07/18 00:25:58 INFO Client: Application report for application_1491786134915_22107 (state: ACCEPTED)%%0001017/07/18 00:25:58 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308756865%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22107/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:25:59 INFO Client: Application report for application_1491786134915_22107 (state: ACCEPTED)%%0001017/07/18 00:25:59 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:35220/user/YarnAM#676870486])%%0001017/07/18 00:25:59 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22107,http://hcnnc117:8088/proxy/application_1491786134915_22107), /proxy/application_1491786134915_22107%%0001017/07/18 00:25:59 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:26:00 INFO Client: Application report for application_1491786134915_22107 (state: RUNNING)%%0001017/07/18 00:26:00 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308756865%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22107/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:26:00 INFO YarnClientSchedulerBackend: Application application_1491786134915_22107 has started running.%%0001017/07/18 00:26:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36677.%%0001017/07/18 00:26:00 INFO NettyBlockTransferService: Server created on 36677%%0001017/07/18 00:26:00 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:26:00 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:26:00 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:36677 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 36677)%%0001017/07/18 00:26:00 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:26:00 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22107%%0001017/07/18 00:26:00 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:26:01 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:26:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:26:01 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:26:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:26:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:36677 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:26:01 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:26:01 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.30:50010%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.24:50010%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.37:50010%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.17:50010%%0001017/07/18 00:26:01 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:26:01 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:26:01 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:26:01 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:26:01 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:26:01 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:26:01 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:26:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:26:01 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:26:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:26:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:36677 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:26:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:26:01 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:26:02 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:26:03 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:26:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38802] &lt;- [akka.tcp://driverPropsFetcher@hcdnc325:40844]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc325:40844] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc325:40844%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:26:05 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc325:36717/user/Executor#-1644048041]) with ID 1%%0001017/07/18 00:26:05 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:26:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc325, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:26:05 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc325:45123 with 530.0 MB RAM, BlockManagerId(1, hcdnc325, 45123)%%0001017/07/18 00:26:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38802] &lt;- [akka.tcp://driverPropsFetcher@hcdnc821:47379]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc821:47379] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc821:47379%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:26:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc325:45123 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:26:06 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc821:40992/user/Executor#-380674388]) with ID 2%%0001017/07/18 00:26:06 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:26:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc821, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:26:06 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc821:39191 with 530.0 MB RAM, BlockManagerId(2, hcdnc821, 39191)%%0001017/07/18 00:26:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc325:45123 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:26:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc821:39191 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:26:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc821:39191 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:26:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11810 ms on hcdnc325 (1/2)%%0001017/07/18 00:26:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12514 ms on hcdnc821 (2/2)%%0001017/07/18 00:26:18 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 17.121 s%%0001017/07/18 00:26:18 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:18 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.245811 s%%0001017/07/18 00:26:18 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:26:18 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:26:18 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:26:18 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:26:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:26:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:26:18 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:26:18 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:26:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:26:18 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:26:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:26:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:36677 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:26:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:26:18 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:26:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc821, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:26:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc325, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:26:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc821:39191 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:26:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc325:45123 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:26:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17325 ms on hcdnc821 (1/2)%%0001017/07/18 00:26:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17422 ms on hcdnc325 (2/2)%%0001017/07/18 00:26:36 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:36 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.424 s%%0001017/07/18 00:26:36 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:26:36 INFO DAGScheduler: running: Set()%%0001017/07/18 00:26:36 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:26:36 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:26:36 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:26:36 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:26:36 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:26:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:26:36 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:26:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:26:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:36677 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:26:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:26:36 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:26:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc821, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc325:45123 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:26:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc821:39191 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:26:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc325:36717%%0001017/07/18 00:26:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:26:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc821:40992%%0001017/07/18 00:26:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1354 ms on hcdnc821 (1/2)%%0001017/07/18 00:26:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1438 ms on hcdnc325 (2/2)%%0001017/07/18 00:26:37 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:37 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.440 s%%0001017/07/18 00:26:37 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 18.895198 s%%0001017/07/18 00:26:37 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:26:37 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:26:37 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:26:37 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:26:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:26:37 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:26:37 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:26:37 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:26:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:26:37 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:26:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:26:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:36677 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:26:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:26:37 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:26:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc821, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:37 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc325:45123 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:26:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc821:39191 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:26:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2583 ms on hcdnc821 (1/2)%%0001017/07/18 00:26:40 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2829 ms on hcdnc325 (2/2)%%0001017/07/18 00:26:40 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:40 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.830 s%%0001017/07/18 00:26:40 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.860712 s%%0001017/07/18 00:26:40 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:26:40 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:26:40 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:26:40 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:26:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:26:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:26:40 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:26:40 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:26:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:26:40 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:26:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:26:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:36677 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:26:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:26:40 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:26:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc821, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:26:40 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc325, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:26:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc821:39191 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:26:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc325:45123 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2632 ms on hcdnc821 (1/2)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2871 ms on hcdnc325 (2/2)%%0001017/07/18 00:26:43 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:43 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.872 s%%0001017/07/18 00:26:43 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:26:43 INFO DAGScheduler: running: Set()%%0001017/07/18 00:26:43 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:26:43 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:26:43 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:26:43 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:26:43 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:26:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:26:43 INFO MemoryStore: ensureFreeSpace(1614) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:26:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1614.0 B, free 530.0 MB)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:36677 (size: 1614.0 B, free: 530.2 MB)%%0001017/07/18 00:26:43 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:43 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:26:43 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc821, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc325:45123 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc821:39191 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc821:40992%%0001017/07/18 00:26:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:26:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc325:36717%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc821, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 50 ms on hcdnc821 (1/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc325, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 57 ms on hcdnc325 (2/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc821, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc821 (3/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc325, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc325 (4/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc821, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc821 (5/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc325, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc325 (6/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc821, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc821 (7/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc325, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc325 (8/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc821 (9/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc325 (10/10)%%0001017/07/18 00:26:43 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.115 s%%0001017/07/18 00:26:43 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:43 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 3.007737 s%%0001017/07/18 00:26:43 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:26:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:26:43 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:26:43 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:26:43 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:26:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:26:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:26:43 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:26:43 INFO MemoryStore: ensureFreeSpace(12936) called with curMem=288481, maxMem=556038881%%0001017/07/18 00:26:43 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 530.0 MB)%%0001017/07/18 00:26:43 INFO MemoryStore: ensureFreeSpace(7135) called with curMem=301417, maxMem=556038881%%0001017/07/18 00:26:43 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:36677 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 00:26:43 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:26:43 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc325, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc821, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc325:45123 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc821:39191 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc821:40992%%0001017/07/18 00:26:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc325:36717%%0001017/07/18 00:26:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 11414 ms on hcdnc325 (1/2)%%0001017/07/18 00:26:56 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 12393 ms on hcdnc821 (2/2)%%0001017/07/18 00:26:56 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:56 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 12.395 s%%0001017/07/18 00:26:56 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:26:56 INFO DAGScheduler: running: Set()%%0001017/07/18 00:26:56 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:26:56 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:26:56 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:26:56 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:26:56 INFO MemoryStore: ensureFreeSpace(16008) called with curMem=308552, maxMem=556038881%%0001017/07/18 00:26:56 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.6 KB, free 530.0 MB)%%0001017/07/18 00:26:56 INFO MemoryStore: ensureFreeSpace(8481) called with curMem=324560, maxMem=556038881%%0001017/07/18 00:26:56 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 00:26:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:36677 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 00:26:56 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:56 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:26:56 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:26:56 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc325, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:56 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc821, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc821:39191 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:26:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc325:45123 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:26:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc821:40992%%0001017/07/18 00:26:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 163 bytes%%0001017/07/18 00:26:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc325:36717%%0001017/07/18 00:26:56 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc821, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:56 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 538 ms on hcdnc821 (1/10)%%0001017/07/18 00:26:56 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc325, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:56 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 622 ms on hcdnc325 (2/10)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc325, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 353 ms on hcdnc325 (3/10)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc821, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 447 ms on hcdnc821 (4/10)%%0001017/07/18 00:26:57 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc821, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 353 ms on hcdnc821 (5/10)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc325, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 422 ms on hcdnc325 (6/10)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc821, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 436 ms on hcdnc821 (7/10)%%0001017/07/18 00:26:58 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc325, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:58 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 434 ms on hcdnc325 (8/10)%%0001017/07/18 00:26:58 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 432 ms on hcdnc821 (9/10)%%0001017/07/18 00:26:58 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 459 ms on hcdnc325 (10/10)%%0001017/07/18 00:26:58 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:58 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.287 s%%0001017/07/18 00:26:58 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 14.709158 s%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:26:58 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:26:58 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:26:58 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:26:58 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:26:58 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:26:58 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:26:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38802] &lt;- [akka.tcp://sparkExecutor@hcdnc821:40992]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc821:40992] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc821:40992%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:26:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38802] &lt;- [akka.tcp://sparkExecutor@hcdnc325:36717]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc325:36717] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc325:36717%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:26:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:26:58 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:26:58 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:26:58 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:26:58 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:26:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:26:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:26:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:26:58 INFO Remoting: Remoting shut down%%0001017/07/18 00:26:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:26:59 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:26:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-4cd27c74-f47e-4f7b-9482-a778d468c37e/pyspark-2992b9cb-4634-465b-8e73-45cea7e2b774%%0001017/07/18 00:26:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-4cd27c74-f47e-4f7b-9482-a778d468c37e%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:27:13 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:27:14 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:27:14 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:27:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:27:14 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:27:14 INFO Remoting: Starting remoting%%0001017/07/18 00:27:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:43598]%%0001017/07/18 00:27:15 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:43598]%%0001017/07/18 00:27:15 INFO Utils: Successfully started service 'sparkDriver' on port 43598.%%0001017/07/18 00:27:15 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:27:15 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:27:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eb9669bc-b328-489b-9ea6-cf3eb8e905ee%%0001017/07/18 00:27:15 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:27:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-24a2deda-c091-4543-ac3d-532703775810/httpd-7abdfb4b-f6d6-44bf-a5be-18185be8a27d%%0001017/07/18 00:27:15 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:27:15 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:27:15 INFO AbstractConnector: Started SocketConnector@0.0.0.0:36687%%0001017/07/18 00:27:15 INFO Utils: Successfully started service 'HTTP file server' on port 36687.%%0001017/07/18 00:27:15 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:27:15 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:27:15 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:27:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:27:15 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:27:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:27:16 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:27:16 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:27:16 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:27:16 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:27:16 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:27:16 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:27:16 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:27:16 INFO Client: Uploading resource file:/tmp/spark-24a2deda-c091-4543-ac3d-532703775810/__spark_conf__2757115580511688243.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22108/__spark_conf__2757115580511688243.zip%%0001017/07/18 00:27:17 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:27:17 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:27:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:27:17 INFO Client: Submitting application 22108 to ResourceManager%%0001017/07/18 00:27:17 INFO YarnClientImpl: Submitted application application_1491786134915_22108%%0001017/07/18 00:27:18 INFO Client: Application report for application_1491786134915_22108 (state: ACCEPTED)%%0001017/07/18 00:27:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308837118%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22108/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:27:19 INFO Client: Application report for application_1491786134915_22108 (state: ACCEPTED)%%0001017/07/18 00:27:20 INFO Client: Application report for application_1491786134915_22108 (state: ACCEPTED)%%0001017/07/18 00:27:20 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:46137/user/YarnAM#-1684706552])%%0001017/07/18 00:27:20 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22108,http://hcnnc117:8088/proxy/application_1491786134915_22108), /proxy/application_1491786134915_22108%%0001017/07/18 00:27:20 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:27:21 INFO Client: Application report for application_1491786134915_22108 (state: RUNNING)%%0001017/07/18 00:27:21 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308837118%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22108/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:27:21 INFO YarnClientSchedulerBackend: Application application_1491786134915_22108 has started running.%%0001017/07/18 00:27:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46059.%%0001017/07/18 00:27:22 INFO NettyBlockTransferService: Server created on 46059%%0001017/07/18 00:27:22 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:27:22 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:27:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:46059 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 46059)%%0001017/07/18 00:27:22 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:27:22 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22108%%0001017/07/18 00:27:22 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:27:23 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:27:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:27:23 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:27:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:27:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:46059 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:27:23 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:27:23 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.39:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.9:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.17:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.30:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.12:50010%%0001017/07/18 00:27:23 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:27:23 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:27:23 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:27:23 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:27:23 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:27:23 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:27:23 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:27:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:27:23 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:27:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:27:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:46059 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:27:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:27:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:27:23 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:27:24 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:27:25 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:27:26 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:43598] &lt;- [akka.tcp://driverPropsFetcher@hcdnc330:52858]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc330:52858] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc330:52858%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:27:27 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc330:57000/user/Executor#1229962320]) with ID 1%%0001017/07/18 00:27:27 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:27:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc330, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:27:27 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc330:40679 with 530.0 MB RAM, BlockManagerId(1, hcdnc330, 40679)%%0001017/07/18 00:27:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc330:40679 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:27:27 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:43598] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:59288]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:59288] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:59288%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:27:27 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:36720/user/Executor#1741661093]) with ID 2%%0001017/07/18 00:27:27 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:27:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:27:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc330:40679 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:27:28 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:34029 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 34029)%%0001017/07/18 00:27:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:34029 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:27:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:34029 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:27:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12083 ms on hcdnc330 (1/2)%%0001017/07/18 00:27:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11722 ms on hcdnc310 (2/2)%%0001017/07/18 00:27:39 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.333 s%%0001017/07/18 00:27:39 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:27:39 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.478652 s%%0001017/07/18 00:27:39 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:27:39 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:27:39 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:27:39 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:27:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:27:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:27:39 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:27:39 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:27:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:27:39 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:27:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:27:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:46059 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:27:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:27:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:27:39 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:27:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc330, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:27:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:27:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc330:40679 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:27:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:34029 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:27:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17322 ms on hcdnc330 (1/2)%%0001017/07/18 00:27:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17614 ms on hcdnc310 (2/2)%%0001017/07/18 00:27:57 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:27:57 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.616 s%%0001017/07/18 00:27:57 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:27:57 INFO DAGScheduler: running: Set()%%0001017/07/18 00:27:57 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:27:57 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:27:57 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:27:57 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:27:57 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:27:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:27:57 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:27:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:27:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:46059 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:27:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:27:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:27:57 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:27:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc330, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:27:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:27:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc330:40679 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:27:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:34029 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:27:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc330:57000%%0001017/07/18 00:27:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 00:27:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:36720%%0001017/07/18 00:27:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1416 ms on hcdnc330 (1/2)%%0001017/07/18 00:27:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1492 ms on hcdnc310 (2/2)%%0001017/07/18 00:27:58 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:27:58 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.495 s%%0001017/07/18 00:27:58 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.141499 s%%0001017/07/18 00:27:58 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:27:58 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:27:58 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:27:58 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:27:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:27:58 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:27:58 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:27:58 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:27:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:27:58 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:27:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:27:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:46059 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:27:58 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:27:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:27:58 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:27:58 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc330, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:27:58 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:27:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:34029 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:27:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc330:40679 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:28:01 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2714 ms on hcdnc330 (1/2)%%0001017/07/18 00:28:01 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2739 ms on hcdnc310 (2/2)%%0001017/07/18 00:28:01 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:01 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.741 s%%0001017/07/18 00:28:01 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.753667 s%%0001017/07/18 00:28:01 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:28:01 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:28:01 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:28:01 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:28:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:28:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:28:01 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:28:01 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:28:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:28:01 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:28:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:28:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:46059 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:28:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:28:01 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:28:01 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:28:01 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc330, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:28:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc330:40679 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:28:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:34029 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2709 ms on hcdnc310 (1/2)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2845 ms on hcdnc330 (2/2)%%0001017/07/18 00:28:04 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:04 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.846 s%%0001017/07/18 00:28:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:28:04 INFO DAGScheduler: running: Set()%%0001017/07/18 00:28:04 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:28:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:28:04 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:28:04 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:28:04 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:28:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:28:04 INFO MemoryStore: ensureFreeSpace(1614) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:28:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1614.0 B, free 530.0 MB)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:46059 (size: 1614.0 B, free: 530.2 MB)%%0001017/07/18 00:28:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:28:04 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc330, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc330:40679 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:34029 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc330:57000%%0001017/07/18 00:28:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 164 bytes%%0001017/07/18 00:28:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:36720%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc330, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 41 ms on hcdnc330 (1/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 50 ms on hcdnc310 (2/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc330, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc330 (3/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc310 (4/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc330, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc330 (5/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc330, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc330 (6/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 21 ms on hcdnc310 (7/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc330, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc330 (8/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 16 ms on hcdnc310 (9/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 15 ms on hcdnc330 (10/10)%%0001017/07/18 00:28:04 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.111 s%%0001017/07/18 00:28:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:04 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.978699 s%%0001017/07/18 00:28:04 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:28:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 00:28:04 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:28:04 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:28:04 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:28:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:28:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:28:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:28:04 INFO MemoryStore: ensureFreeSpace(12936) called with curMem=288481, maxMem=556038881%%0001017/07/18 00:28:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 530.0 MB)%%0001017/07/18 00:28:04 INFO MemoryStore: ensureFreeSpace(7135) called with curMem=301417, maxMem=556038881%%0001017/07/18 00:28:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:46059 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 00:28:04 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:28:04 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc330, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:34029 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc330:40679 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc330:57000%%0001017/07/18 00:28:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:36720%%0001017/07/18 00:28:15 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 10989 ms on hcdnc310 (1/2)%%0001017/07/18 00:28:15 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 11027 ms on hcdnc330 (2/2)%%0001017/07/18 00:28:15 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:15 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 11.029 s%%0001017/07/18 00:28:15 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:28:15 INFO DAGScheduler: running: Set()%%0001017/07/18 00:28:15 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:28:15 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:28:15 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:28:15 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:28:15 INFO MemoryStore: ensureFreeSpace(16008) called with curMem=308552, maxMem=556038881%%0001017/07/18 00:28:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.6 KB, free 530.0 MB)%%0001017/07/18 00:28:15 INFO MemoryStore: ensureFreeSpace(8481) called with curMem=324560, maxMem=556038881%%0001017/07/18 00:28:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 00:28:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:46059 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 00:28:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:28:15 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:28:15 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:15 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc330, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:34029 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:28:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc330:40679 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:28:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc330:57000%%0001017/07/18 00:28:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:28:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:36720%%0001017/07/18 00:28:16 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc330, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:16 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 621 ms on hcdnc330 (1/10)%%0001017/07/18 00:28:16 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:16 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 702 ms on hcdnc310 (2/10)%%0001017/07/18 00:28:16 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:28:16 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc330, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:16 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 449 ms on hcdnc330 (3/10)%%0001017/07/18 00:28:16 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:16 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 372 ms on hcdnc310 (4/10)%%0001017/07/18 00:28:17 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:17 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 398 ms on hcdnc310 (5/10)%%0001017/07/18 00:28:17 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc330, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:17 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 437 ms on hcdnc330 (6/10)%%0001017/07/18 00:28:17 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc330, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:17 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 431 ms on hcdnc330 (7/10)%%0001017/07/18 00:28:17 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:17 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 519 ms on hcdnc310 (8/10)%%0001017/07/18 00:28:18 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 421 ms on hcdnc330 (9/10)%%0001017/07/18 00:28:18 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 458 ms on hcdnc310 (10/10)%%0001017/07/18 00:28:18 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:18 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.445 s%%0001017/07/18 00:28:18 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 13.516972 s%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:28:18 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:28:18 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:28:18 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:28:18 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:28:18 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:28:18 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:28:18 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:43598] &lt;- [akka.tcp://sparkExecutor@hcdnc310:36720]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:36720] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:36720%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:28:18 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:43598] &lt;- [akka.tcp://sparkExecutor@hcdnc330:57000]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc330:57000] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc330:57000%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:28:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:28:18 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:28:18 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:28:18 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:28:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:28:18 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:28:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:28:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:28:18 INFO Remoting: Remoting shut down%%0001017/07/18 00:28:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:28:19 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:28:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-24a2deda-c091-4543-ac3d-532703775810%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:28:33 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:28:34 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:28:34 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:28:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:28:34 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:28:34 INFO Remoting: Starting remoting%%0001017/07/18 00:28:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:39596]%%0001017/07/18 00:28:34 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:39596]%%0001017/07/18 00:28:34 INFO Utils: Successfully started service 'sparkDriver' on port 39596.%%0001017/07/18 00:28:34 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:28:34 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:28:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7a1f30f8-b8ee-4402-a589-edf9049861a4%%0001017/07/18 00:28:35 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:28:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-2e6972b4-ab35-4126-8f6f-f336737ab153/httpd-e13be6d7-6fc0-426f-a128-25d3b795e6ca%%0001017/07/18 00:28:35 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:28:35 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:28:35 INFO AbstractConnector: Started SocketConnector@0.0.0.0:44700%%0001017/07/18 00:28:35 INFO Utils: Successfully started service 'HTTP file server' on port 44700.%%0001017/07/18 00:28:35 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:28:35 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:28:35 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:28:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:28:35 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:28:36 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:28:36 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:28:36 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:28:36 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:28:36 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:28:36 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:28:36 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:28:36 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:28:36 INFO Client: Uploading resource file:/tmp/spark-2e6972b4-ab35-4126-8f6f-f336737ab153/__spark_conf__7109189492097715323.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22109/__spark_conf__7109189492097715323.zip%%0001017/07/18 00:28:37 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:28:37 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:28:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:28:37 INFO Client: Submitting application 22109 to ResourceManager%%0001017/07/18 00:28:37 INFO YarnClientImpl: Submitted application application_1491786134915_22109%%0001017/07/18 00:28:38 INFO Client: Application report for application_1491786134915_22109 (state: ACCEPTED)%%0001017/07/18 00:28:38 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308917082%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22109/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:28:39 INFO Client: Application report for application_1491786134915_22109 (state: ACCEPTED)%%0001017/07/18 00:28:40 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.11:50173/user/YarnAM#-598983920])%%0001017/07/18 00:28:40 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22109,http://hcnnc117:8088/proxy/application_1491786134915_22109), /proxy/application_1491786134915_22109%%0001017/07/18 00:28:40 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:28:40 INFO Client: Application report for application_1491786134915_22109 (state: ACCEPTED)%%0001017/07/18 00:28:41 INFO Client: Application report for application_1491786134915_22109 (state: RUNNING)%%0001017/07/18 00:28:41 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.11%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308917082%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22109/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:28:41 INFO YarnClientSchedulerBackend: Application application_1491786134915_22109 has started running.%%0001017/07/18 00:28:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40102.%%0001017/07/18 00:28:41 INFO NettyBlockTransferService: Server created on 40102%%0001017/07/18 00:28:41 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:28:41 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:28:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:40102 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 40102)%%0001017/07/18 00:28:41 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:28:41 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22109%%0001017/07/18 00:28:41 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:28:42 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:28:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:28:42 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:28:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:28:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:40102 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:28:42 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:28:42 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.24:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.31:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.31:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.29:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.16:50010%%0001017/07/18 00:28:42 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:28:42 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:28:42 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:28:42 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:28:42 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:28:42 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:28:42 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:28:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:28:42 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:28:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:28:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:40102 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:28:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:28:42 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:28:43 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:28:44 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:28:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:39596] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:59865]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:59865] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:59865%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:28:46 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:50642/user/Executor#-633583132]) with ID 1%%0001017/07/18 00:28:46 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:28:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:28:46 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:39840 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 39840)%%0001017/07/18 00:28:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:39596] &lt;- [akka.tcp://driverPropsFetcher@hcdnc306:51940]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:51940] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:51940%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:28:46 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc306:41062/user/Executor#-1490934676]) with ID 2%%0001017/07/18 00:28:47 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:28:47 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc306:60560 with 530.0 MB RAM, BlockManagerId(2, hcdnc306, 60560)%%0001017/07/18 00:28:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc306, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:28:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:39840 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:28:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc306:60560 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:28:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:39840 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:28:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc306:60560 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:28:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12308 ms on hcdnc310 (1/2)%%0001017/07/18 00:28:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11904 ms on hcdnc306 (2/2)%%0001017/07/18 00:28:59 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.722 s%%0001017/07/18 00:28:59 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:59 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.866564 s%%0001017/07/18 00:28:59 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:28:59 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:28:59 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:28:59 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:28:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:28:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:28:59 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:28:59 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:28:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:28:59 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:28:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:28:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:40102 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:28:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:28:59 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:28:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc306, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:28:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:28:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc306:60560 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:28:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:39840 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:29:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17219 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17425 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:16 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:16 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.427 s%%0001017/07/18 00:29:16 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:29:16 INFO DAGScheduler: running: Set()%%0001017/07/18 00:29:16 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:29:16 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:29:16 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:29:16 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:29:16 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:29:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:29:16 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:29:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:29:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:40102 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:29:16 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:29:16 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:29:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc306:60560 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:29:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:39840 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:29:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:41062%%0001017/07/18 00:29:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:29:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:50642%%0001017/07/18 00:29:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1370 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1455 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:18 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:18 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.457 s%%0001017/07/18 00:29:18 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 18.915144 s%%0001017/07/18 00:29:18 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:29:18 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:29:18 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:29:18 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:29:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:29:18 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:29:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:29:18 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:29:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:29:18 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:29:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:29:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:40102 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:29:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:29:18 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:29:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:18 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:39840 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:29:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc306:60560 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:29:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2610 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:20 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2759 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:20 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:20 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.760 s%%0001017/07/18 00:29:20 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.775384 s%%0001017/07/18 00:29:20 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:29:20 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:29:20 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:29:20 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:29:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:29:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:29:20 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:29:20 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:29:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:29:20 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:29:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:29:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:40102 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:29:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:29:20 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:29:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:29:20 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc306, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:29:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:39840 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:29:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc306:60560 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2696 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2722 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:23 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:23 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.724 s%%0001017/07/18 00:29:23 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:29:23 INFO DAGScheduler: running: Set()%%0001017/07/18 00:29:23 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:29:23 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:29:23 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:29:23 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:29:23 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:29:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:29:23 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:29:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:40102 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:29:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:23 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:29:23 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc306:60560 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:39840 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc306:41062%%0001017/07/18 00:29:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:29:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:50642%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc306, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc310 (1/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 46 ms on hcdnc306 (2/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc306, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc310 (3/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc306 (4/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc310 (5/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc306, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc306 (6/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc310 (7/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc306, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 14 ms on hcdnc306 (8/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc310 (9/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc306 (10/10)%%0001017/07/18 00:29:23 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:29:23 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:23 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.847861 s%%0001017/07/18 00:29:23 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:29:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:29:23 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:29:23 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:29:23 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:29:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:29:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:29:23 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:29:23 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288480, maxMem=556038881%%0001017/07/18 00:29:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:29:23 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300720, maxMem=556038881%%0001017/07/18 00:29:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:40102 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:29:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:29:23 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc306, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc306:60560 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:39840 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:41062%%0001017/07/18 00:29:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:50642%%0001017/07/18 00:29:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 9753 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10223 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:34 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:34 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.225 s%%0001017/07/18 00:29:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:29:34 INFO DAGScheduler: running: Set()%%0001017/07/18 00:29:34 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:29:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:29:34 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:29:34 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:29:34 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307467, maxMem=556038881%%0001017/07/18 00:29:34 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:29:34 INFO MemoryStore: ensureFreeSpace(7999) called with curMem=322627, maxMem=556038881%%0001017/07/18 00:29:34 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:29:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:40102 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:29:34 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:34 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:29:34 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:39840 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:29:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc306:60560 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:29:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:50642%%0001017/07/18 00:29:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 157 bytes%%0001017/07/18 00:29:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc306:41062%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc306, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 430 ms on hcdnc306 (1/10)%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 458 ms on hcdnc310 (2/10)%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 329 ms on hcdnc310 (3/10)%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc306, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 364 ms on hcdnc306 (4/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc306, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 264 ms on hcdnc306 (5/10)%%0001017/07/18 00:29:35 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:29:35 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 289 ms on hcdnc310 (6/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc306, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 301 ms on hcdnc306 (7/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 342 ms on hcdnc310 (8/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 291 ms on hcdnc306 (9/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 327 ms on hcdnc310 (10/10)%%0001017/07/18 00:29:35 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:35 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.744 s%%0001017/07/18 00:29:35 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 11.993336 s%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:29:35 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:29:35 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:29:35 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:29:35 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:29:35 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:29:36 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:29:36 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:39596] &lt;- [akka.tcp://sparkExecutor@hcdnc310:50642]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:50642] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:50642%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:29:36 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:39596] &lt;- [akka.tcp://sparkExecutor@hcdnc306:41062]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc306:41062] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc306:41062%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:29:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:29:36 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:29:36 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:29:36 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:29:36 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:29:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:29:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:29:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:29:36 INFO Remoting: Remoting shut down%%0001017/07/18 00:29:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:29:37 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:29:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-2e6972b4-ab35-4126-8f6f-f336737ab153/pyspark-401c86a6-32ef-48be-9322-bf5d3e795ed1%%0001017/07/18 00:29:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-2e6972b4-ab35-4126-8f6f-f336737ab153%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:29:50 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:29:51 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:29:51 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:29:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:29:51 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:29:51 INFO Remoting: Starting remoting%%0001017/07/18 00:29:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:40473]%%0001017/07/18 00:29:52 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:40473]%%0001017/07/18 00:29:52 INFO Utils: Successfully started service 'sparkDriver' on port 40473.%%0001017/07/18 00:29:52 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:29:52 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:29:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a3c7c9c1-a98b-46be-82b9-721f621d8b9f%%0001017/07/18 00:29:52 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:29:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3f3a6aaa-45f4-405c-a207-6a863176a7c9/httpd-fe177d3a-e3a9-4931-bfbc-831f4e39aa0d%%0001017/07/18 00:29:52 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:29:52 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:29:52 INFO AbstractConnector: Started SocketConnector@0.0.0.0:39996%%0001017/07/18 00:29:52 INFO Utils: Successfully started service 'HTTP file server' on port 39996.%%0001017/07/18 00:29:52 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:29:53 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:29:53 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:29:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:29:53 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:29:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:29:53 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:29:53 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:29:53 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:29:53 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:29:53 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:29:53 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:29:53 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:29:53 INFO Client: Uploading resource file:/tmp/spark-3f3a6aaa-45f4-405c-a207-6a863176a7c9/__spark_conf__2778156201442387549.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22110/__spark_conf__2778156201442387549.zip%%0001017/07/18 00:29:54 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:29:54 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:29:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:29:54 INFO Client: Submitting application 22110 to ResourceManager%%0001017/07/18 00:29:54 INFO YarnClientImpl: Submitted application application_1491786134915_22110%%0001017/07/18 00:29:55 INFO Client: Application report for application_1491786134915_22110 (state: ACCEPTED)%%0001017/07/18 00:29:55 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308994322%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22110/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:29:56 INFO Client: Application report for application_1491786134915_22110 (state: ACCEPTED)%%0001017/07/18 00:29:57 INFO Client: Application report for application_1491786134915_22110 (state: ACCEPTED)%%0001017/07/18 00:29:57 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.13:54596/user/YarnAM#-2041315916])%%0001017/07/18 00:29:57 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22110,http://hcnnc117:8088/proxy/application_1491786134915_22110), /proxy/application_1491786134915_22110%%0001017/07/18 00:29:57 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:29:58 INFO Client: Application report for application_1491786134915_22110 (state: RUNNING)%%0001017/07/18 00:29:58 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.13%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308994322%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22110/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:29:58 INFO YarnClientSchedulerBackend: Application application_1491786134915_22110 has started running.%%0001017/07/18 00:29:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38098.%%0001017/07/18 00:29:58 INFO NettyBlockTransferService: Server created on 38098%%0001017/07/18 00:29:58 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:29:58 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:29:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:38098 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 38098)%%0001017/07/18 00:29:58 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:29:59 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22110%%0001017/07/18 00:29:59 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:29:59 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:29:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:29:59 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:29:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:29:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:38098 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:29:59 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:30:00 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.8:50010%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.30:50010%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.14:50010%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.32:50010%%0001017/07/18 00:30:00 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:30:00 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:30:00 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:30:00 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:30:00 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:30:00 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:30:00 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:30:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:30:00 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:30:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:30:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:38098 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:30:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:30:00 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:30:01 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:30:02 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:30:03 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40473] &lt;- [akka.tcp://driverPropsFetcher@hcdnc338:43711]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc338:43711] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc338:43711%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:30:04 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc338:37584/user/Executor#-776793589]) with ID 1%%0001017/07/18 00:30:04 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:30:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc338, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:30:04 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc338:33544 with 530.0 MB RAM, BlockManagerId(1, hcdnc338, 33544)%%0001017/07/18 00:30:04 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40473] &lt;- [akka.tcp://driverPropsFetcher@hcdnc211:43289]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc211:43289] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc211:43289%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:30:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc338:33544 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:30:05 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc211:38783/user/Executor#1727604213]) with ID 2%%0001017/07/18 00:30:05 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:30:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc211, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:30:05 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc211:58129 with 530.0 MB RAM, BlockManagerId(2, hcdnc211, 58129)%%0001017/07/18 00:30:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc338:33544 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:30:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc211:58129 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:30:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc211:58129 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:30:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12252 ms on hcdnc338 (1/2)%%0001017/07/18 00:30:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11740 ms on hcdnc211 (2/2)%%0001017/07/18 00:30:16 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.786 s%%0001017/07/18 00:30:16 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:16 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.908863 s%%0001017/07/18 00:30:17 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:30:17 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:30:17 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:30:17 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:30:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:30:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:30:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:30:17 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:30:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:30:17 INFO MemoryStore: ensureFreeSpace(5304) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:30:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:30:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:38098 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:30:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:30:17 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:30:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc211, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:30:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc338, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:30:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc211:58129 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:30:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc338:33544 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:30:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17344 ms on hcdnc338 (1/2)%%0001017/07/18 00:30:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17395 ms on hcdnc211 (2/2)%%0001017/07/18 00:30:34 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:34 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.395 s%%0001017/07/18 00:30:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:30:34 INFO DAGScheduler: running: Set()%%0001017/07/18 00:30:34 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:30:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:30:34 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:30:34 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:30:34 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251359, maxMem=556038881%%0001017/07/18 00:30:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:30:34 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258295, maxMem=556038881%%0001017/07/18 00:30:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:30:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:38098 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:30:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:30:34 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:30:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc338, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc211, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc211:58129 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:30:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc338:33544 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:30:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc211:38783%%0001017/07/18 00:30:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:30:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc338:37584%%0001017/07/18 00:30:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1419 ms on hcdnc338 (1/2)%%0001017/07/18 00:30:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1422 ms on hcdnc211 (2/2)%%0001017/07/18 00:30:35 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:35 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.423 s%%0001017/07/18 00:30:35 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 18.849706 s%%0001017/07/18 00:30:35 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:30:35 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:30:35 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:30:35 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:30:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:30:35 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:30:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:30:35 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262338, maxMem=556038881%%0001017/07/18 00:30:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:30:35 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268858, maxMem=556038881%%0001017/07/18 00:30:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:30:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:38098 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:30:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:30:35 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:30:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc211, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:35 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc338, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc211:58129 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:30:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc338:33544 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:30:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2727 ms on hcdnc211 (1/2)%%0001017/07/18 00:30:38 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2776 ms on hcdnc338 (2/2)%%0001017/07/18 00:30:38 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:38 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.777 s%%0001017/07/18 00:30:38 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.790647 s%%0001017/07/18 00:30:38 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:30:38 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:30:38 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:30:38 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:30:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:30:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:30:38 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:30:38 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272760, maxMem=556038881%%0001017/07/18 00:30:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:30:38 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279936, maxMem=556038881%%0001017/07/18 00:30:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:30:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:38098 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:30:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:30:38 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:30:38 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc211, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:30:38 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc338, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:30:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc211:58129 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:30:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc338:33544 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2811 ms on hcdnc338 (1/2)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2826 ms on hcdnc211 (2/2)%%0001017/07/18 00:30:41 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:41 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.827 s%%0001017/07/18 00:30:41 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:30:41 INFO DAGScheduler: running: Set()%%0001017/07/18 00:30:41 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:30:41 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:30:41 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:30:41 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:30:41 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284085, maxMem=556038881%%0001017/07/18 00:30:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:30:41 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286869, maxMem=556038881%%0001017/07/18 00:30:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:38098 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:30:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:30:41 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc211, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc338, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc338:33544 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc211:58129 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc338:37584%%0001017/07/18 00:30:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:30:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc211:38783%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc338, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc338 (1/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc211, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 50 ms on hcdnc211 (2/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc338, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc211, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 18 ms on hcdnc338 (3/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc211 (4/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc338, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc211, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc338 (5/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc211 (6/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc338, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc211, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc338 (7/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc211 (8/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc338 (9/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc211 (10/10)%%0001017/07/18 00:30:41 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.110 s%%0001017/07/18 00:30:41 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:41 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.958702 s%%0001017/07/18 00:30:41 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:30:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:30:41 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:30:41 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:30:41 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:30:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:30:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:30:41 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:30:41 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288482, maxMem=556038881%%0001017/07/18 00:30:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:30:41 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300722, maxMem=556038881%%0001017/07/18 00:30:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:38098 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:30:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:30:41 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc211, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc338, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc338:33544 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc211:58129 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc338:37584%%0001017/07/18 00:30:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc211:38783%%0001017/07/18 00:30:51 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 9518 ms on hcdnc211 (1/2)%%0001017/07/18 00:30:51 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10064 ms on hcdnc338 (2/2)%%0001017/07/18 00:30:51 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:51 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.065 s%%0001017/07/18 00:30:51 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:30:51 INFO DAGScheduler: running: Set()%%0001017/07/18 00:30:51 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:30:51 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:30:51 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:30:51 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:30:51 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307469, maxMem=556038881%%0001017/07/18 00:30:51 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:30:51 INFO MemoryStore: ensureFreeSpace(7998) called with curMem=322629, maxMem=556038881%%0001017/07/18 00:30:51 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:30:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:38098 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:30:51 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:51 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:30:51 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:30:51 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc338, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:51 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc211, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc338:33544 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:30:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc211:58129 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:30:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc338:37584%%0001017/07/18 00:30:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 158 bytes%%0001017/07/18 00:30:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc211:38783%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc338, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 500 ms on hcdnc338 (1/10)%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc211, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 586 ms on hcdnc211 (2/10)%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc338, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 305 ms on hcdnc338 (3/10)%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc211, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 293 ms on hcdnc211 (4/10)%%0001017/07/18 00:30:52 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc338, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 314 ms on hcdnc338 (5/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc211, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 284 ms on hcdnc211 (6/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc338, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 295 ms on hcdnc338 (7/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc211, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 337 ms on hcdnc211 (8/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 325 ms on hcdnc338 (9/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 329 ms on hcdnc211 (10/10)%%0001017/07/18 00:30:53 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:53 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.827 s%%0001017/07/18 00:30:53 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 11.937840 s%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:30:53 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:30:53 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:30:53 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:30:53 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:30:53 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:30:53 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:30:53 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40473] &lt;- [akka.tcp://sparkExecutor@hcdnc338:37584]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc338:37584] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc338:37584%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:30:53 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40473] &lt;- [akka.tcp://sparkExecutor@hcdnc211:38783]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc211:38783] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc211:38783%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:30:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:30:54 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:30:54 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:30:54 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:30:54 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:30:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:30:54 INFO Remoting: Remoting shut down%%0001017/07/18 00:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:30:54 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:30:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-3f3a6aaa-45f4-405c-a207-6a863176a7c9%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:31:08 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:31:09 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:09 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:31:09 INFO Remoting: Starting remoting%%0001017/07/18 00:31:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'sparkDriver' on port 46770.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:31:10 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:31:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b6392a2-47ca-486d-968a-86100bba3ed5%%0001017/07/18 00:31:10 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:31:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/httpd-35660a11-7a6a-4a04-b2a3-fc476816b481%%0001017/07/18 00:31:10 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:10 INFO AbstractConnector: Started SocketConnector@0.0.0.0:32841%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'HTTP file server' on port 32841.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:11 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:31:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:31:11 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:31:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:31:11 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:31:11 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:31:11 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:31:11 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:31:11 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:31:11 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:31:11 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:31:12 INFO Client: Uploading resource file:/tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/__spark_conf__6961910960617804988.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22111/__spark_conf__6961910960617804988.zip%%0001017/07/18 00:31:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:12 INFO Client: Submitting application 22111 to ResourceManager%%0001017/07/18 00:31:12 INFO YarnClientImpl: Submitted application application_1491786134915_22111%%0001017/07/18 00:31:13 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:13 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:14 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:15 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:51470/user/YarnAM#-1905692386])%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22111,http://hcnnc117:8088/proxy/application_1491786134915_22111), /proxy/application_1491786134915_22111%%0001017/07/18 00:31:15 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:31:15 INFO Client: Application report for application_1491786134915_22111 (state: RUNNING)%%0001017/07/18 00:31:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Application application_1491786134915_22111 has started running.%%0001017/07/18 00:31:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41687.%%0001017/07/18 00:31:15 INFO NettyBlockTransferService: Server created on 41687%%0001017/07/18 00:31:15 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:31:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41687 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41687)%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:31:16 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22111%%0001017/07/18 00:31:16 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41687 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:31:16 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.23:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.7:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.25:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.26:50010%%0001017/07/18 00:31:16 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:31:16 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:31:16 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:31:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:31:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:31:20 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:34646]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:20 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:56029/user/Executor#150168492]) with ID 1%%0001017/07/18 00:31:20 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:31:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc304, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:20 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:34185 with 530.0 MB RAM, BlockManagerId(1, hcdnc304, 34185)%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc336:54707]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:34185 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc336:34477/user/Executor#-848880720]) with ID 2%%0001017/07/18 00:31:21 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:31:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc336, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:21 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc336:44962 with 530.0 MB RAM, BlockManagerId(2, hcdnc336, 44962)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc336:44962 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12285 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12246 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 17.038 s%%0001017/07/18 00:31:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.158571 s%%0001017/07/18 00:31:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:31:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:31:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41687 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:31:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc304, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc336, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc336:44962 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:34185 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17613 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17625 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:51 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:51 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.628 s%%0001017/07/18 00:31:51 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:51 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:31:51 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:31:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:51 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1397 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1400 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.400 s%%0001017/07/18 00:31:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.060293 s%%0001017/07/18 00:31:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:31:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:31:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:31:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:31:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:31:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41687 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:31:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:31:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:34185 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc336:44962 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2566 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:56 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2767 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:56 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:56 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.769 s%%0001017/07/18 00:31:56 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.781932 s%%0001017/07/18 00:31:56 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:31:56 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:31:56 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:31:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41687 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:31:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc336:44962 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:34185 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2703 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2776 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.777 s%%0001017/07/18 00:31:58 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:58 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:31:58 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41687 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:31:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:31:58 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc336:44962 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:34185 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc336:34477%%0001017/07/18 00:31:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:56029%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc336, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc336 (1/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc304 (2/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc336, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc336 (3/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc304, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc304 (4/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc336, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc336 (5/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc304 (6/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc336, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc336 (7/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 12 ms on hcdnc304 (8/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc336 (9/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 12 ms on hcdnc304 (10/10)%%0001017/07/18 00:31:58 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.901611 s%%0001017/07/18 00:31:59 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:31:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:59 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:31:59 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:31:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288480, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300720, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41687 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:31:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc336:44962 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:34185 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 10438 ms on hcdnc336 (1/2)%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10676 ms on hcdnc304 (2/2)%%0001017/07/18 00:32:09 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:09 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.677 s%%0001017/07/18 00:32:09 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:32:09 INFO DAGScheduler: running: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:32:09 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307467, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(7999) called with curMem=322627, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41687 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:32:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:32:09 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:34185 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc336:44962 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc336:34477%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 444 ms on hcdnc304 (1/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc336, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 480 ms on hcdnc336 (2/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 313 ms on hcdnc304 (3/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc336, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 357 ms on hcdnc336 (4/10)%%0001017/07/18 00:32:10 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 356 ms on hcdnc304 (5/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc336, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 323 ms on hcdnc336 (6/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 286 ms on hcdnc304 (7/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc336, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 393 ms on hcdnc336 (8/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 322 ms on hcdnc304 (9/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 346 ms on hcdnc336 (10/10)%%0001017/07/18 00:32:11 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:11 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.894 s%%0001017/07/18 00:32:11 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 12.597608 s%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:32:11 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:32:11 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc336:34477]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc304:56029]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:32:11 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:32:11 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:32:11 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:32:11 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:32:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:32:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:32:12 INFO Remoting: Remoting shut down%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_1">
<entry key="column_name" type="xstring" value="FailingNodeMessage"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:20:13 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:20:13 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:20:13 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:20:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:20:15 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:20:15 INFO Remoting: Starting remoting%%0001017/07/18 00:20:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37866]%%0001017/07/18 00:20:15 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37866]%%0001017/07/18 00:20:15 INFO Utils: Successfully started service 'sparkDriver' on port 37866.%%0001017/07/18 00:20:15 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:20:15 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:20:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fec229ec-cac1-40d2-93e9-68f7e8622739%%0001017/07/18 00:20:15 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:20:16 INFO HttpFileServer: HTTP File server directory is /tmp/spark-6521cb87-2158-4374-9443-4c1c8aaa6e56/httpd-1e26b171-e529-4129-bf45-004d2fcbded7%%0001017/07/18 00:20:16 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:20:16 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:20:16 INFO AbstractConnector: Started SocketConnector@0.0.0.0:33890%%0001017/07/18 00:20:16 INFO Utils: Successfully started service 'HTTP file server' on port 33890.%%0001017/07/18 00:20:16 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:20:16 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:20:16 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:20:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:20:16 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:20:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:20:16 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:20:16 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:20:16 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:20:16 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:20:16 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:20:16 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:20:16 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:20:17 INFO Client: Uploading resource file:/tmp/spark-6521cb87-2158-4374-9443-4c1c8aaa6e56/__spark_conf__5110204394930781122.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22103/__spark_conf__5110204394930781122.zip%%0001017/07/18 00:20:17 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:20:17 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:20:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:20:17 INFO Client: Submitting application 22103 to ResourceManager%%0001017/07/18 00:20:17 INFO YarnClientImpl: Submitted application application_1491786134915_22103%%0001017/07/18 00:20:18 INFO Client: Application report for application_1491786134915_22103 (state: ACCEPTED)%%0001017/07/18 00:20:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308417636%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22103/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:20:19 INFO Client: Application report for application_1491786134915_22103 (state: ACCEPTED)%%0001017/07/18 00:20:20 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:33366/user/YarnAM#732571533])%%0001017/07/18 00:20:20 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22103,http://hcnnc117:8088/proxy/application_1491786134915_22103), /proxy/application_1491786134915_22103%%0001017/07/18 00:20:20 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:20:20 INFO Client: Application report for application_1491786134915_22103 (state: RUNNING)%%0001017/07/18 00:20:20 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308417636%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22103/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:20:20 INFO YarnClientSchedulerBackend: Application application_1491786134915_22103 has started running.%%0001017/07/18 00:20:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44216.%%0001017/07/18 00:20:20 INFO NettyBlockTransferService: Server created on 44216%%0001017/07/18 00:20:20 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:20:20 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:20:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:44216 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 44216)%%0001017/07/18 00:20:20 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:20:21 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22103%%0001017/07/18 00:20:22 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:20:22 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:20:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:20:22 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:20:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:20:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:44216 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:20:22 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:20:22 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.34:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.32:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.35:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.3:50010%%0001017/07/18 00:20:22 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.23:50010%%0001017/07/18 00:20:22 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:20:22 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:20:22 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:20:22 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:20:22 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:20:22 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:20:22 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:20:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:20:22 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:20:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:20:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:44216 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:20:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:20:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:20:22 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:20:23 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:20:24 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:20:26 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37866] &lt;- [akka.tcp://driverPropsFetcher@hcdnc213:34504]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc213:34504] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc213:34504%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:20:26 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc213:53498/user/Executor#-615378246]) with ID 1%%0001017/07/18 00:20:26 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:20:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc213, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:20:26 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc213:37680 with 530.0 MB RAM, BlockManagerId(1, hcdnc213, 37680)%%0001017/07/18 00:20:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc213:37680 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:20:27 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37866] &lt;- [akka.tcp://driverPropsFetcher@hcdnc306:37871]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:37871] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:37871%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:20:27 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc306:35465/user/Executor#1926258327]) with ID 2%%0001017/07/18 00:20:27 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:20:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc213:37680 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:20:27 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc306:44767 with 530.0 MB RAM, BlockManagerId(2, hcdnc306, 44767)%%0001017/07/18 00:20:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc306, partition 1,ANY, 2145 bytes)%%0001017/07/18 00:20:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc306:44767 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:20:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc306:44767 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:20:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11637 ms on hcdnc213 (1/2)%%0001017/07/18 00:20:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11633 ms on hcdnc306 (2/2)%%0001017/07/18 00:20:41 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 18.593 s%%0001017/07/18 00:20:41 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:20:41 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 18.741660 s%%0001017/07/18 00:20:41 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:20:41 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:20:41 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:20:41 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:20:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:20:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:20:41 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:20:41 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:20:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:20:41 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:20:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:20:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:44216 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:20:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:20:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:20:41 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:20:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc306, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:20:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc213, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:20:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc306:44767 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:20:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc213:37680 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:20:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17008 ms on hcdnc213 (1/2)%%0001017/07/18 00:20:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17312 ms on hcdnc306 (2/2)%%0001017/07/18 00:20:58 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:20:58 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.312 s%%0001017/07/18 00:20:58 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:20:58 INFO DAGScheduler: running: Set()%%0001017/07/18 00:20:58 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:20:58 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:20:58 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:20:58 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:20:58 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:20:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:20:58 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:20:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:20:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:44216 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:20:58 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:20:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:20:58 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:20:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:20:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc213, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:20:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc306:44767 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:20:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc213:37680 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:20:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:35465%%0001017/07/18 00:20:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:20:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc213:53498%%0001017/07/18 00:21:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1349 ms on hcdnc306 (1/2)%%0001017/07/18 00:21:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1377 ms on hcdnc213 (2/2)%%0001017/07/18 00:21:00 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:00 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.378 s%%0001017/07/18 00:21:00 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 18.722483 s%%0001017/07/18 00:21:00 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:21:00 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:21:00 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:21:00 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:21:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:21:00 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:21:00 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:21:00 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:21:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:21:00 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:21:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:21:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:44216 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:21:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:21:00 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:21:00 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:00 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc213, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc306:44767 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:21:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc213:37680 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:21:02 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2564 ms on hcdnc213 (1/2)%%0001017/07/18 00:21:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2603 ms on hcdnc306 (2/2)%%0001017/07/18 00:21:02 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:02 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.603 s%%0001017/07/18 00:21:02 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.617427 s%%0001017/07/18 00:21:02 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:21:02 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:21:02 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:21:02 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:21:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:21:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:21:02 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:21:02 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:21:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:21:02 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:21:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:21:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:44216 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:21:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:21:02 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:21:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc306, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:21:02 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc213, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:21:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc213:37680 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:21:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc306:44767 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2580 ms on hcdnc213 (1/2)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2591 ms on hcdnc306 (2/2)%%0001017/07/18 00:21:05 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:05 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.592 s%%0001017/07/18 00:21:05 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:21:05 INFO DAGScheduler: running: Set()%%0001017/07/18 00:21:05 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:21:05 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:21:05 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:21:05 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:21:05 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:21:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:21:05 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:21:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:44216 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 00:21:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:05 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:21:05 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc213, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc306, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc213:37680 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc306:44767 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc213:53498%%0001017/07/18 00:21:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:21:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc306:35465%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc306, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc213, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc306 (1/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc213 (2/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc306, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc213, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc306 (3/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc213 (4/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc306, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc306 (5/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc213, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc213 (6/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc306, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc306 (7/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc213, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc213 (8/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc306 (9/10)%%0001017/07/18 00:21:05 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc213 (10/10)%%0001017/07/18 00:21:05 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.105 s%%0001017/07/18 00:21:05 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:05 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.717496 s%%0001017/07/18 00:21:05 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:21:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:21:05 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:21:05 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:21:05 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:21:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:21:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:21:05 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:21:05 INFO MemoryStore: ensureFreeSpace(14024) called with curMem=288482, maxMem=556038881%%0001017/07/18 00:21:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:21:05 INFO MemoryStore: ensureFreeSpace(7740) called with curMem=302506, maxMem=556038881%%0001017/07/18 00:21:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:44216 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:21:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:21:05 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc306, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:21:05 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc213, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc213:37680 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc306:44767 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:21:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc213:53498%%0001017/07/18 00:21:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:35465%%0001017/07/18 00:21:18 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 12965 ms on hcdnc213 (1/2)%%0001017/07/18 00:21:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 13562 ms on hcdnc306 (2/2)%%0001017/07/18 00:21:19 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:19 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 13.563 s%%0001017/07/18 00:21:19 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:21:19 INFO DAGScheduler: running: Set()%%0001017/07/18 00:21:19 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:21:19 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:21:19 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:21:19 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:21:19 INFO MemoryStore: ensureFreeSpace(17344) called with curMem=310246, maxMem=556038881%%0001017/07/18 00:21:19 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.9 KB, free 530.0 MB)%%0001017/07/18 00:21:19 INFO MemoryStore: ensureFreeSpace(9233) called with curMem=327590, maxMem=556038881%%0001017/07/18 00:21:19 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 00:21:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:44216 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 00:21:19 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:19 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:21:19 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:21:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:19 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc213, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc306:44767 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:21:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc213:37680 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:21:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc306:35465%%0001017/07/18 00:21:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 165 bytes%%0001017/07/18 00:21:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc213:53498%%0001017/07/18 00:21:19 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc213, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:19 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 628 ms on hcdnc213 (1/10)%%0001017/07/18 00:21:20 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc306, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:20 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 707 ms on hcdnc306 (2/10)%%0001017/07/18 00:21:20 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:21:20 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc213, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:20 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 512 ms on hcdnc213 (3/10)%%0001017/07/18 00:21:20 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc306, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:20 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 558 ms on hcdnc306 (4/10)%%0001017/07/18 00:21:20 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc213, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:20 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 481 ms on hcdnc213 (5/10)%%0001017/07/18 00:21:21 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc306, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:21 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 470 ms on hcdnc306 (6/10)%%0001017/07/18 00:21:21 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 4)%%0001017/07/18 00:21:21 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc213, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:21 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 542 ms on hcdnc213 (7/10)%%0001017/07/18 00:21:21 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc306, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:21:21 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 583 ms on hcdnc306 (8/10)%%0001017/07/18 00:21:22 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 549 ms on hcdnc213 (9/10)%%0001017/07/18 00:21:22 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 534 ms on hcdnc306 (10/10)%%0001017/07/18 00:21:22 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:21:22 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.849 s%%0001017/07/18 00:21:22 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 16.438286 s%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:21:22 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:21:22 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:21:22 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:21:22 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:21:22 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:21:22 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:21:22 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:21:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37866] &lt;- [akka.tcp://sparkExecutor@hcdnc213:53498]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc213:53498] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc213:53498%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:21:22 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37866] &lt;- [akka.tcp://sparkExecutor@hcdnc306:35465]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc306:35465] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc306:35465%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:21:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:21:22 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:21:22 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:21:22 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:21:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:21:22 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:21:22 INFO Remoting: Remoting shut down%%0001017/07/18 00:21:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:21:23 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:21:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-6521cb87-2158-4374-9443-4c1c8aaa6e56/pyspark-a43a12f3-97d0-4c1f-aa22-65f43644c130%%0001017/07/18 00:21:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-6521cb87-2158-4374-9443-4c1c8aaa6e56%%00010"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:21:37 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:21:38 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:21:38 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:21:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:21:38 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:21:39 INFO Remoting: Starting remoting%%0001017/07/18 00:21:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:33819]%%0001017/07/18 00:21:39 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:33819]%%0001017/07/18 00:21:39 INFO Utils: Successfully started service 'sparkDriver' on port 33819.%%0001017/07/18 00:21:39 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:21:39 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:21:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-73372352-70b1-405d-8d6e-792a91b8c89f%%0001017/07/18 00:21:39 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:21:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-cb24707b-5060-466a-a599-2b5af5627c51/httpd-91578644-6daf-4d8b-9acf-49e6b88187d0%%0001017/07/18 00:21:39 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:21:39 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:21:39 INFO AbstractConnector: Started SocketConnector@0.0.0.0:46260%%0001017/07/18 00:21:39 INFO Utils: Successfully started service 'HTTP file server' on port 46260.%%0001017/07/18 00:21:39 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:21:39 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:21:39 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:21:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:21:39 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:21:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:21:40 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:21:40 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:21:40 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:21:40 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:21:40 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:21:40 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:21:40 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:21:40 INFO Client: Uploading resource file:/tmp/spark-cb24707b-5060-466a-a599-2b5af5627c51/__spark_conf__9150238668380521165.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22104/__spark_conf__9150238668380521165.zip%%0001017/07/18 00:21:40 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:21:40 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:21:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:21:41 INFO Client: Submitting application 22104 to ResourceManager%%0001017/07/18 00:21:41 INFO YarnClientImpl: Submitted application application_1491786134915_22104%%0001017/07/18 00:21:42 INFO Client: Application report for application_1491786134915_22104 (state: ACCEPTED)%%0001017/07/18 00:21:42 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308501014%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22104/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:21:43 INFO Client: Application report for application_1491786134915_22104 (state: ACCEPTED)%%0001017/07/18 00:21:44 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:42554/user/YarnAM#1637362184])%%0001017/07/18 00:21:44 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22104,http://hcnnc117:8088/proxy/application_1491786134915_22104), /proxy/application_1491786134915_22104%%0001017/07/18 00:21:44 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:21:44 INFO Client: Application report for application_1491786134915_22104 (state: ACCEPTED)%%0001017/07/18 00:21:45 INFO Client: Application report for application_1491786134915_22104 (state: RUNNING)%%0001017/07/18 00:21:45 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308501014%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22104/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:21:45 INFO YarnClientSchedulerBackend: Application application_1491786134915_22104 has started running.%%0001017/07/18 00:21:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45774.%%0001017/07/18 00:21:45 INFO NettyBlockTransferService: Server created on 45774%%0001017/07/18 00:21:45 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:21:45 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:21:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:45774 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 45774)%%0001017/07/18 00:21:45 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:21:46 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22104%%0001017/07/18 00:21:46 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:21:46 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:21:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:21:47 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:21:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:21:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:45774 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:21:47 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:21:47 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.3:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.10:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.31:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.17:50010%%0001017/07/18 00:21:47 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.18:50010%%0001017/07/18 00:21:47 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:21:47 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:21:47 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:21:47 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:21:47 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:21:47 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:21:47 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:21:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:21:47 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:21:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:21:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:45774 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:21:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:21:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:21:47 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:21:48 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:21:49 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:21:50 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:33819] &lt;- [akka.tcp://driverPropsFetcher@hcdnc419:43972]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc419:43972] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc419:43972%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:21:51 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc419:40710/user/Executor#454427462]) with ID 1%%0001017/07/18 00:21:51 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:21:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc419, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:21:51 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc419:55768 with 530.0 MB RAM, BlockManagerId(1, hcdnc419, 55768)%%0001017/07/18 00:21:51 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:33819] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:43141]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:43141] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:43141%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:21:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc419:55768 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:21:51 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:40244/user/Executor#-1848429002]) with ID 2%%0001017/07/18 00:21:51 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:21:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:21:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc419:55768 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:21:51 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:60575 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 60575)%%0001017/07/18 00:21:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:60575 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:21:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:60575 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:22:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11697 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11656 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:03 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.239 s%%0001017/07/18 00:22:03 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:03 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.359774 s%%0001017/07/18 00:22:03 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:22:03 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:22:03 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:22:03 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:22:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:22:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:22:03 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:22:03 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:22:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:22:03 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:22:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:22:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:45774 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:22:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:22:03 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:22:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc419, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:22:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:22:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc419:55768 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:22:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:60575 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:22:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17481 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 18548 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:22 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:22 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 18.552 s%%0001017/07/18 00:22:22 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:22:22 INFO DAGScheduler: running: Set()%%0001017/07/18 00:22:22 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:22:22 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:22:22 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:22:22 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:22:22 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:22:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:22:22 INFO MemoryStore: ensureFreeSpace(4048) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:22:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 530.0 MB)%%0001017/07/18 00:22:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:45774 (size: 4.0 KB, free: 530.2 MB)%%0001017/07/18 00:22:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:22:22 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:22:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc419, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:60575 (size: 4.0 KB, free: 530.0 MB)%%0001017/07/18 00:22:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc419:55768 (size: 4.0 KB, free: 530.0 MB)%%0001017/07/18 00:22:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:40244%%0001017/07/18 00:22:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:22:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc419:40710%%0001017/07/18 00:22:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1509 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1544 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:23 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:23 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.544 s%%0001017/07/18 00:22:23 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 20.127949 s%%0001017/07/18 00:22:23 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:22:23 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:22:23 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:22:23 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:22:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:22:23 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:22:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:22:23 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262341, maxMem=556038881%%0001017/07/18 00:22:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:22:23 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268861, maxMem=556038881%%0001017/07/18 00:22:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:22:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:45774 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:22:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:22:23 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:22:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc419, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:23 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc419:55768 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:22:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:60575 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:22:26 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2683 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:26 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 3108 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:26 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:26 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 3.110 s%%0001017/07/18 00:22:26 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 3.124242 s%%0001017/07/18 00:22:26 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:22:26 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:22:26 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:22:26 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:22:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:22:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:22:26 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:22:26 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272763, maxMem=556038881%%0001017/07/18 00:22:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:22:26 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279939, maxMem=556038881%%0001017/07/18 00:22:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:22:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:45774 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:22:26 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:22:26 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:22:26 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc419, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:22:26 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:22:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc419:55768 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:22:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:60575 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:22:29 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2673 ms on hcdnc419 (1/2)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 3140 ms on hcdnc310 (2/2)%%0001017/07/18 00:22:30 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:30 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 3.141 s%%0001017/07/18 00:22:30 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:22:30 INFO DAGScheduler: running: Set()%%0001017/07/18 00:22:30 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:22:30 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:22:30 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:22:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:22:30 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284088, maxMem=556038881%%0001017/07/18 00:22:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:22:30 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286872, maxMem=556038881%%0001017/07/18 00:22:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:45774 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 00:22:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:22:30 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc419, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc419:55768 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:60575 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:22:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:40244%%0001017/07/18 00:22:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:22:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc419:40710%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc419, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 44 ms on hcdnc419 (1/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 49 ms on hcdnc310 (2/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc419, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc419 (3/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 18 ms on hcdnc310 (4/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc419, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc419 (5/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc310 (6/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc419, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc419 (7/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 14 ms on hcdnc310 (8/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc419 (9/10)%%0001017/07/18 00:22:30 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 11 ms on hcdnc310 (10/10)%%0001017/07/18 00:22:30 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.106 s%%0001017/07/18 00:22:30 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:30 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 3.269401 s%%0001017/07/18 00:22:30 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:22:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:22:30 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:22:30 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:22:30 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:22:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:22:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:22:30 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:22:30 INFO MemoryStore: ensureFreeSpace(14024) called with curMem=288487, maxMem=556038881%%0001017/07/18 00:22:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:22:30 INFO MemoryStore: ensureFreeSpace(7740) called with curMem=302511, maxMem=556038881%%0001017/07/18 00:22:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:45774 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:22:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:22:30 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:22:30 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc419, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:60575 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:22:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc419:55768 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:22:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:40244%%0001017/07/18 00:22:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc419:40710%%0001017/07/18 00:22:44 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 13775 ms on hcdnc310 (1/2)%%0001017/07/18 00:22:44 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 14541 ms on hcdnc419 (2/2)%%0001017/07/18 00:22:44 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:44 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 14.542 s%%0001017/07/18 00:22:44 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:22:44 INFO DAGScheduler: running: Set()%%0001017/07/18 00:22:44 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:22:44 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:22:44 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:22:44 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:22:44 INFO MemoryStore: ensureFreeSpace(17344) called with curMem=310251, maxMem=556038881%%0001017/07/18 00:22:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.9 KB, free 530.0 MB)%%0001017/07/18 00:22:44 INFO MemoryStore: ensureFreeSpace(9233) called with curMem=327595, maxMem=556038881%%0001017/07/18 00:22:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 00:22:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:45774 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 00:22:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:22:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:22:44 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:22:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc419, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:44 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc419:55768 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:22:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:60575 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:22:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc419:40710%%0001017/07/18 00:22:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 165 bytes%%0001017/07/18 00:22:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:40244%%0001017/07/18 00:22:45 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc419, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 601 ms on hcdnc419 (1/10)%%0001017/07/18 00:22:45 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:45 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 722 ms on hcdnc310 (2/10)%%0001017/07/18 00:22:45 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 486 ms on hcdnc310 (3/10)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc419, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 725 ms on hcdnc419 (4/10)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 477 ms on hcdnc310 (5/10)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc419, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 613 ms on hcdnc419 (6/10)%%0001017/07/18 00:22:46 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 4)%%0001017/07/18 00:22:46 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:46 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 511 ms on hcdnc310 (7/10)%%0001017/07/18 00:22:47 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc419, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:22:47 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 547 ms on hcdnc419 (8/10)%%0001017/07/18 00:22:47 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 516 ms on hcdnc310 (9/10)%%0001017/07/18 00:22:47 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 529 ms on hcdnc419 (10/10)%%0001017/07/18 00:22:47 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:22:47 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 3.011 s%%0001017/07/18 00:22:47 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 17.580705 s%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:22:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:22:47 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:22:47 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:22:47 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:22:47 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:22:47 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:22:47 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:22:48 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:33819] &lt;- [akka.tcp://sparkExecutor@hcdnc419:40710]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc419:40710] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc419:40710%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:22:48 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:33819] &lt;- [akka.tcp://sparkExecutor@hcdnc310:40244]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:40244] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:40244%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:22:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:22:48 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:22:48 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:22:48 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:22:48 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:22:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:22:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:22:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:22:48 INFO Remoting: Remoting shut down%%0001017/07/18 00:22:48 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:22:48 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:22:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-cb24707b-5060-466a-a599-2b5af5627c51%%00010"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:23:03 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:23:03 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:23:03 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:23:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:23:04 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:23:04 INFO Remoting: Starting remoting%%0001017/07/18 00:23:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:32849]%%0001017/07/18 00:23:04 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:32849]%%0001017/07/18 00:23:04 INFO Utils: Successfully started service 'sparkDriver' on port 32849.%%0001017/07/18 00:23:04 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:23:04 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:23:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-be37ba71-e9e8-41f3-a50b-6dc74ac8fbf4%%0001017/07/18 00:23:04 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:23:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0c70c4de-250f-4d13-9c2e-53e1f8e4f62a/httpd-a5d65b98-b456-44b8-ac5b-22cb2ecaa266%%0001017/07/18 00:23:04 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:23:04 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:23:05 INFO AbstractConnector: Started SocketConnector@0.0.0.0:33519%%0001017/07/18 00:23:05 INFO Utils: Successfully started service 'HTTP file server' on port 33519.%%0001017/07/18 00:23:05 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:23:05 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:23:06 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:23:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:23:06 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:23:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:23:06 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:23:06 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:23:06 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:23:06 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:23:06 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:23:06 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:23:06 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:23:07 INFO Client: Uploading resource file:/tmp/spark-0c70c4de-250f-4d13-9c2e-53e1f8e4f62a/__spark_conf__5472358139873679719.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22105/__spark_conf__5472358139873679719.zip%%0001017/07/18 00:23:07 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:23:07 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:23:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:23:07 INFO Client: Submitting application 22105 to ResourceManager%%0001017/07/18 00:23:07 INFO YarnClientImpl: Submitted application application_1491786134915_22105%%0001017/07/18 00:23:08 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:08 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308587621%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22105/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:23:09 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:10 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:11 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:12 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:13 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:14 INFO Client: Application report for application_1491786134915_22105 (state: ACCEPTED)%%0001017/07/18 00:23:15 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.3.27:59248/user/YarnAM#-1737969702])%%0001017/07/18 00:23:15 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22105,http://hcnnc117:8088/proxy/application_1491786134915_22105), /proxy/application_1491786134915_22105%%0001017/07/18 00:23:15 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:23:15 INFO Client: Application report for application_1491786134915_22105 (state: RUNNING)%%0001017/07/18 00:23:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.3.27%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308587621%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22105/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:23:15 INFO YarnClientSchedulerBackend: Application application_1491786134915_22105 has started running.%%0001017/07/18 00:23:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39917.%%0001017/07/18 00:23:15 INFO NettyBlockTransferService: Server created on 39917%%0001017/07/18 00:23:15 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:23:15 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:23:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:39917 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 39917)%%0001017/07/18 00:23:15 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:23:16 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22105%%0001017/07/18 00:23:16 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:23:16 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:23:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:23:17 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:23:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:23:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:39917 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:23:17 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:23:17 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.17:50010%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.15:50010%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.18:50010%%0001017/07/18 00:23:17 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.7:50010%%0001017/07/18 00:23:17 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:23:17 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:23:17 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:23:17 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:23:17 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:23:17 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:23:17 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:23:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:23:17 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:23:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:23:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:39917 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:23:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:23:17 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:23:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:23:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:23:20 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:32849] &lt;- [akka.tcp://driverPropsFetcher@hcdnc305:51994]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc305:51994] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc305:51994%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:23:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc305:35082/user/Executor#-316650948]) with ID 1%%0001017/07/18 00:23:21 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:23:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc305, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:23:21 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc305:47632 with 530.0 MB RAM, BlockManagerId(1, hcdnc305, 47632)%%0001017/07/18 00:23:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:32849] &lt;- [akka.tcp://driverPropsFetcher@hcdnc235:57288]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc235:57288] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc235:57288%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:23:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc305:47632 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:23:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc235:55382/user/Executor#-724987626]) with ID 2%%0001017/07/18 00:23:21 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:23:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc235, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:23:22 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc235:36240 with 530.0 MB RAM, BlockManagerId(2, hcdnc235, 36240)%%0001017/07/18 00:23:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc305:47632 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:23:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc235:36240 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:23:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc235:36240 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:23:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11967 ms on hcdnc305 (1/2)%%0001017/07/18 00:23:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12352 ms on hcdnc235 (2/2)%%0001017/07/18 00:23:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.956 s%%0001017/07/18 00:23:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:23:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.100442 s%%0001017/07/18 00:23:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:23:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:23:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:23:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:23:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:23:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:23:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:23:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:23:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:23:34 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:23:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:39917 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:23:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:23:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:23:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc235, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc235:36240 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:23:35 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:23:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc305, partition 1,ANY, 2134 bytes)%%0001017/07/18 00:23:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc305:47632 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:23:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 18130 ms on hcdnc235 (1/2)%%0001017/07/18 00:23:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17535 ms on hcdnc305 (2/2)%%0001017/07/18 00:23:55 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:23:55 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 21.052 s%%0001017/07/18 00:23:55 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:23:55 INFO DAGScheduler: running: Set()%%0001017/07/18 00:23:55 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:23:55 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:23:55 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:23:55 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:23:55 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:23:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:23:55 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:23:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:23:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:39917 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:23:55 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:23:55 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:23:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:23:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc235, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:23:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc305:47632 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:23:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc235:36240 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:23:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc305:35082%%0001017/07/18 00:23:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:23:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc235:55382%%0001017/07/18 00:23:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1428 ms on hcdnc305 (1/2)%%0001017/07/18 00:23:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1471 ms on hcdnc235 (2/2)%%0001017/07/18 00:23:56 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:23:56 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.473 s%%0001017/07/18 00:23:56 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 22.567359 s%%0001017/07/18 00:23:56 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:23:56 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:23:56 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:23:56 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:23:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:23:56 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:23:56 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:23:56 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:23:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:23:56 INFO MemoryStore: ensureFreeSpace(3901) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:23:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:23:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:39917 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:23:56 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:23:56 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:23:56 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc305, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:23:56 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc235, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:23:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc305:47632 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:23:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc235:36240 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:23:59 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2730 ms on hcdnc235 (1/2)%%0001017/07/18 00:23:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2734 ms on hcdnc305 (2/2)%%0001017/07/18 00:23:59 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:23:59 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.734 s%%0001017/07/18 00:23:59 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.749007 s%%0001017/07/18 00:23:59 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:23:59 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:23:59 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:23:59 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:23:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:23:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:23:59 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:23:59 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272757, maxMem=556038881%%0001017/07/18 00:23:59 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:23:59 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279933, maxMem=556038881%%0001017/07/18 00:23:59 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:23:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:39917 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:23:59 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:23:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:23:59 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:23:59 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc235, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:23:59 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc305, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:23:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc235:36240 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:23:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc305:47632 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2719 ms on hcdnc235 (1/2)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2779 ms on hcdnc305 (2/2)%%0001017/07/18 00:24:02 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:02 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.780 s%%0001017/07/18 00:24:02 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:24:02 INFO DAGScheduler: running: Set()%%0001017/07/18 00:24:02 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:24:02 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:24:02 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:24:02 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:24:02 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284082, maxMem=556038881%%0001017/07/18 00:24:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:24:02 INFO MemoryStore: ensureFreeSpace(1615) called with curMem=286866, maxMem=556038881%%0001017/07/18 00:24:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1615.0 B, free 530.0 MB)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:39917 (size: 1615.0 B, free: 530.2 MB)%%0001017/07/18 00:24:02 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:02 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:24:02 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc235, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc305, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc235:36240 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc305:47632 (size: 1615.0 B, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc305:35082%%0001017/07/18 00:24:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:24:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc235:55382%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc305, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc305 (1/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc305, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc305 (2/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc235, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 65 ms on hcdnc235 (3/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc305, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 19 ms on hcdnc305 (4/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc235, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc235 (5/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc305, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 16 ms on hcdnc305 (6/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc235, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 18 ms on hcdnc235 (7/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc305, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 14 ms on hcdnc305 (8/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc235 (9/10)%%0001017/07/18 00:24:02 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc305 (10/10)%%0001017/07/18 00:24:02 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:02 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.114 s%%0001017/07/18 00:24:02 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.915616 s%%0001017/07/18 00:24:02 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:24:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:24:02 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:24:02 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:24:02 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:24:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:24:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:24:02 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:24:02 INFO MemoryStore: ensureFreeSpace(14024) called with curMem=288481, maxMem=556038881%%0001017/07/18 00:24:02 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.7 KB, free 530.0 MB)%%0001017/07/18 00:24:02 INFO MemoryStore: ensureFreeSpace(7740) called with curMem=302505, maxMem=556038881%%0001017/07/18 00:24:02 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KB, free 530.0 MB)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:39917 (size: 7.6 KB, free: 530.2 MB)%%0001017/07/18 00:24:02 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:24:02 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc305, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:24:02 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc235, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc305:47632 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc235:36240 (size: 7.6 KB, free: 530.0 MB)%%0001017/07/18 00:24:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc305:35082%%0001017/07/18 00:24:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc235:55382%%0001017/07/18 00:24:16 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 13555 ms on hcdnc305 (1/2)%%0001017/07/18 00:24:16 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 13602 ms on hcdnc235 (2/2)%%0001017/07/18 00:24:16 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:16 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 13.603 s%%0001017/07/18 00:24:16 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:24:16 INFO DAGScheduler: running: Set()%%0001017/07/18 00:24:16 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:24:16 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:24:16 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:24:16 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:24:16 INFO MemoryStore: ensureFreeSpace(17344) called with curMem=310245, maxMem=556038881%%0001017/07/18 00:24:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.9 KB, free 530.0 MB)%%0001017/07/18 00:24:16 INFO MemoryStore: ensureFreeSpace(9233) called with curMem=327589, maxMem=556038881%%0001017/07/18 00:24:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 530.0 MB)%%0001017/07/18 00:24:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:39917 (size: 9.0 KB, free: 530.2 MB)%%0001017/07/18 00:24:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:16 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:24:16 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:24:16 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc235, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:16 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc305, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc305:47632 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:24:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc235:36240 (size: 9.0 KB, free: 529.9 MB)%%0001017/07/18 00:24:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc305:35082%%0001017/07/18 00:24:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 164 bytes%%0001017/07/18 00:24:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc235:55382%%0001017/07/18 00:24:16 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc305, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:16 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 633 ms on hcdnc305 (1/10)%%0001017/07/18 00:24:17 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc235, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:17 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 678 ms on hcdnc235 (2/10)%%0001017/07/18 00:24:17 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:24:17 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc235, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:17 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 487 ms on hcdnc235 (3/10)%%0001017/07/18 00:24:17 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc305, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:17 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 540 ms on hcdnc305 (4/10)%%0001017/07/18 00:24:18 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc305, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 492 ms on hcdnc305 (5/10)%%0001017/07/18 00:24:18 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc235, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 546 ms on hcdnc235 (6/10)%%0001017/07/18 00:24:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 4)%%0001017/07/18 00:24:18 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc305, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 511 ms on hcdnc305 (7/10)%%0001017/07/18 00:24:18 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc235, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 519 ms on hcdnc235 (8/10)%%0001017/07/18 00:24:18 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 463 ms on hcdnc305 (9/10)%%0001017/07/18 00:24:19 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 485 ms on hcdnc235 (10/10)%%0001017/07/18 00:24:19 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:19 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.713 s%%0001017/07/18 00:24:19 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 16.343022 s%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:24:19 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:24:19 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:24:19 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:24:19 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:24:19 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:24:19 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:24:19 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:24:19 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:32849] &lt;- [akka.tcp://sparkExecutor@hcdnc235:55382]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc235:55382] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc235:55382%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:24:19 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:32849] &lt;- [akka.tcp://sparkExecutor@hcdnc305:35082]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc305:35082] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc305:35082%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:24:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:24:19 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:24:19 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:24:19 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:24:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:24:19 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:24:19 INFO Remoting: Remoting shut down%%0001017/07/18 00:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:24:20 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:24:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-0c70c4de-250f-4d13-9c2e-53e1f8e4f62a/pyspark-91ccdb90-5f5b-4df8-ba46-5fb90111cd32%%0001017/07/18 00:24:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-0c70c4de-250f-4d13-9c2e-53e1f8e4f62a%%00010"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:24:33 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:24:34 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:24:34 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:24:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:24:34 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:24:34 INFO Remoting: Starting remoting%%0001017/07/18 00:24:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:37659]%%0001017/07/18 00:24:35 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:37659]%%0001017/07/18 00:24:35 INFO Utils: Successfully started service 'sparkDriver' on port 37659.%%0001017/07/18 00:24:35 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:24:35 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:24:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a27826c8-a68d-4448-8217-201a38b17c3a%%0001017/07/18 00:24:35 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:24:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-73eb15c7-f5e4-4194-b169-d63121342d43/httpd-d298e4a2-a24a-4e2c-8720-99cc466ded7e%%0001017/07/18 00:24:35 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:24:35 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:24:35 INFO AbstractConnector: Started SocketConnector@0.0.0.0:36872%%0001017/07/18 00:24:35 INFO Utils: Successfully started service 'HTTP file server' on port 36872.%%0001017/07/18 00:24:35 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:24:35 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:24:35 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:24:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:24:35 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:24:35 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:24:35 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:24:35 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:24:35 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:24:35 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:24:35 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:24:35 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:24:35 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:24:36 INFO Client: Uploading resource file:/tmp/spark-73eb15c7-f5e4-4194-b169-d63121342d43/__spark_conf__818153191684606821.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22106/__spark_conf__818153191684606821.zip%%0001017/07/18 00:24:36 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:24:36 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:24:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:24:36 INFO Client: Submitting application 22106 to ResourceManager%%0001017/07/18 00:24:36 INFO YarnClientImpl: Submitted application application_1491786134915_22106%%0001017/07/18 00:24:37 INFO Client: Application report for application_1491786134915_22106 (state: ACCEPTED)%%0001017/07/18 00:24:37 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308676754%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22106/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:24:38 INFO Client: Application report for application_1491786134915_22106 (state: ACCEPTED)%%0001017/07/18 00:24:39 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:48955/user/YarnAM#-2080359981])%%0001017/07/18 00:24:39 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22106,http://hcnnc117:8088/proxy/application_1491786134915_22106), /proxy/application_1491786134915_22106%%0001017/07/18 00:24:39 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:24:39 INFO Client: Application report for application_1491786134915_22106 (state: RUNNING)%%0001017/07/18 00:24:39 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308676754%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22106/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:24:39 INFO YarnClientSchedulerBackend: Application application_1491786134915_22106 has started running.%%0001017/07/18 00:24:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41804.%%0001017/07/18 00:24:40 INFO NettyBlockTransferService: Server created on 41804%%0001017/07/18 00:24:40 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:24:40 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:24:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41804 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41804)%%0001017/07/18 00:24:40 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:24:41 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22106%%0001017/07/18 00:24:41 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:24:41 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:24:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:24:41 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:24:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:24:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41804 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:24:41 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:24:41 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.22:50010%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.36:50010%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.23:50010%%0001017/07/18 00:24:41 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.4:50010%%0001017/07/18 00:24:41 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:24:41 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:24:41 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:24:41 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:24:41 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:24:41 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:24:41 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:24:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:24:41 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:24:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:24:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41804 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:24:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:24:41 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:24:42 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:24:43 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:24:45 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37659] &lt;- [akka.tcp://driverPropsFetcher@hcdnc823:51461]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:51461] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc823:51461%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:24:45 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc823:48750/user/Executor#-433458982]) with ID 1%%0001017/07/18 00:24:45 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:24:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc823, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:24:45 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc823:46039 with 530.0 MB RAM, BlockManagerId(1, hcdnc823, 46039)%%0001017/07/18 00:24:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc823:46039 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:24:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37659] &lt;- [akka.tcp://driverPropsFetcher@hcdnc316:39091]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc316:39091] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc316:39091%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:24:46 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc316:53852/user/Executor#320444702]) with ID 2%%0001017/07/18 00:24:46 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:24:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc316, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:24:46 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc316:49066 with 530.0 MB RAM, BlockManagerId(2, hcdnc316, 49066)%%0001017/07/18 00:24:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc823:46039 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:24:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc316:49066 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:24:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc316:49066 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:24:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12386 ms on hcdnc823 (1/2)%%0001017/07/18 00:24:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11693 ms on hcdnc316 (2/2)%%0001017/07/18 00:24:58 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.253 s%%0001017/07/18 00:24:58 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:24:58 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.374166 s%%0001017/07/18 00:24:58 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:24:58 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:24:58 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:24:58 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:24:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:24:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:24:58 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:24:58 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:24:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:24:58 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:24:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:24:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41804 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:24:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:24:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:24:58 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:24:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc823, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:24:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc316, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:24:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc823:46039 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:24:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc316:49066 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:25:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17045 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17895 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:16 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:16 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.895 s%%0001017/07/18 00:25:16 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:25:16 INFO DAGScheduler: running: Set()%%0001017/07/18 00:25:16 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:25:16 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:25:16 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:25:16 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:25:16 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:25:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:25:16 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:25:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:25:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41804 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:25:16 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:25:16 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:25:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc316, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc823, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc823:46039 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:25:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc316:49066 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:25:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:48750%%0001017/07/18 00:25:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:25:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc316:53852%%0001017/07/18 00:25:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1362 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1455 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:17 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:17 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.458 s%%0001017/07/18 00:25:17 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.383326 s%%0001017/07/18 00:25:17 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:25:17 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:25:17 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:25:17 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:25:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:25:17 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:25:17 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:25:17 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:25:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:25:17 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:25:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41804 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:25:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:25:17 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:25:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc316, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:17 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc823, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc316:49066 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:25:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc823:46039 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:25:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2558 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:20 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2744 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:20 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:20 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.745 s%%0001017/07/18 00:25:20 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.758066 s%%0001017/07/18 00:25:20 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:25:20 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:25:20 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:25:20 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:25:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:25:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:25:20 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:25:20 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:25:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:25:20 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:25:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:25:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41804 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:25:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:25:20 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:25:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc823, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:25:20 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc316, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:25:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc316:49066 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:25:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc823:46039 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2627 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2753 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:23 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:23 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.753 s%%0001017/07/18 00:25:23 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:25:23 INFO DAGScheduler: running: Set()%%0001017/07/18 00:25:23 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:25:23 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:25:23 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:25:23 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:25:23 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:25:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:25:23 INFO MemoryStore: ensureFreeSpace(1614) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:25:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1614.0 B, free 530.0 MB)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41804 (size: 1614.0 B, free: 530.2 MB)%%0001017/07/18 00:25:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:23 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:25:23 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc823:46039 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc316:49066 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc823:48750%%0001017/07/18 00:25:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:25:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc316:53852%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc316, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 44 ms on hcdnc316 (1/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc823, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 47 ms on hcdnc823 (2/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc316, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc316 (3/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc823 (4/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc316, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc316 (5/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 18 ms on hcdnc823 (6/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc316, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc316 (7/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 15 ms on hcdnc823 (8/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc316 (9/10)%%0001017/07/18 00:25:23 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc823 (10/10)%%0001017/07/18 00:25:23 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.104 s%%0001017/07/18 00:25:23 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:23 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.878391 s%%0001017/07/18 00:25:23 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:25:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:25:23 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:25:23 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:25:23 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:25:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:25:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:25:23 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:25:23 INFO MemoryStore: ensureFreeSpace(12936) called with curMem=288481, maxMem=556038881%%0001017/07/18 00:25:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 530.0 MB)%%0001017/07/18 00:25:23 INFO MemoryStore: ensureFreeSpace(7135) called with curMem=301417, maxMem=556038881%%0001017/07/18 00:25:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41804 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 00:25:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:25:23 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc823, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:25:23 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc316, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc823:46039 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc316:49066 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:25:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc823:48750%%0001017/07/18 00:25:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc316:53852%%0001017/07/18 00:25:35 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 11711 ms on hcdnc316 (1/2)%%0001017/07/18 00:25:35 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 12085 ms on hcdnc823 (2/2)%%0001017/07/18 00:25:35 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:35 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 12.085 s%%0001017/07/18 00:25:35 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:25:35 INFO DAGScheduler: running: Set()%%0001017/07/18 00:25:35 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:25:35 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:25:35 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:25:35 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:25:35 INFO MemoryStore: ensureFreeSpace(16008) called with curMem=308552, maxMem=556038881%%0001017/07/18 00:25:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.6 KB, free 530.0 MB)%%0001017/07/18 00:25:35 INFO MemoryStore: ensureFreeSpace(8481) called with curMem=324560, maxMem=556038881%%0001017/07/18 00:25:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 00:25:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41804 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 00:25:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:25:35 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:25:35 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:25:35 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc823, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:35 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc316, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc823:46039 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:25:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc316:49066 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:25:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc823:48750%%0001017/07/18 00:25:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 163 bytes%%0001017/07/18 00:25:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc316:53852%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc316, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 524 ms on hcdnc316 (1/10)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc823, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 622 ms on hcdnc823 (2/10)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc316, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 439 ms on hcdnc316 (3/10)%%0001017/07/18 00:25:36 INFO ExecutorAllocationManager: Requesting 2 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc823, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 399 ms on hcdnc823 (4/10)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc316, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 393 ms on hcdnc316 (5/10)%%0001017/07/18 00:25:36 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc823, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:36 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 360 ms on hcdnc823 (6/10)%%0001017/07/18 00:25:37 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc316, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:37 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 399 ms on hcdnc316 (7/10)%%0001017/07/18 00:25:37 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc823, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:25:37 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 574 ms on hcdnc823 (8/10)%%0001017/07/18 00:25:37 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 402 ms on hcdnc316 (9/10)%%0001017/07/18 00:25:38 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 566 ms on hcdnc823 (10/10)%%0001017/07/18 00:25:38 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:25:38 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.518 s%%0001017/07/18 00:25:38 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 14.629216 s%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:25:38 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:25:38 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:25:38 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:25:38 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:25:38 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:25:38 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:25:38 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:25:38 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37659] &lt;- [akka.tcp://sparkExecutor@hcdnc823:48750]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc823:48750] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc823:48750%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:25:38 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:37659] &lt;- [akka.tcp://sparkExecutor@hcdnc316:53852]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc316:53852] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc316:53852%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:25:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:25:38 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:25:38 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:25:38 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:25:38 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:25:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:25:38 INFO Remoting: Remoting shut down%%0001017/07/18 00:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:25:39 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:25:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-73eb15c7-f5e4-4194-b169-d63121342d43%%00010"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:25:52 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:25:54 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:25:54 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:25:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:25:54 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:25:54 INFO Remoting: Starting remoting%%0001017/07/18 00:25:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:38802]%%0001017/07/18 00:25:54 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:38802]%%0001017/07/18 00:25:54 INFO Utils: Successfully started service 'sparkDriver' on port 38802.%%0001017/07/18 00:25:54 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:25:54 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:25:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-41ef7b83-9984-436e-89cd-d5d709cb5c98%%0001017/07/18 00:25:54 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:25:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-4cd27c74-f47e-4f7b-9482-a778d468c37e/httpd-7ff2b5c9-0540-4dd9-93df-5ac8073e2da6%%0001017/07/18 00:25:54 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:25:54 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:25:54 INFO AbstractConnector: Started SocketConnector@0.0.0.0:42268%%0001017/07/18 00:25:54 INFO Utils: Successfully started service 'HTTP file server' on port 42268.%%0001017/07/18 00:25:54 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:25:55 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:25:55 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:25:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:25:55 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:25:55 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:25:55 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:25:55 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:25:56 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:25:56 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:25:56 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:25:56 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:25:56 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:25:56 INFO Client: Uploading resource file:/tmp/spark-4cd27c74-f47e-4f7b-9482-a778d468c37e/__spark_conf__1057274651183876044.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22107/__spark_conf__1057274651183876044.zip%%0001017/07/18 00:25:56 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:25:56 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:25:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:25:56 INFO Client: Submitting application 22107 to ResourceManager%%0001017/07/18 00:25:57 INFO YarnClientImpl: Submitted application application_1491786134915_22107%%0001017/07/18 00:25:58 INFO Client: Application report for application_1491786134915_22107 (state: ACCEPTED)%%0001017/07/18 00:25:58 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308756865%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22107/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:25:59 INFO Client: Application report for application_1491786134915_22107 (state: ACCEPTED)%%0001017/07/18 00:25:59 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:35220/user/YarnAM#676870486])%%0001017/07/18 00:25:59 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22107,http://hcnnc117:8088/proxy/application_1491786134915_22107), /proxy/application_1491786134915_22107%%0001017/07/18 00:25:59 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:26:00 INFO Client: Application report for application_1491786134915_22107 (state: RUNNING)%%0001017/07/18 00:26:00 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308756865%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22107/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:26:00 INFO YarnClientSchedulerBackend: Application application_1491786134915_22107 has started running.%%0001017/07/18 00:26:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36677.%%0001017/07/18 00:26:00 INFO NettyBlockTransferService: Server created on 36677%%0001017/07/18 00:26:00 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:26:00 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:26:00 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:36677 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 36677)%%0001017/07/18 00:26:00 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:26:00 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22107%%0001017/07/18 00:26:00 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:26:01 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:26:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:26:01 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:26:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:26:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:36677 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:26:01 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:26:01 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.30:50010%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.24:50010%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.37:50010%%0001017/07/18 00:26:01 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.17:50010%%0001017/07/18 00:26:01 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:26:01 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:26:01 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:26:01 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:26:01 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:26:01 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:26:01 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:26:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:26:01 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:26:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:26:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:36677 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:26:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:26:01 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:26:02 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:26:03 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:26:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38802] &lt;- [akka.tcp://driverPropsFetcher@hcdnc325:40844]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc325:40844] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc325:40844%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:26:05 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc325:36717/user/Executor#-1644048041]) with ID 1%%0001017/07/18 00:26:05 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:26:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc325, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:26:05 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc325:45123 with 530.0 MB RAM, BlockManagerId(1, hcdnc325, 45123)%%0001017/07/18 00:26:05 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38802] &lt;- [akka.tcp://driverPropsFetcher@hcdnc821:47379]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc821:47379] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc821:47379%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:26:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc325:45123 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:26:06 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc821:40992/user/Executor#-380674388]) with ID 2%%0001017/07/18 00:26:06 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:26:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc821, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:26:06 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc821:39191 with 530.0 MB RAM, BlockManagerId(2, hcdnc821, 39191)%%0001017/07/18 00:26:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc325:45123 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:26:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc821:39191 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:26:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc821:39191 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:26:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11810 ms on hcdnc325 (1/2)%%0001017/07/18 00:26:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12514 ms on hcdnc821 (2/2)%%0001017/07/18 00:26:18 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 17.121 s%%0001017/07/18 00:26:18 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:18 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.245811 s%%0001017/07/18 00:26:18 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:26:18 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:26:18 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:26:18 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:26:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:26:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:26:18 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:26:18 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:26:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:26:18 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:26:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:26:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:36677 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:26:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:26:18 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:26:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc821, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:26:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc325, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:26:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc821:39191 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:26:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc325:45123 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:26:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17325 ms on hcdnc821 (1/2)%%0001017/07/18 00:26:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17422 ms on hcdnc325 (2/2)%%0001017/07/18 00:26:36 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:36 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.424 s%%0001017/07/18 00:26:36 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:26:36 INFO DAGScheduler: running: Set()%%0001017/07/18 00:26:36 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:26:36 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:26:36 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:26:36 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:26:36 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:26:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:26:36 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:26:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:26:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:36677 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:26:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:26:36 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:26:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc821, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc325:45123 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:26:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc821:39191 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:26:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc325:36717%%0001017/07/18 00:26:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:26:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc821:40992%%0001017/07/18 00:26:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1354 ms on hcdnc821 (1/2)%%0001017/07/18 00:26:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1438 ms on hcdnc325 (2/2)%%0001017/07/18 00:26:37 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:37 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.440 s%%0001017/07/18 00:26:37 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 18.895198 s%%0001017/07/18 00:26:37 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:26:37 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:26:37 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:26:37 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:26:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:26:37 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:26:37 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:26:37 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:26:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:26:37 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:26:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:26:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:36677 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:26:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:26:37 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:26:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc821, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:37 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc325:45123 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:26:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc821:39191 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:26:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2583 ms on hcdnc821 (1/2)%%0001017/07/18 00:26:40 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2829 ms on hcdnc325 (2/2)%%0001017/07/18 00:26:40 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:40 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.830 s%%0001017/07/18 00:26:40 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.860712 s%%0001017/07/18 00:26:40 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:26:40 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:26:40 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:26:40 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:26:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:26:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:26:40 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:26:40 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:26:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:26:40 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:26:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:26:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:36677 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:26:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:26:40 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:26:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc821, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:26:40 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc325, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:26:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc821:39191 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:26:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc325:45123 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2632 ms on hcdnc821 (1/2)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2871 ms on hcdnc325 (2/2)%%0001017/07/18 00:26:43 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:43 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.872 s%%0001017/07/18 00:26:43 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:26:43 INFO DAGScheduler: running: Set()%%0001017/07/18 00:26:43 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:26:43 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:26:43 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:26:43 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:26:43 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:26:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:26:43 INFO MemoryStore: ensureFreeSpace(1614) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:26:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1614.0 B, free 530.0 MB)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:36677 (size: 1614.0 B, free: 530.2 MB)%%0001017/07/18 00:26:43 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:43 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:26:43 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc821, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc325, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc325:45123 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc821:39191 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc821:40992%%0001017/07/18 00:26:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:26:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc325:36717%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc821, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 50 ms on hcdnc821 (1/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc325, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 57 ms on hcdnc325 (2/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc821, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 16 ms on hcdnc821 (3/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc325, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 14 ms on hcdnc325 (4/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc821, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 18 ms on hcdnc821 (5/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc325, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc325 (6/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc821, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc821 (7/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc325, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc325 (8/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 14 ms on hcdnc821 (9/10)%%0001017/07/18 00:26:43 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc325 (10/10)%%0001017/07/18 00:26:43 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.115 s%%0001017/07/18 00:26:43 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:43 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 3.007737 s%%0001017/07/18 00:26:43 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:26:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:26:43 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:26:43 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:26:43 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:26:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:26:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:26:43 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:26:43 INFO MemoryStore: ensureFreeSpace(12936) called with curMem=288481, maxMem=556038881%%0001017/07/18 00:26:43 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 530.0 MB)%%0001017/07/18 00:26:43 INFO MemoryStore: ensureFreeSpace(7135) called with curMem=301417, maxMem=556038881%%0001017/07/18 00:26:43 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:36677 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 00:26:43 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:26:43 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc325, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:26:43 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc821, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc325:45123 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc821:39191 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:26:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc821:40992%%0001017/07/18 00:26:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc325:36717%%0001017/07/18 00:26:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 11414 ms on hcdnc325 (1/2)%%0001017/07/18 00:26:56 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 12393 ms on hcdnc821 (2/2)%%0001017/07/18 00:26:56 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:56 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 12.395 s%%0001017/07/18 00:26:56 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:26:56 INFO DAGScheduler: running: Set()%%0001017/07/18 00:26:56 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:26:56 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:26:56 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:26:56 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:26:56 INFO MemoryStore: ensureFreeSpace(16008) called with curMem=308552, maxMem=556038881%%0001017/07/18 00:26:56 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.6 KB, free 530.0 MB)%%0001017/07/18 00:26:56 INFO MemoryStore: ensureFreeSpace(8481) called with curMem=324560, maxMem=556038881%%0001017/07/18 00:26:56 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 00:26:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:36677 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 00:26:56 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:26:56 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:26:56 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:26:56 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc325, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:56 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc821, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc821:39191 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:26:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc325:45123 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:26:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc821:40992%%0001017/07/18 00:26:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 163 bytes%%0001017/07/18 00:26:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc325:36717%%0001017/07/18 00:26:56 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc821, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:56 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 538 ms on hcdnc821 (1/10)%%0001017/07/18 00:26:56 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc325, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:56 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 622 ms on hcdnc325 (2/10)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc325, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 353 ms on hcdnc325 (3/10)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc821, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 447 ms on hcdnc821 (4/10)%%0001017/07/18 00:26:57 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc821, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 353 ms on hcdnc821 (5/10)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc325, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 422 ms on hcdnc325 (6/10)%%0001017/07/18 00:26:57 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc821, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:57 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 436 ms on hcdnc821 (7/10)%%0001017/07/18 00:26:58 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc325, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:26:58 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 434 ms on hcdnc325 (8/10)%%0001017/07/18 00:26:58 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 432 ms on hcdnc821 (9/10)%%0001017/07/18 00:26:58 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 459 ms on hcdnc325 (10/10)%%0001017/07/18 00:26:58 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:26:58 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.287 s%%0001017/07/18 00:26:58 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 14.709158 s%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:26:58 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:26:58 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:26:58 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:26:58 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:26:58 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:26:58 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:26:58 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:26:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38802] &lt;- [akka.tcp://sparkExecutor@hcdnc821:40992]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc821:40992] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc821:40992%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:26:58 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:38802] &lt;- [akka.tcp://sparkExecutor@hcdnc325:36717]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc325:36717] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc325:36717%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:26:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:26:58 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:26:58 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:26:58 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:26:58 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:26:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:26:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:26:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:26:58 INFO Remoting: Remoting shut down%%0001017/07/18 00:26:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:26:59 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:26:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-4cd27c74-f47e-4f7b-9482-a778d468c37e/pyspark-2992b9cb-4634-465b-8e73-45cea7e2b774%%0001017/07/18 00:26:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-4cd27c74-f47e-4f7b-9482-a778d468c37e%%00010"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:27:13 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:27:14 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:27:14 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:27:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:27:14 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:27:14 INFO Remoting: Starting remoting%%0001017/07/18 00:27:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:43598]%%0001017/07/18 00:27:15 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:43598]%%0001017/07/18 00:27:15 INFO Utils: Successfully started service 'sparkDriver' on port 43598.%%0001017/07/18 00:27:15 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:27:15 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:27:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eb9669bc-b328-489b-9ea6-cf3eb8e905ee%%0001017/07/18 00:27:15 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:27:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-24a2deda-c091-4543-ac3d-532703775810/httpd-7abdfb4b-f6d6-44bf-a5be-18185be8a27d%%0001017/07/18 00:27:15 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:27:15 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:27:15 INFO AbstractConnector: Started SocketConnector@0.0.0.0:36687%%0001017/07/18 00:27:15 INFO Utils: Successfully started service 'HTTP file server' on port 36687.%%0001017/07/18 00:27:15 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:27:15 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:27:15 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:27:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:27:15 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:27:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:27:16 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:27:16 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:27:16 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:27:16 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:27:16 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:27:16 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:27:16 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:27:16 INFO Client: Uploading resource file:/tmp/spark-24a2deda-c091-4543-ac3d-532703775810/__spark_conf__2757115580511688243.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22108/__spark_conf__2757115580511688243.zip%%0001017/07/18 00:27:17 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:27:17 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:27:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:27:17 INFO Client: Submitting application 22108 to ResourceManager%%0001017/07/18 00:27:17 INFO YarnClientImpl: Submitted application application_1491786134915_22108%%0001017/07/18 00:27:18 INFO Client: Application report for application_1491786134915_22108 (state: ACCEPTED)%%0001017/07/18 00:27:18 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308837118%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22108/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:27:19 INFO Client: Application report for application_1491786134915_22108 (state: ACCEPTED)%%0001017/07/18 00:27:20 INFO Client: Application report for application_1491786134915_22108 (state: ACCEPTED)%%0001017/07/18 00:27:20 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:46137/user/YarnAM#-1684706552])%%0001017/07/18 00:27:20 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22108,http://hcnnc117:8088/proxy/application_1491786134915_22108), /proxy/application_1491786134915_22108%%0001017/07/18 00:27:20 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:27:21 INFO Client: Application report for application_1491786134915_22108 (state: RUNNING)%%0001017/07/18 00:27:21 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308837118%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22108/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:27:21 INFO YarnClientSchedulerBackend: Application application_1491786134915_22108 has started running.%%0001017/07/18 00:27:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46059.%%0001017/07/18 00:27:22 INFO NettyBlockTransferService: Server created on 46059%%0001017/07/18 00:27:22 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:27:22 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:27:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:46059 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 46059)%%0001017/07/18 00:27:22 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:27:22 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22108%%0001017/07/18 00:27:22 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:27:23 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:27:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:27:23 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:27:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:27:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:46059 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:27:23 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:27:23 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.39:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.9:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.17:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.30:50010%%0001017/07/18 00:27:23 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.12:50010%%0001017/07/18 00:27:23 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:27:23 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:27:23 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:27:23 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:27:23 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:27:23 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:27:23 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:27:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:27:23 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:27:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:27:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:46059 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:27:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:27:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:27:23 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:27:24 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:27:25 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:27:26 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:43598] &lt;- [akka.tcp://driverPropsFetcher@hcdnc330:52858]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc330:52858] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc330:52858%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:27:27 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc330:57000/user/Executor#1229962320]) with ID 1%%0001017/07/18 00:27:27 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:27:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc330, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:27:27 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc330:40679 with 530.0 MB RAM, BlockManagerId(1, hcdnc330, 40679)%%0001017/07/18 00:27:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc330:40679 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:27:27 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:43598] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:59288]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:59288] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:59288%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:27:27 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:36720/user/Executor#1741661093]) with ID 2%%0001017/07/18 00:27:27 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:27:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc310, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:27:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc330:40679 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:27:28 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:34029 with 530.0 MB RAM, BlockManagerId(2, hcdnc310, 34029)%%0001017/07/18 00:27:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:34029 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:27:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:34029 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:27:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12083 ms on hcdnc330 (1/2)%%0001017/07/18 00:27:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11722 ms on hcdnc310 (2/2)%%0001017/07/18 00:27:39 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.333 s%%0001017/07/18 00:27:39 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:27:39 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.478652 s%%0001017/07/18 00:27:39 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:27:39 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:27:39 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:27:39 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:27:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:27:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:27:39 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:27:39 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:27:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:27:39 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:27:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:27:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:46059 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:27:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:27:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:27:39 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:27:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc330, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:27:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:27:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc330:40679 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:27:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:34029 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:27:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17322 ms on hcdnc330 (1/2)%%0001017/07/18 00:27:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17614 ms on hcdnc310 (2/2)%%0001017/07/18 00:27:57 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:27:57 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.616 s%%0001017/07/18 00:27:57 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:27:57 INFO DAGScheduler: running: Set()%%0001017/07/18 00:27:57 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:27:57 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:27:57 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:27:57 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:27:57 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:27:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:27:57 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:27:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:27:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:46059 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:27:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:27:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:27:57 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:27:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc330, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:27:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:27:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc330:40679 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:27:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:34029 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:27:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc330:57000%%0001017/07/18 00:27:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 00:27:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:36720%%0001017/07/18 00:27:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1416 ms on hcdnc330 (1/2)%%0001017/07/18 00:27:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1492 ms on hcdnc310 (2/2)%%0001017/07/18 00:27:58 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:27:58 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.495 s%%0001017/07/18 00:27:58 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.141499 s%%0001017/07/18 00:27:58 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:27:58 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:27:58 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:27:58 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:27:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:27:58 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:27:58 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:27:58 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:27:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:27:58 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:27:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:27:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:46059 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:27:58 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:27:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:27:58 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:27:58 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc330, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:27:58 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:27:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:34029 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:27:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc330:40679 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:28:01 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2714 ms on hcdnc330 (1/2)%%0001017/07/18 00:28:01 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2739 ms on hcdnc310 (2/2)%%0001017/07/18 00:28:01 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:01 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.741 s%%0001017/07/18 00:28:01 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.753667 s%%0001017/07/18 00:28:01 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:28:01 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:28:01 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:28:01 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:28:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:28:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:28:01 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:28:01 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:28:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:28:01 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:28:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:28:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:46059 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:28:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:28:01 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:28:01 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:28:01 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc330, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:28:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc330:40679 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:28:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:34029 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2709 ms on hcdnc310 (1/2)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2845 ms on hcdnc330 (2/2)%%0001017/07/18 00:28:04 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:04 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.846 s%%0001017/07/18 00:28:04 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:28:04 INFO DAGScheduler: running: Set()%%0001017/07/18 00:28:04 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:28:04 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:28:04 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:28:04 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:28:04 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:28:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:28:04 INFO MemoryStore: ensureFreeSpace(1614) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:28:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1614.0 B, free 530.0 MB)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:46059 (size: 1614.0 B, free: 530.2 MB)%%0001017/07/18 00:28:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:28:04 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc330, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc330:40679 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:34029 (size: 1614.0 B, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc330:57000%%0001017/07/18 00:28:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 164 bytes%%0001017/07/18 00:28:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:36720%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc330, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 41 ms on hcdnc330 (1/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 50 ms on hcdnc310 (2/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc330, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc330 (3/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc310 (4/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc330, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc330 (5/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc330, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc330 (6/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 21 ms on hcdnc310 (7/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc330, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc330 (8/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 16 ms on hcdnc310 (9/10)%%0001017/07/18 00:28:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 15 ms on hcdnc330 (10/10)%%0001017/07/18 00:28:04 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.111 s%%0001017/07/18 00:28:04 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:04 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.978699 s%%0001017/07/18 00:28:04 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:28:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes%%0001017/07/18 00:28:04 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:28:04 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:28:04 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:28:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:28:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:28:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:28:04 INFO MemoryStore: ensureFreeSpace(12936) called with curMem=288481, maxMem=556038881%%0001017/07/18 00:28:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 530.0 MB)%%0001017/07/18 00:28:04 INFO MemoryStore: ensureFreeSpace(7135) called with curMem=301417, maxMem=556038881%%0001017/07/18 00:28:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:46059 (size: 7.0 KB, free: 530.2 MB)%%0001017/07/18 00:28:04 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:28:04 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:28:04 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc330, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:34029 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc330:40679 (size: 7.0 KB, free: 530.0 MB)%%0001017/07/18 00:28:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc330:57000%%0001017/07/18 00:28:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:36720%%0001017/07/18 00:28:15 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 10989 ms on hcdnc310 (1/2)%%0001017/07/18 00:28:15 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 11027 ms on hcdnc330 (2/2)%%0001017/07/18 00:28:15 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:15 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 11.029 s%%0001017/07/18 00:28:15 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:28:15 INFO DAGScheduler: running: Set()%%0001017/07/18 00:28:15 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:28:15 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:28:15 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:28:15 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:28:15 INFO MemoryStore: ensureFreeSpace(16008) called with curMem=308552, maxMem=556038881%%0001017/07/18 00:28:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.6 KB, free 530.0 MB)%%0001017/07/18 00:28:15 INFO MemoryStore: ensureFreeSpace(8481) called with curMem=324560, maxMem=556038881%%0001017/07/18 00:28:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 530.0 MB)%%0001017/07/18 00:28:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:46059 (size: 8.3 KB, free: 530.2 MB)%%0001017/07/18 00:28:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:28:15 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:28:15 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc310, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:15 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc330, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:34029 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:28:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc330:40679 (size: 8.3 KB, free: 530.0 MB)%%0001017/07/18 00:28:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc330:57000%%0001017/07/18 00:28:15 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:28:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:36720%%0001017/07/18 00:28:16 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc330, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:16 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 621 ms on hcdnc330 (1/10)%%0001017/07/18 00:28:16 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:16 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 702 ms on hcdnc310 (2/10)%%0001017/07/18 00:28:16 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:28:16 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc330, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:16 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 449 ms on hcdnc330 (3/10)%%0001017/07/18 00:28:16 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc310, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:16 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 372 ms on hcdnc310 (4/10)%%0001017/07/18 00:28:17 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:17 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 398 ms on hcdnc310 (5/10)%%0001017/07/18 00:28:17 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc330, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:17 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 437 ms on hcdnc330 (6/10)%%0001017/07/18 00:28:17 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc330, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:17 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 431 ms on hcdnc330 (7/10)%%0001017/07/18 00:28:17 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:28:17 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 519 ms on hcdnc310 (8/10)%%0001017/07/18 00:28:18 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 421 ms on hcdnc330 (9/10)%%0001017/07/18 00:28:18 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 458 ms on hcdnc310 (10/10)%%0001017/07/18 00:28:18 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:18 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 2.445 s%%0001017/07/18 00:28:18 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 13.516972 s%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:28:18 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:28:18 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:28:18 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:28:18 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:28:18 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:28:18 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:28:18 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:28:18 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:43598] &lt;- [akka.tcp://sparkExecutor@hcdnc310:36720]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:36720] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:36720%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:28:18 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:43598] &lt;- [akka.tcp://sparkExecutor@hcdnc330:57000]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc330:57000] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc330:57000%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:28:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:28:18 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:28:18 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:28:18 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:28:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:28:18 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:28:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:28:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:28:18 INFO Remoting: Remoting shut down%%0001017/07/18 00:28:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:28:19 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:28:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-24a2deda-c091-4543-ac3d-532703775810%%00010"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:28:33 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:28:34 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:28:34 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:28:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:28:34 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:28:34 INFO Remoting: Starting remoting%%0001017/07/18 00:28:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:39596]%%0001017/07/18 00:28:34 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:39596]%%0001017/07/18 00:28:34 INFO Utils: Successfully started service 'sparkDriver' on port 39596.%%0001017/07/18 00:28:34 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:28:34 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:28:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7a1f30f8-b8ee-4402-a589-edf9049861a4%%0001017/07/18 00:28:35 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:28:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-2e6972b4-ab35-4126-8f6f-f336737ab153/httpd-e13be6d7-6fc0-426f-a128-25d3b795e6ca%%0001017/07/18 00:28:35 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:28:35 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:28:35 INFO AbstractConnector: Started SocketConnector@0.0.0.0:44700%%0001017/07/18 00:28:35 INFO Utils: Successfully started service 'HTTP file server' on port 44700.%%0001017/07/18 00:28:35 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:28:35 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:28:35 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:28:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:28:35 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:28:36 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:28:36 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:28:36 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:28:36 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:28:36 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:28:36 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:28:36 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:28:36 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:28:36 INFO Client: Uploading resource file:/tmp/spark-2e6972b4-ab35-4126-8f6f-f336737ab153/__spark_conf__7109189492097715323.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22109/__spark_conf__7109189492097715323.zip%%0001017/07/18 00:28:37 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:28:37 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:28:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:28:37 INFO Client: Submitting application 22109 to ResourceManager%%0001017/07/18 00:28:37 INFO YarnClientImpl: Submitted application application_1491786134915_22109%%0001017/07/18 00:28:38 INFO Client: Application report for application_1491786134915_22109 (state: ACCEPTED)%%0001017/07/18 00:28:38 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308917082%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22109/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:28:39 INFO Client: Application report for application_1491786134915_22109 (state: ACCEPTED)%%0001017/07/18 00:28:40 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.11:50173/user/YarnAM#-598983920])%%0001017/07/18 00:28:40 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22109,http://hcnnc117:8088/proxy/application_1491786134915_22109), /proxy/application_1491786134915_22109%%0001017/07/18 00:28:40 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:28:40 INFO Client: Application report for application_1491786134915_22109 (state: ACCEPTED)%%0001017/07/18 00:28:41 INFO Client: Application report for application_1491786134915_22109 (state: RUNNING)%%0001017/07/18 00:28:41 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.11%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308917082%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22109/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:28:41 INFO YarnClientSchedulerBackend: Application application_1491786134915_22109 has started running.%%0001017/07/18 00:28:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40102.%%0001017/07/18 00:28:41 INFO NettyBlockTransferService: Server created on 40102%%0001017/07/18 00:28:41 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:28:41 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:28:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:40102 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 40102)%%0001017/07/18 00:28:41 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:28:41 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22109%%0001017/07/18 00:28:41 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:28:42 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:28:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:28:42 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:28:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:28:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:40102 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:28:42 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:28:42 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.24:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.31:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.31:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.29:50010%%0001017/07/18 00:28:42 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.16:50010%%0001017/07/18 00:28:42 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:28:42 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:28:42 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:28:42 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:28:42 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:28:42 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:28:42 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:28:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:28:42 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:28:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:28:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:40102 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:28:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:28:42 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:28:43 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:28:44 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:28:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:39596] &lt;- [akka.tcp://driverPropsFetcher@hcdnc310:59865]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:59865] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc310:59865%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:28:46 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc310:50642/user/Executor#-633583132]) with ID 1%%0001017/07/18 00:28:46 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:28:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc310, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:28:46 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc310:39840 with 530.0 MB RAM, BlockManagerId(1, hcdnc310, 39840)%%0001017/07/18 00:28:46 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:39596] &lt;- [akka.tcp://driverPropsFetcher@hcdnc306:51940]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:51940] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc306:51940%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:28:46 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc306:41062/user/Executor#-1490934676]) with ID 2%%0001017/07/18 00:28:47 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:28:47 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc306:60560 with 530.0 MB RAM, BlockManagerId(2, hcdnc306, 60560)%%0001017/07/18 00:28:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc306, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:28:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc310:39840 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:28:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc306:60560 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:28:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc310:39840 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:28:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc306:60560 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:28:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12308 ms on hcdnc310 (1/2)%%0001017/07/18 00:28:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11904 ms on hcdnc306 (2/2)%%0001017/07/18 00:28:59 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.722 s%%0001017/07/18 00:28:59 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:28:59 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.866564 s%%0001017/07/18 00:28:59 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:28:59 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:28:59 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:28:59 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:28:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:28:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:28:59 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:28:59 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:28:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:28:59 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:28:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:28:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:40102 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:28:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:28:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:28:59 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:28:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc306, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:28:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc310, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:28:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc306:60560 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:28:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc310:39840 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:29:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17219 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17425 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:16 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:16 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.427 s%%0001017/07/18 00:29:16 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:29:16 INFO DAGScheduler: running: Set()%%0001017/07/18 00:29:16 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:29:16 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:29:16 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:29:16 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:29:16 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:29:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:29:16 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:29:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:29:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:40102 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:29:16 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:29:16 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:29:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc306:60560 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:29:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc310:39840 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:29:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:41062%%0001017/07/18 00:29:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:29:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:50642%%0001017/07/18 00:29:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1370 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1455 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:18 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:18 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.457 s%%0001017/07/18 00:29:18 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 18.915144 s%%0001017/07/18 00:29:18 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:29:18 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:29:18 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:29:18 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:29:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:29:18 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:29:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:29:18 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:29:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:29:18 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:29:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:29:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:40102 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:29:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:29:18 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:29:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:18 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc310:39840 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:29:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc306:60560 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:29:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2610 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:20 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2759 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:20 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:20 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.760 s%%0001017/07/18 00:29:20 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.775384 s%%0001017/07/18 00:29:20 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:29:20 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:29:20 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:29:20 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:29:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:29:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:29:20 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:29:20 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:29:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:29:20 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:29:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:29:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:40102 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:29:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:29:20 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:29:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc310, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:29:20 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc306, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:29:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc310:39840 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:29:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc306:60560 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2696 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2722 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:23 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:23 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.724 s%%0001017/07/18 00:29:23 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:29:23 INFO DAGScheduler: running: Set()%%0001017/07/18 00:29:23 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:29:23 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:29:23 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:29:23 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:29:23 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:29:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:29:23 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:29:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:40102 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:29:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:23 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:29:23 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc306:60560 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc310:39840 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc306:41062%%0001017/07/18 00:29:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:29:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc310:50642%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc310, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc306, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 45 ms on hcdnc310 (1/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 46 ms on hcdnc306 (2/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc306, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 15 ms on hcdnc310 (3/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 15 ms on hcdnc306 (4/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc310, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc310 (5/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc306, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc306 (6/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc310, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc310 (7/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc306, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 14 ms on hcdnc306 (8/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc310 (9/10)%%0001017/07/18 00:29:23 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 13 ms on hcdnc306 (10/10)%%0001017/07/18 00:29:23 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:29:23 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:23 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.847861 s%%0001017/07/18 00:29:23 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:29:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:29:23 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:29:23 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:29:23 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:29:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:29:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:29:23 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:29:23 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288480, maxMem=556038881%%0001017/07/18 00:29:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:29:23 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300720, maxMem=556038881%%0001017/07/18 00:29:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:40102 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:29:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:29:23 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc306, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:29:23 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc310, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc306:60560 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc310:39840 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:29:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc306:41062%%0001017/07/18 00:29:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc310:50642%%0001017/07/18 00:29:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 9753 ms on hcdnc306 (1/2)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10223 ms on hcdnc310 (2/2)%%0001017/07/18 00:29:34 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:34 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.225 s%%0001017/07/18 00:29:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:29:34 INFO DAGScheduler: running: Set()%%0001017/07/18 00:29:34 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:29:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:29:34 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:29:34 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:29:34 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307467, maxMem=556038881%%0001017/07/18 00:29:34 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:29:34 INFO MemoryStore: ensureFreeSpace(7999) called with curMem=322627, maxMem=556038881%%0001017/07/18 00:29:34 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:29:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:40102 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:29:34 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:29:34 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:29:34 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc306, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc310, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc310:39840 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:29:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc306:60560 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:29:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc310:50642%%0001017/07/18 00:29:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 157 bytes%%0001017/07/18 00:29:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc306:41062%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc306, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 430 ms on hcdnc306 (1/10)%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc310, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 458 ms on hcdnc310 (2/10)%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc310, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 329 ms on hcdnc310 (3/10)%%0001017/07/18 00:29:34 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc306, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:34 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 364 ms on hcdnc306 (4/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc306, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 264 ms on hcdnc306 (5/10)%%0001017/07/18 00:29:35 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:29:35 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc310, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 289 ms on hcdnc310 (6/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc306, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 301 ms on hcdnc306 (7/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc310, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 342 ms on hcdnc310 (8/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 291 ms on hcdnc306 (9/10)%%0001017/07/18 00:29:35 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 327 ms on hcdnc310 (10/10)%%0001017/07/18 00:29:35 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:29:35 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.744 s%%0001017/07/18 00:29:35 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 11.993336 s%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:29:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:29:35 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:29:35 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:29:35 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:29:35 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:29:35 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:29:36 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:29:36 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:39596] &lt;- [akka.tcp://sparkExecutor@hcdnc310:50642]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc310:50642] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc310:50642%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:29:36 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:39596] &lt;- [akka.tcp://sparkExecutor@hcdnc306:41062]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc306:41062] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc306:41062%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:29:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:29:36 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:29:36 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:29:36 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:29:36 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:29:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:29:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:29:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:29:36 INFO Remoting: Remoting shut down%%0001017/07/18 00:29:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:29:37 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:29:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-2e6972b4-ab35-4126-8f6f-f336737ab153/pyspark-401c86a6-32ef-48be-9322-bf5d3e795ed1%%0001017/07/18 00:29:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-2e6972b4-ab35-4126-8f6f-f336737ab153%%00010"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:29:50 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:29:51 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:29:51 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:29:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:29:51 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:29:51 INFO Remoting: Starting remoting%%0001017/07/18 00:29:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:40473]%%0001017/07/18 00:29:52 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:40473]%%0001017/07/18 00:29:52 INFO Utils: Successfully started service 'sparkDriver' on port 40473.%%0001017/07/18 00:29:52 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:29:52 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:29:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a3c7c9c1-a98b-46be-82b9-721f621d8b9f%%0001017/07/18 00:29:52 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:29:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3f3a6aaa-45f4-405c-a207-6a863176a7c9/httpd-fe177d3a-e3a9-4931-bfbc-831f4e39aa0d%%0001017/07/18 00:29:52 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:29:52 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:29:52 INFO AbstractConnector: Started SocketConnector@0.0.0.0:39996%%0001017/07/18 00:29:52 INFO Utils: Successfully started service 'HTTP file server' on port 39996.%%0001017/07/18 00:29:52 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:29:53 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:29:53 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:29:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:29:53 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:29:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:29:53 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:29:53 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:29:53 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:29:53 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:29:53 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:29:53 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:29:53 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:29:53 INFO Client: Uploading resource file:/tmp/spark-3f3a6aaa-45f4-405c-a207-6a863176a7c9/__spark_conf__2778156201442387549.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22110/__spark_conf__2778156201442387549.zip%%0001017/07/18 00:29:54 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:29:54 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:29:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:29:54 INFO Client: Submitting application 22110 to ResourceManager%%0001017/07/18 00:29:54 INFO YarnClientImpl: Submitted application application_1491786134915_22110%%0001017/07/18 00:29:55 INFO Client: Application report for application_1491786134915_22110 (state: ACCEPTED)%%0001017/07/18 00:29:55 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308994322%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22110/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:29:56 INFO Client: Application report for application_1491786134915_22110 (state: ACCEPTED)%%0001017/07/18 00:29:57 INFO Client: Application report for application_1491786134915_22110 (state: ACCEPTED)%%0001017/07/18 00:29:57 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.13:54596/user/YarnAM#-2041315916])%%0001017/07/18 00:29:57 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22110,http://hcnnc117:8088/proxy/application_1491786134915_22110), /proxy/application_1491786134915_22110%%0001017/07/18 00:29:57 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:29:58 INFO Client: Application report for application_1491786134915_22110 (state: RUNNING)%%0001017/07/18 00:29:58 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.13%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500308994322%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22110/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:29:58 INFO YarnClientSchedulerBackend: Application application_1491786134915_22110 has started running.%%0001017/07/18 00:29:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38098.%%0001017/07/18 00:29:58 INFO NettyBlockTransferService: Server created on 38098%%0001017/07/18 00:29:58 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:29:58 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:29:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:38098 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 38098)%%0001017/07/18 00:29:58 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:29:59 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22110%%0001017/07/18 00:29:59 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:29:59 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:29:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:29:59 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:29:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:29:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:38098 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:29:59 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:30:00 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.8:50010%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /hc02/172.16.2.30:50010%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.14:50010%%0001017/07/18 00:30:00 INFO NetworkTopology: Adding a new node: /hc04/172.16.4.32:50010%%0001017/07/18 00:30:00 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:30:00 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:30:00 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:30:00 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:30:00 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:30:00 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:30:00 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:30:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:30:00 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:30:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:30:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:38098 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:30:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:30:00 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:30:01 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:30:02 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:30:03 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40473] &lt;- [akka.tcp://driverPropsFetcher@hcdnc338:43711]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc338:43711] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc338:43711%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:30:04 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc338:37584/user/Executor#-776793589]) with ID 1%%0001017/07/18 00:30:04 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:30:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc338, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:30:04 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc338:33544 with 530.0 MB RAM, BlockManagerId(1, hcdnc338, 33544)%%0001017/07/18 00:30:04 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40473] &lt;- [akka.tcp://driverPropsFetcher@hcdnc211:43289]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc211:43289] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc211:43289%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:30:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc338:33544 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:30:05 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc211:38783/user/Executor#1727604213]) with ID 2%%0001017/07/18 00:30:05 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:30:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc211, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:30:05 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc211:58129 with 530.0 MB RAM, BlockManagerId(2, hcdnc211, 58129)%%0001017/07/18 00:30:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc338:33544 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:30:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc211:58129 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:30:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc211:58129 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:30:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12252 ms on hcdnc338 (1/2)%%0001017/07/18 00:30:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11740 ms on hcdnc211 (2/2)%%0001017/07/18 00:30:16 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 16.786 s%%0001017/07/18 00:30:16 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:16 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 16.908863 s%%0001017/07/18 00:30:17 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:30:17 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:30:17 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:30:17 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:30:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:30:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:30:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:30:17 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:30:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:30:17 INFO MemoryStore: ensureFreeSpace(5304) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:30:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:30:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:38098 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:30:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:30:17 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:30:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc211, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:30:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc338, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:30:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc211:58129 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:30:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc338:33544 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:30:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17344 ms on hcdnc338 (1/2)%%0001017/07/18 00:30:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17395 ms on hcdnc211 (2/2)%%0001017/07/18 00:30:34 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:34 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.395 s%%0001017/07/18 00:30:34 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:30:34 INFO DAGScheduler: running: Set()%%0001017/07/18 00:30:34 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:30:34 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:30:34 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:30:34 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:30:34 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251359, maxMem=556038881%%0001017/07/18 00:30:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:30:34 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258295, maxMem=556038881%%0001017/07/18 00:30:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:30:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:38098 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:30:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:30:34 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:30:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc338, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc211, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc211:58129 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:30:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc338:33544 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:30:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc211:38783%%0001017/07/18 00:30:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:30:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc338:37584%%0001017/07/18 00:30:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1419 ms on hcdnc338 (1/2)%%0001017/07/18 00:30:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1422 ms on hcdnc211 (2/2)%%0001017/07/18 00:30:35 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:35 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.423 s%%0001017/07/18 00:30:35 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 18.849706 s%%0001017/07/18 00:30:35 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:30:35 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:30:35 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:30:35 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:30:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:30:35 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:30:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:30:35 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262338, maxMem=556038881%%0001017/07/18 00:30:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:30:35 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268858, maxMem=556038881%%0001017/07/18 00:30:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:30:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:38098 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:30:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:30:35 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:30:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc211, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:35 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc338, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc211:58129 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:30:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc338:33544 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:30:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2727 ms on hcdnc211 (1/2)%%0001017/07/18 00:30:38 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2776 ms on hcdnc338 (2/2)%%0001017/07/18 00:30:38 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:38 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.777 s%%0001017/07/18 00:30:38 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.790647 s%%0001017/07/18 00:30:38 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:30:38 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:30:38 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:30:38 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:30:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:30:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:30:38 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:30:38 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272760, maxMem=556038881%%0001017/07/18 00:30:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:30:38 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279936, maxMem=556038881%%0001017/07/18 00:30:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:30:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:38098 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:30:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:30:38 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:30:38 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc211, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:30:38 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc338, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:30:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc211:58129 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:30:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc338:33544 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2811 ms on hcdnc338 (1/2)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2826 ms on hcdnc211 (2/2)%%0001017/07/18 00:30:41 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:41 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.827 s%%0001017/07/18 00:30:41 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:30:41 INFO DAGScheduler: running: Set()%%0001017/07/18 00:30:41 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:30:41 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:30:41 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:30:41 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:30:41 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284085, maxMem=556038881%%0001017/07/18 00:30:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:30:41 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286869, maxMem=556038881%%0001017/07/18 00:30:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:38098 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:30:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:30:41 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc211, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc338, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc338:33544 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc211:58129 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc338:37584%%0001017/07/18 00:30:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 166 bytes%%0001017/07/18 00:30:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc211:38783%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc338, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 47 ms on hcdnc338 (1/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc211, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 50 ms on hcdnc211 (2/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc338, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc211, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 18 ms on hcdnc338 (3/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 16 ms on hcdnc211 (4/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc338, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc211, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 19 ms on hcdnc338 (5/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 19 ms on hcdnc211 (6/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc338, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc211, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 16 ms on hcdnc338 (7/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 16 ms on hcdnc211 (8/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 15 ms on hcdnc338 (9/10)%%0001017/07/18 00:30:41 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 14 ms on hcdnc211 (10/10)%%0001017/07/18 00:30:41 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.110 s%%0001017/07/18 00:30:41 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:41 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.958702 s%%0001017/07/18 00:30:41 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:30:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 154 bytes%%0001017/07/18 00:30:41 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:30:41 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:30:41 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:30:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:30:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:30:41 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:30:41 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288482, maxMem=556038881%%0001017/07/18 00:30:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:30:41 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300722, maxMem=556038881%%0001017/07/18 00:30:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:38098 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:30:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:30:41 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc211, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:30:41 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc338, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc338:33544 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc211:58129 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:30:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc338:37584%%0001017/07/18 00:30:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc211:38783%%0001017/07/18 00:30:51 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 9518 ms on hcdnc211 (1/2)%%0001017/07/18 00:30:51 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10064 ms on hcdnc338 (2/2)%%0001017/07/18 00:30:51 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:51 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.065 s%%0001017/07/18 00:30:51 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:30:51 INFO DAGScheduler: running: Set()%%0001017/07/18 00:30:51 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:30:51 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:30:51 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:30:51 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:30:51 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307469, maxMem=556038881%%0001017/07/18 00:30:51 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:30:51 INFO MemoryStore: ensureFreeSpace(7998) called with curMem=322629, maxMem=556038881%%0001017/07/18 00:30:51 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:30:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:38098 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:30:51 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:30:51 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:30:51 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:30:51 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc338, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:51 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc211, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc338:33544 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:30:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc211:58129 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:30:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc338:37584%%0001017/07/18 00:30:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 158 bytes%%0001017/07/18 00:30:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc211:38783%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc338, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 500 ms on hcdnc338 (1/10)%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc211, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 586 ms on hcdnc211 (2/10)%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc338, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 305 ms on hcdnc338 (3/10)%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc211, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 293 ms on hcdnc211 (4/10)%%0001017/07/18 00:30:52 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:30:52 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc338, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:52 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 314 ms on hcdnc338 (5/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc211, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 284 ms on hcdnc211 (6/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc338, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 295 ms on hcdnc338 (7/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc211, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 337 ms on hcdnc211 (8/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 325 ms on hcdnc338 (9/10)%%0001017/07/18 00:30:53 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 329 ms on hcdnc211 (10/10)%%0001017/07/18 00:30:53 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:30:53 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.827 s%%0001017/07/18 00:30:53 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 11.937840 s%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:30:53 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:30:53 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:30:53 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:30:53 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:30:53 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:30:53 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:30:53 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:30:53 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40473] &lt;- [akka.tcp://sparkExecutor@hcdnc338:37584]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc338:37584] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc338:37584%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:30:53 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:40473] &lt;- [akka.tcp://sparkExecutor@hcdnc211:38783]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc211:38783] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc211:38783%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:30:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:30:54 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:30:54 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:30:54 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:30:54 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:30:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:30:54 INFO Remoting: Remoting shut down%%0001017/07/18 00:30:54 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:30:54 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:30:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-3f3a6aaa-45f4-405c-a207-6a863176a7c9%%00010"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:31:08 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:31:09 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:09 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:31:09 INFO Remoting: Starting remoting%%0001017/07/18 00:31:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'sparkDriver' on port 46770.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:31:10 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:31:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b6392a2-47ca-486d-968a-86100bba3ed5%%0001017/07/18 00:31:10 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:31:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/httpd-35660a11-7a6a-4a04-b2a3-fc476816b481%%0001017/07/18 00:31:10 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:10 INFO AbstractConnector: Started SocketConnector@0.0.0.0:32841%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'HTTP file server' on port 32841.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:11 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:31:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:31:11 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:31:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:31:11 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:31:11 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:31:11 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:31:11 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:31:11 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:31:11 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:31:11 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:31:12 INFO Client: Uploading resource file:/tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/__spark_conf__6961910960617804988.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22111/__spark_conf__6961910960617804988.zip%%0001017/07/18 00:31:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:12 INFO Client: Submitting application 22111 to ResourceManager%%0001017/07/18 00:31:12 INFO YarnClientImpl: Submitted application application_1491786134915_22111%%0001017/07/18 00:31:13 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:13 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:14 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:15 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:51470/user/YarnAM#-1905692386])%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22111,http://hcnnc117:8088/proxy/application_1491786134915_22111), /proxy/application_1491786134915_22111%%0001017/07/18 00:31:15 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:31:15 INFO Client: Application report for application_1491786134915_22111 (state: RUNNING)%%0001017/07/18 00:31:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Application application_1491786134915_22111 has started running.%%0001017/07/18 00:31:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41687.%%0001017/07/18 00:31:15 INFO NettyBlockTransferService: Server created on 41687%%0001017/07/18 00:31:15 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:31:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41687 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41687)%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:31:16 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22111%%0001017/07/18 00:31:16 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41687 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:31:16 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.23:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.7:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.25:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.26:50010%%0001017/07/18 00:31:16 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:31:16 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:31:16 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:31:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:31:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:31:20 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:34646]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:20 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:56029/user/Executor#150168492]) with ID 1%%0001017/07/18 00:31:20 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:31:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc304, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:20 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:34185 with 530.0 MB RAM, BlockManagerId(1, hcdnc304, 34185)%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc336:54707]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:34185 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc336:34477/user/Executor#-848880720]) with ID 2%%0001017/07/18 00:31:21 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:31:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc336, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:21 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc336:44962 with 530.0 MB RAM, BlockManagerId(2, hcdnc336, 44962)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc336:44962 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12285 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12246 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 17.038 s%%0001017/07/18 00:31:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.158571 s%%0001017/07/18 00:31:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:31:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:31:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41687 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:31:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc304, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc336, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc336:44962 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:34185 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17613 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17625 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:51 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:51 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.628 s%%0001017/07/18 00:31:51 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:51 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:31:51 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:31:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:51 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1397 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1400 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.400 s%%0001017/07/18 00:31:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.060293 s%%0001017/07/18 00:31:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:31:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:31:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:31:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:31:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:31:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41687 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:31:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:31:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:34185 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc336:44962 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2566 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:56 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2767 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:56 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:56 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.769 s%%0001017/07/18 00:31:56 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.781932 s%%0001017/07/18 00:31:56 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:31:56 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:31:56 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:31:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41687 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:31:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc336:44962 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:34185 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2703 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2776 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.777 s%%0001017/07/18 00:31:58 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:58 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:31:58 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41687 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:31:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:31:58 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc336:44962 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:34185 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc336:34477%%0001017/07/18 00:31:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:56029%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc336, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc336 (1/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc304 (2/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc336, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc336 (3/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc304, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc304 (4/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc336, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc336 (5/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc304 (6/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc336, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc336 (7/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 12 ms on hcdnc304 (8/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc336 (9/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 12 ms on hcdnc304 (10/10)%%0001017/07/18 00:31:58 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.901611 s%%0001017/07/18 00:31:59 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:31:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:59 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:31:59 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:31:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288480, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300720, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41687 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:31:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc336:44962 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:34185 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 10438 ms on hcdnc336 (1/2)%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10676 ms on hcdnc304 (2/2)%%0001017/07/18 00:32:09 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:09 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.677 s%%0001017/07/18 00:32:09 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:32:09 INFO DAGScheduler: running: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:32:09 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307467, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(7999) called with curMem=322627, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41687 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:32:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:32:09 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:34185 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc336:44962 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc336:34477%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 444 ms on hcdnc304 (1/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc336, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 480 ms on hcdnc336 (2/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 313 ms on hcdnc304 (3/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc336, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 357 ms on hcdnc336 (4/10)%%0001017/07/18 00:32:10 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 356 ms on hcdnc304 (5/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc336, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 323 ms on hcdnc336 (6/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 286 ms on hcdnc304 (7/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc336, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 393 ms on hcdnc336 (8/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 322 ms on hcdnc304 (9/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 346 ms on hcdnc336 (10/10)%%0001017/07/18 00:32:11 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:11 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.894 s%%0001017/07/18 00:32:11 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 12.597608 s%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:32:11 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:32:11 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc336:34477]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc304:56029]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:32:11 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:32:11 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:32:11 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:32:11 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:32:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:32:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:32:12 INFO Remoting: Remoting shut down%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443%%00010"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_2">
<entry key="column_name" type="xstring" value="FailingNode"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Bash"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_3">
<entry key="column_name" type="xstring" value="currentIteration"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.IntCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="8"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_4">
<entry key="column_name" type="xstring" value="maxIterations"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.IntCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="9"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.IntCell"/>
<config key="org.knime.core.data.def.IntCell">
<entry key="IntCell" type="xint" value="9"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_5">
<entry key="column_name" type="xstring" value="index_of_drugColumn"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="4.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="4.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_6">
<entry key="column_name" type="xstring" value="minSupport"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.005"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.009999999999999998"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_7">
<entry key="column_name" type="xstring" value="minConfidence"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.2"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.4000000000000001"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_8">
<entry key="column_name" type="xstring" value="cmd"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.005 0.2"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.005 0.3"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.005 0.4"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.0075 0.2"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.0075 0.3"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.0075 0.4"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.01 0.2"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.01 0.3"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32  spark-submit TCMAnalyzer2.py /home_i1/y23ycc01/incoming/tid.acne.csv 4 0.01 0.4"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_9">
<entry key="column_name" type="xstring" value="RowID"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="9"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="0"/>
</config>
</config>
<config key="1">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1"/>
</config>
</config>
<config key="2">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="2"/>
</config>
</config>
<config key="3">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="3"/>
</config>
</config>
<config key="4">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="4"/>
</config>
</config>
<config key="5">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="5"/>
</config>
</config>
<config key="6">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="6"/>
</config>
</config>
<config key="7">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="7"/>
</config>
</config>
<config key="8">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="8"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_10">
<entry key="column_name" type="xstring" value="config_host_ip"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="140.110.30.32"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_11">
<entry key="column_name" type="xstring" value="task_minConfidenceLower"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="20.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="20.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_12">
<entry key="column_name" type="xstring" value="task_local_attr_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.feature.TCM.summary.level123.QiFlavorMeri.20170621.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_13">
<entry key="column_name" type="xstring" value="config_password"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1q2w3e4r"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_14">
<entry key="column_name" type="xstring" value="config_local_NHIcode_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.TCM.HF_SH.20170703.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_15">
<entry key="column_name" type="xstring" value="config_local_metadata_fullpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_16">
<entry key="column_name" type="xstring" value="task_minConfidenceStep"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="10.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="10.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_17">
<entry key="column_name" type="xstring" value="task_local_keyword_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.keyword.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_18">
<entry key="column_name" type="xstring" value="task_drugColumnIndex"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="4.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="4.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_19">
<entry key="column_name" type="xstring" value="task_updateCachedDataFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_20">
<entry key="column_name" type="xstring" value="task_name_Ch"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="痤瘡(青春痘)中醫治療圖譜"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_21">
<entry key="column_name" type="xstring" value="config_local_output_fullpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData/Sample"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_22">
<entry key="column_name" type="xstring" value="task_minSupportUpper"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="1.25"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="1.25"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_23">
<entry key="column_name" type="xstring" value="task_local_cachedData_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.cachedData.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_24">
<entry key="column_name" type="xstring" value="task_updateCachedPubmedFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="N"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_25">
<entry key="column_name" type="xstring" value="task_name"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="ACNE"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_26">
<entry key="column_name" type="xstring" value="task_minConfidenceUpper"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="50.0"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="50.0"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_27">
<entry key="column_name" type="xstring" value="config_local_translation_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.NAME.translation_shortform.20170625.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_28">
<entry key="column_name" type="xstring" value="task_local_translation_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.NAME.translation_shortform.20170625.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_29">
<entry key="column_name" type="xstring" value="config_graphspace_id"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="yuchn.chen@gmail.com"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_30">
<entry key="column_name" type="xstring" value="task_local_NHIcode_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.DRUG.TCM.HF_SH.20170703.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_31">
<entry key="column_name" type="xstring" value="config_graphspace_pwd"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="1q2w3e4r"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_32">
<entry key="column_name" type="xstring" value="task_local_cachedPubmed_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:/Dropbox/1.Projects/Cytoscape/testData\metadata.cachedPubmed.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_33">
<entry key="column_name" type="xstring" value="config_local_cachedData_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.cachedData.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_34">
<entry key="column_name" type="xstring" value="task_remote_srcFilemname"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="/home_i1/y23ycc01/incoming/tid.acne.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_35">
<entry key="column_name" type="xstring" value="config_local_cachedPubmed_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.cachedPubmed.knime"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_36">
<entry key="column_name" type="xstring" value="task_remote_srcFilepath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="/home_i1/y23ycc01/incoming"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_37">
<entry key="column_name" type="xstring" value="config_user_id"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="y23ycc01"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_38">
<entry key="column_name" type="xstring" value="task_forceReanalyze"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_39">
<entry key="column_name" type="xstring" value="config_workpath"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="incoming"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_40">
<entry key="column_name" type="xstring" value="task_reuploadSrcFile"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="Y"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_41">
<entry key="column_name" type="xstring" value="task_minSupportLower"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.5"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.5"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_42">
<entry key="column_name" type="xstring" value="config_local_keyword_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.keyword.tab"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_43">
<entry key="column_name" type="xstring" value="task_minSupportStep"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
</config>
<config key="column_domain">
<config key="lower_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.25"/>
</config>
</config>
<config key="upper_bound">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.DoubleCell"/>
<config key="org.knime.core.data.def.DoubleCell">
<entry key="DoubleCell" type="xdouble" value="0.25"/>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_44">
<entry key="column_name" type="xstring" value="config_local_attr_filename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="metadata.DRUG.feature.TCM.summary.level123.QiFlavorMeri.20170621.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_45">
<entry key="column_name" type="xstring" value="task_srcFileExt"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value=".csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_46">
<entry key="column_name" type="xstring" value="task_srcFilename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="tid.acne"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_47">
<entry key="column_name" type="xstring" value="task_srcDirectory"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Dropbox\1.Projects\Cytoscape\testData\Sample"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_48">
<entry key="column_name" type="xstring" value="task_local_srcfilename"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Dropbox\1.Projects\Cytoscape\testData\Sample\tid.acne.csv"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
<config key="column_spec_49">
<entry key="column_name" type="xstring" value="knime.workspace"/>
<config key="element_names">
<entry key="array-size" type="xint" value="0"/>
</config>
<config key="column_type">
<entry key="cell_class" type="xstring" value="org.knime.core.data.def.StringCell"/>
</config>
<config key="column_domain">
<config key="possible_values">
<entry key="array-size" type="xint" value="1"/>
<config key="0">
<entry key="datacell" type="xstring" value="org.knime.core.data.def.StringCell"/>
<config key="org.knime.core.data.def.StringCell">
<entry key="StringCell" type="xstring" value="C:\Users\yuchn\knime-workspace"/>
</config>
</config>
</config>
</config>
<config key="column_properties"/>
</config>
</config>
