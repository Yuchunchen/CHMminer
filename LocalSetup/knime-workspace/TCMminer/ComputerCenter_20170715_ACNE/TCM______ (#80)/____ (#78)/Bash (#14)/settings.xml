<?xml version="1.0" encoding="UTF-8"?>
<config xmlns="http://www.knime.org/2008/09/XMLConfig" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.knime.org/2008/09/XMLConfig http://www.knime.org/XMLConfig_2008_09.xsd" key="settings.xml">
<entry key="node_file" type="xstring" value="settings.xml"/>
<config key="flow_stack">
<config key="Variable_0">
<entry key="type" type="xstring" value="variable"/>
<entry key="name" type="xstring" value="_error_caught"/>
<entry key="class" type="xstring" value="INTEGER"/>
<entry key="value" type="xint" value="1"/>
</config>
<config key="Variable_1">
<entry key="type" type="xstring" value="variable"/>
<entry key="name" type="xstring" value="_error_node"/>
<entry key="class" type="xstring" value="STRING"/>
<entry key="value" type="xstring" value="Bash"/>
</config>
<config key="Variable_2">
<entry key="type" type="xstring" value="variable"/>
<entry key="name" type="xstring" value="_error_reason"/>
<entry key="class" type="xstring" value="STRING"/>
<entry key="value" type="xstring" value="STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:31:08 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:31:09 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:09 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:31:09 INFO Remoting: Starting remoting%%0001017/07/18 00:31:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'sparkDriver' on port 46770.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:31:10 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:31:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b6392a2-47ca-486d-968a-86100bba3ed5%%0001017/07/18 00:31:10 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:31:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/httpd-35660a11-7a6a-4a04-b2a3-fc476816b481%%0001017/07/18 00:31:10 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:10 INFO AbstractConnector: Started SocketConnector@0.0.0.0:32841%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'HTTP file server' on port 32841.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:11 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:31:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:31:11 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:31:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:31:11 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:31:11 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:31:11 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:31:11 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:31:11 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:31:11 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:31:11 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:31:12 INFO Client: Uploading resource file:/tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/__spark_conf__6961910960617804988.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22111/__spark_conf__6961910960617804988.zip%%0001017/07/18 00:31:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:12 INFO Client: Submitting application 22111 to ResourceManager%%0001017/07/18 00:31:12 INFO YarnClientImpl: Submitted application application_1491786134915_22111%%0001017/07/18 00:31:13 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:13 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:14 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:15 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:51470/user/YarnAM#-1905692386])%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22111,http://hcnnc117:8088/proxy/application_1491786134915_22111), /proxy/application_1491786134915_22111%%0001017/07/18 00:31:15 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:31:15 INFO Client: Application report for application_1491786134915_22111 (state: RUNNING)%%0001017/07/18 00:31:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Application application_1491786134915_22111 has started running.%%0001017/07/18 00:31:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41687.%%0001017/07/18 00:31:15 INFO NettyBlockTransferService: Server created on 41687%%0001017/07/18 00:31:15 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:31:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41687 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41687)%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:31:16 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22111%%0001017/07/18 00:31:16 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41687 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:31:16 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.23:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.7:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.25:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.26:50010%%0001017/07/18 00:31:16 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:31:16 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:31:16 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:31:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:31:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:31:20 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:34646]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:20 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:56029/user/Executor#150168492]) with ID 1%%0001017/07/18 00:31:20 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:31:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc304, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:20 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:34185 with 530.0 MB RAM, BlockManagerId(1, hcdnc304, 34185)%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc336:54707]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:34185 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc336:34477/user/Executor#-848880720]) with ID 2%%0001017/07/18 00:31:21 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:31:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc336, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:21 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc336:44962 with 530.0 MB RAM, BlockManagerId(2, hcdnc336, 44962)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc336:44962 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12285 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12246 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 17.038 s%%0001017/07/18 00:31:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.158571 s%%0001017/07/18 00:31:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:31:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:31:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41687 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:31:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc304, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc336, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc336:44962 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:34185 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17613 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17625 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:51 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:51 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.628 s%%0001017/07/18 00:31:51 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:51 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:31:51 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:31:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:51 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1397 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1400 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.400 s%%0001017/07/18 00:31:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.060293 s%%0001017/07/18 00:31:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:31:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:31:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:31:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:31:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:31:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41687 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:31:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:31:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:34185 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc336:44962 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2566 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:56 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2767 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:56 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:56 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.769 s%%0001017/07/18 00:31:56 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.781932 s%%0001017/07/18 00:31:56 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:31:56 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:31:56 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:31:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41687 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:31:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc336:44962 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:34185 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2703 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2776 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.777 s%%0001017/07/18 00:31:58 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:58 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:31:58 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41687 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:31:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:31:58 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc336:44962 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:34185 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc336:34477%%0001017/07/18 00:31:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:56029%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc336, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc336 (1/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc304 (2/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc336, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc336 (3/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc304, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc304 (4/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc336, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc336 (5/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc304 (6/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc336, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc336 (7/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 12 ms on hcdnc304 (8/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc336 (9/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 12 ms on hcdnc304 (10/10)%%0001017/07/18 00:31:58 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.901611 s%%0001017/07/18 00:31:59 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:31:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:59 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:31:59 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:31:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288480, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300720, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41687 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:31:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc336:44962 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:34185 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 10438 ms on hcdnc336 (1/2)%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10676 ms on hcdnc304 (2/2)%%0001017/07/18 00:32:09 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:09 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.677 s%%0001017/07/18 00:32:09 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:32:09 INFO DAGScheduler: running: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:32:09 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307467, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(7999) called with curMem=322627, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41687 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:32:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:32:09 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:34185 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc336:44962 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc336:34477%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 444 ms on hcdnc304 (1/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc336, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 480 ms on hcdnc336 (2/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 313 ms on hcdnc304 (3/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc336, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 357 ms on hcdnc336 (4/10)%%0001017/07/18 00:32:10 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 356 ms on hcdnc304 (5/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc336, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 323 ms on hcdnc336 (6/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 286 ms on hcdnc304 (7/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc336, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 393 ms on hcdnc336 (8/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 322 ms on hcdnc304 (9/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 346 ms on hcdnc336 (10/10)%%0001017/07/18 00:32:11 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:11 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.894 s%%0001017/07/18 00:32:11 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 12.597608 s%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:32:11 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:32:11 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc336:34477]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc304:56029]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:32:11 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:32:11 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:32:11 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:32:11 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:32:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:32:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:32:12 INFO Remoting: Remoting shut down%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443%%00010"/>
</config>
<config key="Variable_3">
<entry key="type" type="xstring" value="variable"/>
<entry key="name" type="xstring" value="_error_stacktrace"/>
<entry key="class" type="xstring" value="STRING"/>
<entry key="value" type="xstring" value="org.pasteur.pf2.tools.InterruptedExecutionException: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:31:08 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:31:09 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:09 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:31:09 INFO Remoting: Starting remoting%%0001017/07/18 00:31:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'sparkDriver' on port 46770.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:31:10 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:31:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b6392a2-47ca-486d-968a-86100bba3ed5%%0001017/07/18 00:31:10 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:31:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/httpd-35660a11-7a6a-4a04-b2a3-fc476816b481%%0001017/07/18 00:31:10 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:10 INFO AbstractConnector: Started SocketConnector@0.0.0.0:32841%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'HTTP file server' on port 32841.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:11 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:31:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:31:11 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:31:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:31:11 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:31:11 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:31:11 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:31:11 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:31:11 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:31:11 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:31:11 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:31:12 INFO Client: Uploading resource file:/tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/__spark_conf__6961910960617804988.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22111/__spark_conf__6961910960617804988.zip%%0001017/07/18 00:31:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:12 INFO Client: Submitting application 22111 to ResourceManager%%0001017/07/18 00:31:12 INFO YarnClientImpl: Submitted application application_1491786134915_22111%%0001017/07/18 00:31:13 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:13 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:14 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:15 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:51470/user/YarnAM#-1905692386])%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22111,http://hcnnc117:8088/proxy/application_1491786134915_22111), /proxy/application_1491786134915_22111%%0001017/07/18 00:31:15 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:31:15 INFO Client: Application report for application_1491786134915_22111 (state: RUNNING)%%0001017/07/18 00:31:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Application application_1491786134915_22111 has started running.%%0001017/07/18 00:31:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41687.%%0001017/07/18 00:31:15 INFO NettyBlockTransferService: Server created on 41687%%0001017/07/18 00:31:15 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:31:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41687 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41687)%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:31:16 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22111%%0001017/07/18 00:31:16 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41687 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:31:16 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.23:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.7:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.25:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.26:50010%%0001017/07/18 00:31:16 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:31:16 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:31:16 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:31:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:31:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:31:20 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:34646]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:20 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:56029/user/Executor#150168492]) with ID 1%%0001017/07/18 00:31:20 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:31:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc304, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:20 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:34185 with 530.0 MB RAM, BlockManagerId(1, hcdnc304, 34185)%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc336:54707]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:34185 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc336:34477/user/Executor#-848880720]) with ID 2%%0001017/07/18 00:31:21 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:31:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc336, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:21 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc336:44962 with 530.0 MB RAM, BlockManagerId(2, hcdnc336, 44962)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc336:44962 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12285 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12246 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 17.038 s%%0001017/07/18 00:31:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.158571 s%%0001017/07/18 00:31:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:31:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:31:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41687 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:31:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc304, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc336, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc336:44962 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:34185 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17613 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17625 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:51 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:51 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.628 s%%0001017/07/18 00:31:51 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:51 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:31:51 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:31:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:51 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1397 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1400 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.400 s%%0001017/07/18 00:31:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.060293 s%%0001017/07/18 00:31:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:31:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:31:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:31:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:31:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:31:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41687 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:31:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:31:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:34185 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc336:44962 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2566 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:56 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2767 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:56 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:56 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.769 s%%0001017/07/18 00:31:56 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.781932 s%%0001017/07/18 00:31:56 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:31:56 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:31:56 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:31:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41687 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:31:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc336:44962 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:34185 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2703 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2776 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.777 s%%0001017/07/18 00:31:58 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:58 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:31:58 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41687 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:31:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:31:58 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc336:44962 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:34185 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc336:34477%%0001017/07/18 00:31:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:56029%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc336, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc336 (1/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc304 (2/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc336, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc336 (3/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc304, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc304 (4/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc336, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc336 (5/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc304 (6/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc336, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc336 (7/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 12 ms on hcdnc304 (8/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc336 (9/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 12 ms on hcdnc304 (10/10)%%0001017/07/18 00:31:58 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.901611 s%%0001017/07/18 00:31:59 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:31:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:59 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:31:59 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:31:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288480, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300720, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41687 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:31:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc336:44962 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:34185 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 10438 ms on hcdnc336 (1/2)%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10676 ms on hcdnc304 (2/2)%%0001017/07/18 00:32:09 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:09 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.677 s%%0001017/07/18 00:32:09 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:32:09 INFO DAGScheduler: running: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:32:09 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307467, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(7999) called with curMem=322627, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41687 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:32:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:32:09 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:34185 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc336:44962 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc336:34477%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 444 ms on hcdnc304 (1/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc336, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 480 ms on hcdnc336 (2/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 313 ms on hcdnc304 (3/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc336, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 357 ms on hcdnc336 (4/10)%%0001017/07/18 00:32:10 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 356 ms on hcdnc304 (5/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc336, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 323 ms on hcdnc336 (6/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 286 ms on hcdnc304 (7/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc336, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 393 ms on hcdnc336 (8/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 322 ms on hcdnc304 (9/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 346 ms on hcdnc336 (10/10)%%0001017/07/18 00:32:11 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:11 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.894 s%%0001017/07/18 00:32:11 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 12.597608 s%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:32:11 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:32:11 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc336:34477]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc304:56029]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:32:11 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:32:11 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:32:11 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:32:11 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:32:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:32:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:32:12 INFO Remoting: Remoting shut down%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443%%00010%%00013%%00010%%00009at org.pasteur.pf2.tools.BashNodeModel.execute(BashNodeModel.java:151)%%00013%%00010%%00009at org.knime.core.node.NodeModel.execute(NodeModel.java:733)%%00013%%00010%%00009at org.knime.core.node.NodeModel.executeModel(NodeModel.java:567)%%00013%%00010%%00009at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1128)%%00013%%00010%%00009at org.knime.core.node.Node.execute(Node.java:915)%%00013%%00010%%00009at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:561)%%00013%%00010%%00009at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)%%00013%%00010%%00009at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)%%00013%%00010%%00009at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)%%00013%%00010%%00009at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)%%00013%%00010%%00009at java.util.concurrent.FutureTask.run(FutureTask.java:266)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:123)%%00013%%00010%%00009at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:246)%%00013%%00010"/>
</config>
</config>
<config key="internal_node_subsettings">
<entry key="memory_policy" type="xstring" value="CacheSmallInMemory"/>
</config>
<config key="model">
<config key="B_Cmd_Internals">
<entry key="SettingsModelID" type="xstring" value="SMID_string"/>
<entry key="EnabledStatus" type="xboolean" value="true"/>
</config>
<entry key="B_Cmd" type="xstring" value="klink -ssh -auto_store_sshkey -pw 1q2w3e4r y23ycc01@140.110.30.32 spark-submit TCMAnalyzer.py ~/incoming/GYN.OO.csv"/>
<config key="B_Path_Internals">
<entry key="SettingsModelID" type="xstring" value="SMID_string"/>
<entry key="EnabledStatus" type="xboolean" value="true"/>
</config>
<entry key="B_Path" type="xstring" value=""/>
<config key="B_err_Internals">
<entry key="SettingsModelID" type="xstring" value="SMID_boolean"/>
<entry key="EnabledStatus" type="xboolean" value="true"/>
</config>
<entry key="B_err" type="xboolean" value="true"/>
</config>
<config key="variables">
<config key="B_Cmd">
<entry key="used_variable" type="xstring" value="cmd"/>
<entry key="exposed_variable" type="xstring" isnull="true" value=""/>
</config>
</config>
<config key="nodeAnnotation">
<entry key="text" type="xstring" value="TCM analyzer"/>
<entry key="bgcolor" type="xint" value="16777215"/>
<entry key="x-coordinate" type="xint" value="273"/>
<entry key="y-coordinate" type="xint" value="182"/>
<entry key="width" type="xint" value="106"/>
<entry key="height" type="xint" value="15"/>
<entry key="alignment" type="xstring" value="CENTER"/>
<entry key="borderSize" type="xint" value="0"/>
<entry key="borderColor" type="xint" value="16777215"/>
<entry key="defFontSize" type="xint" value="9"/>
<entry key="annotation-version" type="xint" value="20151123"/>
<config key="styles"/>
</config>
<entry key="customDescription" type="xstring" isnull="true" value=""/>
<entry key="state" type="xstring" value="EXECUTED"/>
<config key="nodecontainer_message">
<entry key="type" type="xstring" value="ERROR"/>
<entry key="message" type="xstring" value="Execution failed in Try-Catch block: STDERR message:%%00010SLF4J: Class path contains multiple SLF4J bindings.%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/avro-tools-1.7.6-cdh5.5.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.5.1-1.cdh5.5.1.p0.11/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]%%00010SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.%%0001017/07/18 00:31:08 INFO SparkContext: Running Spark version 1.5.0-cdh5.5.1%%0001017/07/18 00:31:09 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:09 INFO Slf4jLogger: Slf4jLogger started%%0001017/07/18 00:31:09 INFO Remoting: Starting remoting%%0001017/07/18 00:31:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@172.16.1.12:46770]%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'sparkDriver' on port 46770.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering MapOutputTracker%%0001017/07/18 00:31:10 INFO SparkEnv: Registering BlockManagerMaster%%0001017/07/18 00:31:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b6392a2-47ca-486d-968a-86100bba3ed5%%0001017/07/18 00:31:10 INFO MemoryStore: MemoryStore started with capacity 530.3 MB%%0001017/07/18 00:31:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/httpd-35660a11-7a6a-4a04-b2a3-fc476816b481%%0001017/07/18 00:31:10 INFO HttpServer: Starting HTTP Server%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:10 INFO AbstractConnector: Started SocketConnector@0.0.0.0:32841%%0001017/07/18 00:31:10 INFO Utils: Successfully started service 'HTTP file server' on port 32841.%%0001017/07/18 00:31:10 INFO SparkEnv: Registering OutputCommitCoordinator%%0001017/07/18 00:31:10 INFO Server: jetty-8.y.z-SNAPSHOT%%0001017/07/18 00:31:11 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040%%0001017/07/18 00:31:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.%%0001017/07/18 00:31:11 INFO SparkUI: Started SparkUI at http://172.16.1.12:4040%%0001017/07/18 00:31:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.%%0001017/07/18 00:31:11 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm571%%0001017/07/18 00:31:11 INFO Client: Requesting a new application from cluster with 122 NodeManagers%%0001017/07/18 00:31:11 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (49152 MB per container)%%0001017/07/18 00:31:11 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead%%0001017/07/18 00:31:11 INFO Client: Setting up container launch context for our AM%%0001017/07/18 00:31:11 INFO Client: Setting up the launch environment for our AM container%%0001017/07/18 00:31:11 INFO Client: Preparing resources for our AM container%%0001017/07/18 00:31:12 INFO Client: Uploading resource file:/tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443/__spark_conf__6961910960617804988.zip -&gt; hdfs://nn/user/y23ycc01/.sparkStaging/application_1491786134915_22111/__spark_conf__6961910960617804988.zip%%0001017/07/18 00:31:12 INFO SecurityManager: Changing view acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: Changing modify acls to: y23ycc01%%0001017/07/18 00:31:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(y23ycc01); users with modify permissions: Set(y23ycc01)%%0001017/07/18 00:31:12 INFO Client: Submitting application 22111 to ResourceManager%%0001017/07/18 00:31:12 INFO YarnClientImpl: Submitted application application_1491786134915_22111%%0001017/07/18 00:31:13 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:13 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: N/A%%00010%%00009 ApplicationMaster RPC port: -1%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:14 INFO Client: Application report for application_1491786134915_22111 (state: ACCEPTED)%%0001017/07/18 00:31:15 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.16.2.35:51470/user/YarnAM#-1905692386])%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -&gt; hcnnc115,hcnnc117, PROXY_URI_BASES -&gt; http://hcnnc115:8088/proxy/application_1491786134915_22111,http://hcnnc117:8088/proxy/application_1491786134915_22111), /proxy/application_1491786134915_22111%%0001017/07/18 00:31:15 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter%%0001017/07/18 00:31:15 INFO Client: Application report for application_1491786134915_22111 (state: RUNNING)%%0001017/07/18 00:31:15 INFO Client: %%00010%%00009 client token: N/A%%00010%%00009 diagnostics: N/A%%00010%%00009 ApplicationMaster host: 172.16.2.35%%00010%%00009 ApplicationMaster RPC port: 0%%00010%%00009 queue: root.y23ycc01%%00010%%00009 start time: 1500309072642%%00010%%00009 final status: UNDEFINED%%00010%%00009 tracking URL: http://hcnnc117:8088/proxy/application_1491786134915_22111/%%00010%%00009 user: y23ycc01%%0001017/07/18 00:31:15 INFO YarnClientSchedulerBackend: Application application_1491786134915_22111 has started running.%%0001017/07/18 00:31:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41687.%%0001017/07/18 00:31:15 INFO NettyBlockTransferService: Server created on 41687%%0001017/07/18 00:31:15 INFO BlockManager: external shuffle service port = 7337%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Trying to register BlockManager%%0001017/07/18 00:31:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.1.12:41687 with 530.3 MB RAM, BlockManagerId(driver, 172.16.1.12, 41687)%%0001017/07/18 00:31:15 INFO BlockManagerMaster: Registered BlockManager%%0001017/07/18 00:31:16 INFO EventLoggingListener: Logging events to hdfs://nn/user/spark/applicationHistory/application_1491786134915_22111%%0001017/07/18 00:31:16 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(202768) called with curMem=0, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.0 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(23868) called with curMem=202768, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.1.12:41687 (size: 23.3 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2%%0001017/07/18 00:31:16 INFO FileInputFormat: Total input paths to process : 1%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.23:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc03/172.16.3.7:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /default/172.16.3.20:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.25:50010%%0001017/07/18 00:31:16 INFO NetworkTopology: Adding a new node: /hc08/172.16.8.26:50010%%0001017/07/18 00:31:16 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65%%0001017/07/18 00:31:16 INFO DAGScheduler: Got job 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) with 2 output partitions%%0001017/07/18 00:31:16 INFO DAGScheduler: Final stage: ResultStage 0(count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO DAGScheduler: Parents of final stage: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65), which has no missing parents%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(6792) called with curMem=226636, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.6 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO MemoryStore: ensureFreeSpace(3971) called with curMem=233428, maxMem=556038881%%0001017/07/18 00:31:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.1 MB)%%0001017/07/18 00:31:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.3 MB)%%0001017/07/18 00:31:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:65)%%0001017/07/18 00:31:16 INFO YarnScheduler: Adding task set 0.0 with 2 tasks%%0001017/07/18 00:31:18 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)%%0001017/07/18 00:31:19 INFO ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 2)%%0001017/07/18 00:31:20 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc304:34646]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc304:34646%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:20 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc304:56029/user/Executor#150168492]) with ID 1%%0001017/07/18 00:31:20 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)%%0001017/07/18 00:31:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, hcdnc304, partition 0,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:20 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc304:34185 with 530.0 MB RAM, BlockManagerId(1, hcdnc304, 34185)%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://driverPropsFetcher@hcdnc336:54707]: Error [Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://driverPropsFetcher@hcdnc336:54707%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:31:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc304:34185 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:21 INFO YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@hcdnc336:34477/user/Executor#-848880720]) with ID 2%%0001017/07/18 00:31:21 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)%%0001017/07/18 00:31:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, hcdnc336, partition 1,RACK_LOCAL, 2145 bytes)%%0001017/07/18 00:31:21 INFO BlockManagerMasterEndpoint: Registering block manager hcdnc336:44962 with 530.0 MB RAM, BlockManagerId(2, hcdnc336, 44962)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hcdnc336:44962 (size: 23.3 KB, free: 530.0 MB)%%0001017/07/18 00:31:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12285 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12246 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:34 INFO DAGScheduler: ResultStage 0 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:65) finished in 17.038 s%%0001017/07/18 00:31:34 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:34 INFO DAGScheduler: Job 0 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:65, took 17.158571 s%%0001017/07/18 00:31:34 INFO SparkContext: Starting job: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70%%0001017/07/18 00:31:34 INFO DAGScheduler: Registering RDD 4 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO DAGScheduler: Got job 1 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) with 2 output partitions%%0001017/07/18 00:31:34 INFO DAGScheduler: Final stage: ResultStage 2(count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69), which has no missing parents%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(8656) called with curMem=237399, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO MemoryStore: ensureFreeSpace(5302) called with curMem=246055, maxMem=556038881%%0001017/07/18 00:31:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.1.12:41687 (size: 5.2 KB, free: 530.2 MB)%%0001017/07/18 00:31:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[4] at combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69)%%0001017/07/18 00:31:34 INFO YarnScheduler: Adding task set 1.0 with 2 tasks%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, hcdnc304, partition 0,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, hcdnc336, partition 1,RACK_LOCAL, 2134 bytes)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc336:44962 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hcdnc304:34185 (size: 5.2 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 17613 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 17625 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:51 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:51 INFO DAGScheduler: ShuffleMapStage 1 (combineByKey at /home_i1/y23ycc01/TCMAnalyzer2.py:69) finished in 17.628 s%%0001017/07/18 00:31:51 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:51 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: waiting: Set(ResultStage 2)%%0001017/07/18 00:31:51 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:51 INFO DAGScheduler: Missing parents for ResultStage 2: List()%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70), which is now runnable%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(6936) called with curMem=251357, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO MemoryStore: ensureFreeSpace(4043) called with curMem=258293, maxMem=556038881%%0001017/07/18 00:31:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.1.12:41687 (size: 3.9 KB, free: 530.2 MB)%%0001017/07/18 00:31:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[7] at count at /home_i1/y23ycc01/TCMAnalyzer2.py:70)%%0001017/07/18 00:31:51 INFO YarnScheduler: Adding task set 2.0 with 2 tasks%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc336:44962 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hcdnc304:34185 (size: 3.9 KB, free: 530.0 MB)%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 1397 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 1400 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:53 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:53 INFO DAGScheduler: ResultStage 2 (count at /home_i1/y23ycc01/TCMAnalyzer2.py:70) finished in 1.400 s%%0001017/07/18 00:31:53 INFO DAGScheduler: Job 1 finished: count at /home_i1/y23ycc01/TCMAnalyzer2.py:70, took 19.060293 s%%0001017/07/18 00:31:53 WARN FPGrowth: Input data is not cached.%%0001017/07/18 00:31:53 INFO SparkContext: Starting job: count at FPGrowth.scala:121%%0001017/07/18 00:31:53 INFO DAGScheduler: Got job 2 (count at FPGrowth.scala:121) with 2 output partitions%%0001017/07/18 00:31:53 INFO DAGScheduler: Final stage: ResultStage 4(count at FPGrowth.scala:121)%%0001017/07/18 00:31:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)%%0001017/07/18 00:31:53 INFO DAGScheduler: Missing parents: List()%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544), which has no missing parents%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(6520) called with curMem=262336, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO MemoryStore: ensureFreeSpace(3902) called with curMem=268856, maxMem=556038881%%0001017/07/18 00:31:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KB, free 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.1.12:41687 (size: 3.8 KB, free: 530.2 MB)%%0001017/07/18 00:31:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at map at PythonMLLibAPI.scala:544)%%0001017/07/18 00:31:53 INFO YarnScheduler: Adding task set 4.0 with 2 tasks%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc304:34185 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hcdnc336:44962 (size: 3.8 KB, free: 530.0 MB)%%0001017/07/18 00:31:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 2566 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:56 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2767 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:56 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:56 INFO DAGScheduler: ResultStage 4 (count at FPGrowth.scala:121) finished in 2.769 s%%0001017/07/18 00:31:56 INFO DAGScheduler: Job 2 finished: count at FPGrowth.scala:121, took 2.781932 s%%0001017/07/18 00:31:56 INFO SparkContext: Starting job: collect at FPGrowth.scala:156%%0001017/07/18 00:31:56 INFO DAGScheduler: Registering RDD 12 (map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO DAGScheduler: Got job 3 (collect at FPGrowth.scala:156) with 10 output partitions%%0001017/07/18 00:31:56 INFO DAGScheduler: Final stage: ResultStage 7(collect at FPGrowth.scala:156)%%0001017/07/18 00:31:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153), which has no missing parents%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(7176) called with curMem=272758, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO MemoryStore: ensureFreeSpace(4149) called with curMem=279934, maxMem=556038881%%0001017/07/18 00:31:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.1.12:41687 (size: 4.1 KB, free: 530.2 MB)%%0001017/07/18 00:31:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at map at FPGrowth.scala:153)%%0001017/07/18 00:31:56 INFO YarnScheduler: Adding task set 6.0 with 2 tasks%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc336:44962 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hcdnc304:34185 (size: 4.1 KB, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 2703 ms on hcdnc304 (1/2)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 2776 ms on hcdnc336 (2/2)%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: ShuffleMapStage 6 (map at FPGrowth.scala:153) finished in 2.777 s%%0001017/07/18 00:31:58 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:31:58 INFO DAGScheduler: running: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: waiting: Set(ResultStage 7)%%0001017/07/18 00:31:58 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:31:58 INFO DAGScheduler: Missing parents for ResultStage 7: List()%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155), which is now runnable%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(2784) called with curMem=284083, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.7 KB, free 530.0 MB)%%0001017/07/18 00:31:58 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=286867, maxMem=556038881%%0001017/07/18 00:31:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1613.0 B, free 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.1.12:41687 (size: 1613.0 B, free: 530.2 MB)%%0001017/07/18 00:31:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[14] at filter at FPGrowth.scala:155)%%0001017/07/18 00:31:58 INFO YarnScheduler: Adding task set 7.0 with 10 tasks%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, hcdnc336, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, hcdnc304, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc336:44962 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hcdnc304:34185 (size: 1613.0 B, free: 530.0 MB)%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc336:34477%%0001017/07/18 00:31:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 165 bytes%%0001017/07/18 00:31:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to hcdnc304:56029%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, hcdnc336, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 44 ms on hcdnc336 (1/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, hcdnc304, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 46 ms on hcdnc304 (2/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, hcdnc336, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 14 ms on hcdnc336 (3/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 15, hcdnc304, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 17 ms on hcdnc304 (4/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 16, hcdnc336, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 17 ms on hcdnc336 (5/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 17, hcdnc304, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 15) in 20 ms on hcdnc304 (6/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 18, hcdnc336, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 16) in 15 ms on hcdnc336 (7/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 19, hcdnc304, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 17) in 12 ms on hcdnc304 (8/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 18) in 13 ms on hcdnc336 (9/10)%%0001017/07/18 00:31:58 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 19) in 12 ms on hcdnc304 (10/10)%%0001017/07/18 00:31:58 INFO DAGScheduler: ResultStage 7 (collect at FPGrowth.scala:156) finished in 0.103 s%%0001017/07/18 00:31:58 INFO YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool %%0001017/07/18 00:31:58 INFO DAGScheduler: Job 3 finished: collect at FPGrowth.scala:156, took 2.901611 s%%0001017/07/18 00:31:59 INFO SparkContext: Starting job: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73%%0001017/07/18 00:31:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes%%0001017/07/18 00:31:59 INFO DAGScheduler: Registering RDD 15 (flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO DAGScheduler: Got job 4 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) with 10 output partitions%%0001017/07/18 00:31:59 INFO DAGScheduler: Final stage: ResultStage 10(collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:31:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175), which has no missing parents%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(12240) called with curMem=288480, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO MemoryStore: ensureFreeSpace(6747) called with curMem=300720, maxMem=556038881%%0001017/07/18 00:31:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.1.12:41687 (size: 6.6 KB, free: 530.2 MB)%%0001017/07/18 00:31:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:31:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[15] at flatMap at FPGrowth.scala:175)%%0001017/07/18 00:31:59 INFO YarnScheduler: Adding task set 9.0 with 2 tasks%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20, hcdnc336, partition 0,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21, hcdnc304, partition 1,PROCESS_LOCAL, 1890 bytes)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc336:44962 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hcdnc304:34185 (size: 6.6 KB, free: 530.0 MB)%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc336:34477%%0001017/07/18 00:31:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 10438 ms on hcdnc336 (1/2)%%0001017/07/18 00:32:09 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 10676 ms on hcdnc304 (2/2)%%0001017/07/18 00:32:09 INFO YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:09 INFO DAGScheduler: ShuffleMapStage 9 (flatMap at FPGrowth.scala:175) finished in 10.677 s%%0001017/07/18 00:32:09 INFO DAGScheduler: looking for newly runnable stages%%0001017/07/18 00:32:09 INFO DAGScheduler: running: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: waiting: Set(ResultStage 10)%%0001017/07/18 00:32:09 INFO DAGScheduler: failed: Set()%%0001017/07/18 00:32:09 INFO DAGScheduler: Missing parents for ResultStage 10: List()%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73), which is now runnable%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(15160) called with curMem=307467, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO MemoryStore: ensureFreeSpace(7999) called with curMem=322627, maxMem=556038881%%0001017/07/18 00:32:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.8 KB, free 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.1.12:41687 (size: 7.8 KB, free: 530.2 MB)%%0001017/07/18 00:32:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861%%0001017/07/18 00:32:09 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 10 (PythonRDD[22] at collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73)%%0001017/07/18 00:32:09 INFO YarnScheduler: Adding task set 10.0 with 10 tasks%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, hcdnc304, partition 0,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 23, hcdnc336, partition 1,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc304:34185 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hcdnc336:44962 (size: 7.8 KB, free: 530.0 MB)%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc304:56029%%0001017/07/18 00:32:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 161 bytes%%0001017/07/18 00:32:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to hcdnc336:34477%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 24, hcdnc304, partition 2,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 444 ms on hcdnc304 (1/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 25, hcdnc336, partition 3,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 23) in 480 ms on hcdnc336 (2/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 26, hcdnc304, partition 4,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 24) in 313 ms on hcdnc304 (3/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 27, hcdnc336, partition 5,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 25) in 357 ms on hcdnc336 (4/10)%%0001017/07/18 00:32:10 INFO ExecutorAllocationManager: Requesting 3 new executors because tasks are backlogged (new desired total will be 3)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 28, hcdnc304, partition 6,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 26) in 356 ms on hcdnc304 (5/10)%%0001017/07/18 00:32:10 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 29, hcdnc336, partition 7,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:10 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 27) in 323 ms on hcdnc336 (6/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 30, hcdnc304, partition 8,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 28) in 286 ms on hcdnc304 (7/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 31, hcdnc336, partition 9,PROCESS_LOCAL, 1901 bytes)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 29) in 393 ms on hcdnc336 (8/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 30) in 322 ms on hcdnc304 (9/10)%%0001017/07/18 00:32:11 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 31) in 346 ms on hcdnc336 (10/10)%%0001017/07/18 00:32:11 INFO YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool %%0001017/07/18 00:32:11 INFO DAGScheduler: ResultStage 10 (collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73) finished in 1.894 s%%0001017/07/18 00:32:11 INFO DAGScheduler: Job 4 finished: collect at /home_i1/y23ycc01/TCMAnalyzer2.py:73, took 12.597608 s%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}%%0001017/07/18 00:32:11 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}%%0001017/07/18 00:32:11 INFO SparkUI: Stopped Spark web UI at http://172.16.1.12:4040%%0001017/07/18 00:32:11 INFO DAGScheduler: Stopping DAGScheduler%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Shutting down all executors%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Interrupting monitor thread%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Asking each executor to shut down%%0001017/07/18 00:32:11 INFO YarnClientSchedulerBackend: Stopped%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc336:34477]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc336:34477%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@172.16.1.12:46770] &lt;- [akka.tcp://sparkExecutor@hcdnc304:56029]: Error [Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029] [%%00010akka.remote.ShutDownAssociation: Shut down address: akka.tcp://sparkExecutor@hcdnc304:56029%%00010Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.%%00010]%%00010akka.event.Logging$Error$NoCause$%%0001017/07/18 00:32:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!%%0001017/07/18 00:32:11 INFO MemoryStore: MemoryStore cleared%%0001017/07/18 00:32:11 INFO BlockManager: BlockManager stopped%%0001017/07/18 00:32:11 INFO BlockManagerMaster: BlockManagerMaster stopped%%0001017/07/18 00:32:11 INFO SparkContext: Successfully stopped SparkContext%%0001017/07/18 00:32:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!%%0001017/07/18 00:32:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.%%0001017/07/18 00:32:12 INFO Remoting: Remoting shut down%%0001017/07/18 00:32:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Shutdown hook called%%0001017/07/18 00:32:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-ea345060-46f1-4ac3-9634-d63c6b690443%%00010"/>
</config>
<entry key="factory" type="xstring" value="org.pasteur.pf2.tools.BashNodeFactory"/>
<entry key="node-name" type="xstring" value="Bash"/>
<entry key="node-bundle-name" type="xstring" value="NGS related nodes for KNIME Workbench"/>
<entry key="node-bundle-symbolic-name" type="xstring" value="org.pasteur.pf2.ngs"/>
<entry key="node-bundle-vendor" type="xstring" value="Bernd Jagla, Institute Pasteur"/>
<entry key="node-bundle-version" type="xstring" value="0.2.200.v201510231057"/>
<entry key="node-feature-name" type="xstring" value="KNIME NGS tools"/>
<entry key="node-feature-symbolic-name" type="xstring" value="org.pasteur.pf2.ngs.feature.feature.group"/>
<entry key="node-feature-vendor" type="xstring" value="Plate-forme 2 - Transcriptome et Epigenome, Institut Pasteur, Paris."/>
<entry key="node-feature-version" type="xstring" value="0.2.200.v201602081511"/>
<config key="factory_settings"/>
<entry key="name" type="xstring" value="Bash"/>
<entry key="hasContent" type="xboolean" value="false"/>
<entry key="isInactive" type="xboolean" value="true"/>
<config key="ports">
<config key="port_1">
<entry key="index" type="xint" value="1"/>
<entry key="port_spec_class" type="xstring" value="org.knime.core.node.port.inactive.InactiveBranchPortObjectSpec"/>
<entry key="port_object_class" type="xstring" value="org.knime.core.node.port.inactive.InactiveBranchPortObject"/>
<entry key="port_object_summary" type="xstring" value="Inactive Port Object"/>
<entry key="port_spec_location" type="xstring" value="spec/spec.zip"/>
<entry key="port_object_location" type="xstring" value="object/portobject.zip"/>
<entry key="port_dir_location" type="xstring" value="port_1"/>
</config>
<config key="port_2">
<entry key="index" type="xint" value="2"/>
<entry key="port_spec_class" type="xstring" value="org.knime.core.node.port.inactive.InactiveBranchPortObjectSpec"/>
<entry key="port_object_class" type="xstring" value="org.knime.core.node.port.inactive.InactiveBranchPortObject"/>
<entry key="port_object_summary" type="xstring" value="Inactive Port Object"/>
<entry key="port_spec_location" type="xstring" value="spec/spec.zip"/>
<entry key="port_object_location" type="xstring" value="object/portobject.zip"/>
<entry key="port_dir_location" type="xstring" value="port_2"/>
</config>
</config>
<config key="filestores">
<entry key="file_store_location" type="xstring" isnull="true" value=""/>
<entry key="file_store_id" type="xstring" isnull="true" value=""/>
</config>
</config>
